{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import Boo-specific libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Yunzhou-specific libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 10\n",
    "SPLIT = 0.2\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import and Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "raw_cases_df = pd.read_csv('Data/confirmed_diff.csv')\n",
    "raw_deaths_df = pd.read_csv('Data/deaths_diff.csv')\n",
    "raw_mobility_df = pd.read_csv('Data/Google_Mobility.csv')\n",
    "# raw_whole_usa_cases_df = pd.read_csv('Data/us_confirmed_cases.csv')\n",
    "# raw_whole_usa_deaths_df = pd.read_csv('Data/us_confirmed_deaths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR STATES\n",
    "# Clean Mobility Data\n",
    "# mobility_df already contains only those counties and states for which\n",
    "# complete data on all 6 mobility categories exist\n",
    "mobility_df = raw_mobility_df.copy()\n",
    "mobility_df = mobility_df.rename(columns={\"retail_and_recreation_percent_change_from_baseline\": \"retail_and_recreation\",\n",
    "        \"grocery_and_pharmacy_percent_change_from_baseline\": \"grocery_and_pharmacy\",\n",
    "        \"parks_percent_change_from_baseline\": \"parks\",\n",
    "        \"transit_stations_percent_change_from_baseline\": \"transit_stations\",\n",
    "        \"workplaces_percent_change_from_baseline\": \"workplaces\",\n",
    "        \"residential_percent_change_from_baseline\": \"residential\"})\n",
    "# Optional extreme shortening of names\n",
    "if True:\n",
    "    mobility_df = mobility_df.rename(columns={\"retail_and_recreation\": \"rr\",\n",
    "            \"grocery_and_pharmacy\": \"gp\",\n",
    "            \"transit_stations\": \"ts\",\n",
    "            \"workplaces\": \"wp\",\n",
    "            \"residential\": \"res\"})\n",
    "# US is the country already, do not need that data\n",
    "mobility_df.drop(columns=['country_region_code', 'country_region'], inplace=True)\n",
    "mobility_df.rename(columns={'sub_region_1': 'state', 'sub_region_2': 'county'}, inplace=True)\n",
    "\n",
    "# Extract all states only data, which have been marked with 'ZZZ' in the county name\n",
    "state_mobility_df = (mobility_df[mobility_df['county'] == 'ZZZ']).copy()\n",
    "state_mobility_df.drop(columns=['county'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR STATES\n",
    "# Clean Cases Data\n",
    "cases_df = raw_cases_df.copy()\n",
    "cases_df.rename(columns={'Admin2': 'county', 'Province_State': 'state', 'Date': 'date', 'Value': 'cases'}, inplace=True)\n",
    "# Since this is on the state level, county info is not needed\n",
    "# 'region' and 'diff' are legacy columns that are not needed here\n",
    "cases_df.drop(columns=['Country_Region', 'county', 'Lat', 'Long_', 'region', 'diff'], inplace=True)\n",
    "# Sum up cases for each state\n",
    "state_cases_df = cases_df.groupby(['state', 'date'], as_index=False).agg({'cases':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR STATES\n",
    "# Merge Google Mobility and Cases Data\n",
    "state_cases_mobility_df = state_cases_df.merge(state_mobility_df, how='inner', on=['state', 'date'])\n",
    "# Sort to ensure proper order\n",
    "state_cases_mobility_df['date'] = pd.to_datetime(state_cases_mobility_df['date'], format=\"%m/%d/%Y\")\n",
    "state_cases_mobility_df.sort_values(['state', 'date'], ascending=[True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all applicable states for later\n",
    "state_names = ['South Carolina', 'Louisiana', 'Virginia', 'Idaho', 'Iowa',\n",
    "               'Kentucky', 'Missouri', 'Oklahoma', 'Colorado', 'Illinois',\n",
    "               'Indiana', 'Mississippi', 'Nebraska', 'North Dakota', 'Ohio',\n",
    "               'Pennsylvania', 'Washington', 'Wisconsin', 'Vermont', 'Minnesota',\n",
    "               'Florida', 'North Carolina', 'California', 'New York', 'Wyoming',\n",
    "               'Michigan', 'Alaska', 'Maryland', 'Kansas', 'Tennessee', 'Texas',\n",
    "               'Maine', 'Arizona', 'Georgia', 'Arkansas', 'New Jersey',\n",
    "               'South Dakota', 'Alabama', 'Oregon', 'West Virginia',\n",
    "               'Massachusetts', 'Utah', 'Montana', 'New Hampshire', 'New Mexico',\n",
    "               'Rhode Island', 'Nevada', 'District of Columbia', 'Connecticut',\n",
    "               'Hawaii']\n",
    "# total of 50 statewide data (49 states + Washington D.C.)\n",
    "# Missing Delaware\n",
    "state_names_no_mobility = state_names.copy()\n",
    "state_names_no_mobility.append('Delaware')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is, \"state_cases_mobility_df\" contains confirmed cases data for each state at each point in time, with mobility data.\n",
    "\n",
    "\"state_cases_df\" only contains confirmed cases data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform Data**\n",
    "\n",
    "*Note that these models all assume,\n",
    "the underlying trend of cases for each state is the same,\n",
    "and there are no state-by-state variations in how the disease spreads,\n",
    "which is likely unrealistic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "# Following Boo\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# state_cases_mobility_normalized_df = scaler.fit_transform(state_cases_mobility_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to Split Data into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize Data for LSTM\n",
    "# Objective is to predict cases for current day given previous N_STEPS days\n",
    "# However, having multiple states, each as their own individual time series,\n",
    "# complicates this.\n",
    "# input should be of shape (n_steps, n_features) with multiple samples\n",
    "\n",
    "# Modified from Boo's code\n",
    "def get_LSTM_states_dataset(dataset, n_steps=1):\n",
    "    dataset = dataset.copy()\n",
    "    dataset.drop(columns=['date'], inplace=True)\n",
    "    #print(dataset.shape)\n",
    "    dataset_by_states = []\n",
    "    # Normalize data while you are at it\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    for state in dataset['state'].unique():\n",
    "        state_values = dataset[dataset['state'] == state].drop(columns='state').values\n",
    "        state_values = scaler.fit_transform(state_values)\n",
    "        dataset_by_states.append(state_values)\n",
    "    X, y = [], []\n",
    "    for state_dataset in dataset_by_states:\n",
    "        for i in range(len(state_dataset) - n_steps - 1):\n",
    "            a = state_dataset[i:(i+n_steps)]\n",
    "            X.append(a)\n",
    "            y.append(state_dataset[i + n_steps][0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_LSTM, y_LSTM = get_LSTM_states_dataset(state_cases_mobility_df, n_steps=N_STEPS)\n",
    "X_train_LSTM, X_test_LSTM, y_train_LSTM, y_test_LSTM = train_test_split(X_LSTM, y_LSTM, test_size=SPLIT, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize Data for CNN/Regular NN\n",
    "# Objective is to predict cases for current day given previous N_STEPS days.\n",
    "# We must add the value of the columns from previous\n",
    "# days as extra features per observation\n",
    "def get_CNN_states_dataset(dataset, n_steps=1):\n",
    "    dataset = dataset.copy()\n",
    "    dataset.drop(columns=['date'], inplace=True)\n",
    "    #print(dataset.shape)\n",
    "    dataset_by_states = []\n",
    "    # Normalize data while you are at it\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    for state in dataset['state'].unique():\n",
    "        state_values = dataset[dataset['state'] == state].drop(columns='state').values\n",
    "        state_values = scaler.fit_transform(state_values)\n",
    "        dataset_by_states.append(state_values)\n",
    "    X, y = [], []\n",
    "    for state_dataset in dataset_by_states:\n",
    "        for i in range(len(state_dataset) - n_steps - 1):\n",
    "            a = state_dataset[i:(i+n_steps)]\n",
    "            X.append(a)\n",
    "            y.append(state_dataset[i + n_steps][0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_CNN, y_CNN = get_CNN_states_dataset(state_cases_mobility_df, n_steps=N_STEPS)\n",
    "X_train_CNN, X_test_CNN, y_train_CNN, y_test_CNN = train_test_split(X_CNN, y_CNN, test_size=SPLIT, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize Data for Yunzhou's NN\n",
    "\n",
    "def get_YNN_states_dataset(dataset, n_steps=1):\n",
    "    dataset = dataset.copy()\n",
    "    dataset.drop(columns=['date'], inplace=True)\n",
    "    #print(dataset.shape)\n",
    "    dataset_by_states = []\n",
    "    # Normalize data while you are at it\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    for state in dataset['state'].unique():\n",
    "        state_values = dataset[dataset['state'] == state].drop(columns='state').values\n",
    "        state_values = scaler.fit_transform(state_values)\n",
    "        dataset_by_states.append(state_values)\n",
    "    X, y = [], []\n",
    "    for state_dataset in dataset_by_states:\n",
    "        for i in range(len(state_dataset) - n_steps - 1):\n",
    "            a = state_dataset[i:(i+n_steps)]\n",
    "            # Flatten a, a list of lists, into a single row of features\n",
    "            flat_a = []\n",
    "            for sublist in a:\n",
    "                for item in sublist:\n",
    "                    flat_a.append(item)\n",
    "            X.append(flat_a)\n",
    "            y.append(state_dataset[i + n_steps][0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_YNN, y_YNN = get_YNN_states_dataset(state_cases_mobility_df, n_steps=N_STEPS)\n",
    "X_train_YNN, X_test_YNN, y_train_YNN, y_test_YNN = train_test_split(X_YNN, y_YNN, test_size=SPLIT, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Model with Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LSTM, Boo's model\n",
    "def get_lstm(n_steps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(n_steps, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer = 'adam', loss='mse', metrics=['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "n_lstm_features = X_train_LSTM.shape[2]\n",
    "lstm = get_lstm(N_STEPS, n_lstm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 2440 samples, validate on 610 samples\n",
      "Epoch 1/200\n",
      "2440/2440 [==============================] - 1s 407us/step - loss: 0.0197 - mae: 0.0881 - mse: 0.0197 - val_loss: 0.0029 - val_mae: 0.0367 - val_mse: 0.0029\n",
      "Epoch 2/200\n",
      "2440/2440 [==============================] - 1s 235us/step - loss: 0.0019 - mae: 0.0312 - mse: 0.0019 - val_loss: 0.0018 - val_mae: 0.0265 - val_mse: 0.0018\n",
      "Epoch 3/200\n",
      "2440/2440 [==============================] - 1s 227us/step - loss: 0.0015 - mae: 0.0263 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0250 - val_mse: 0.0015\n",
      "Epoch 4/200\n",
      "2440/2440 [==============================] - 1s 234us/step - loss: 0.0012 - mae: 0.0237 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0227 - val_mse: 0.0012\n",
      "Epoch 5/200\n",
      "2440/2440 [==============================] - 1s 227us/step - loss: 0.0011 - mae: 0.0228 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0213 - val_mse: 0.0011\n",
      "Epoch 6/200\n",
      "2440/2440 [==============================] - 1s 237us/step - loss: 0.0010 - mae: 0.0224 - mse: 0.0010 - val_loss: 9.6651e-04 - val_mae: 0.0195 - val_mse: 9.6651e-04\n",
      "Epoch 7/200\n",
      "2440/2440 [==============================] - 1s 233us/step - loss: 9.8294e-04 - mae: 0.0227 - mse: 9.8294e-04 - val_loss: 9.1408e-04 - val_mae: 0.0197 - val_mse: 9.1408e-04\n",
      "Epoch 8/200\n",
      "2440/2440 [==============================] - 1s 236us/step - loss: 9.5853e-04 - mae: 0.0227 - mse: 9.5853e-04 - val_loss: 9.1875e-04 - val_mae: 0.0215 - val_mse: 9.1875e-04\n",
      "Epoch 9/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 9.3736e-04 - mae: 0.0227 - mse: 9.3736e-04 - val_loss: 9.2948e-04 - val_mae: 0.0227 - val_mse: 9.2948e-04\n",
      "Epoch 10/200\n",
      "2440/2440 [==============================] - 1s 231us/step - loss: 8.9306e-04 - mae: 0.0221 - mse: 8.9306e-04 - val_loss: 8.5018e-04 - val_mae: 0.0209 - val_mse: 8.5018e-04\n",
      "Epoch 11/200\n",
      "2440/2440 [==============================] - 1s 247us/step - loss: 8.1297e-04 - mae: 0.0208 - mse: 8.1297e-04 - val_loss: 7.6098e-04 - val_mae: 0.0184 - val_mse: 7.6098e-04\n",
      "Epoch 12/200\n",
      "2440/2440 [==============================] - 1s 242us/step - loss: 7.4072e-04 - mae: 0.0195 - mse: 7.4072e-04 - val_loss: 7.0966e-04 - val_mae: 0.0174 - val_mse: 7.0966e-04\n",
      "Epoch 13/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 6.9183e-04 - mae: 0.0187 - mse: 6.9183e-04 - val_loss: 6.7342e-04 - val_mae: 0.0170 - val_mse: 6.7342e-04\n",
      "Epoch 14/200\n",
      "2440/2440 [==============================] - 1s 230us/step - loss: 6.5506e-04 - mae: 0.0181 - mse: 6.5506e-04 - val_loss: 6.4096e-04 - val_mae: 0.0167 - val_mse: 6.4096e-04\n",
      "Epoch 15/200\n",
      "2440/2440 [==============================] - 1s 233us/step - loss: 6.2165e-04 - mae: 0.0176 - mse: 6.2165e-04 - val_loss: 6.0879e-04 - val_mae: 0.0164 - val_mse: 6.0879e-04\n",
      "Epoch 16/200\n",
      "2440/2440 [==============================] - 1s 225us/step - loss: 5.8906e-04 - mae: 0.0172 - mse: 5.8906e-04 - val_loss: 5.7677e-04 - val_mae: 0.0160 - val_mse: 5.7677e-04\n",
      "Epoch 17/200\n",
      "2440/2440 [==============================] - 1s 231us/step - loss: 5.5752e-04 - mae: 0.0167 - mse: 5.5752e-04 - val_loss: 5.4574e-04 - val_mae: 0.0157 - val_mse: 5.4574e-04\n",
      "Epoch 18/200\n",
      "2440/2440 [==============================] - 1s 235us/step - loss: 5.2778e-04 - mae: 0.0162 - mse: 5.2778e-04 - val_loss: 5.1637e-04 - val_mae: 0.0153 - val_mse: 5.1637e-04\n",
      "Epoch 19/200\n",
      "2440/2440 [==============================] - 1s 242us/step - loss: 5.0013e-04 - mae: 0.0157 - mse: 5.0013e-04 - val_loss: 4.8881e-04 - val_mae: 0.0149 - val_mse: 4.8881e-04\n",
      "Epoch 20/200\n",
      "2440/2440 [==============================] - 1s 248us/step - loss: 4.7438e-04 - mae: 0.0153 - mse: 4.7438e-04 - val_loss: 4.6296e-04 - val_mae: 0.0146 - val_mse: 4.6296e-04\n",
      "Epoch 21/200\n",
      "2440/2440 [==============================] - 1s 238us/step - loss: 4.5022e-04 - mae: 0.0149 - mse: 4.5022e-04 - val_loss: 4.3832e-04 - val_mae: 0.0142 - val_mse: 4.3832e-04\n",
      "Epoch 22/200\n",
      "2440/2440 [==============================] - 1s 233us/step - loss: 4.2727e-04 - mae: 0.0144 - mse: 4.2727e-04 - val_loss: 4.1445e-04 - val_mae: 0.0138 - val_mse: 4.1445e-04\n",
      "Epoch 23/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 4.0538e-04 - mae: 0.0139 - mse: 4.0538e-04 - val_loss: 3.9100e-04 - val_mae: 0.0133 - val_mse: 3.9100e-04\n",
      "Epoch 24/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 3.8451e-04 - mae: 0.0135 - mse: 3.8451e-04 - val_loss: 3.6814e-04 - val_mae: 0.0127 - val_mse: 3.6814e-04\n",
      "Epoch 25/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 3.6496e-04 - mae: 0.0130 - mse: 3.6496e-04 - val_loss: 3.4675e-04 - val_mae: 0.0121 - val_mse: 3.4675e-04\n",
      "Epoch 26/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 3.4724e-04 - mae: 0.0126 - mse: 3.4724e-04 - val_loss: 3.2806e-04 - val_mae: 0.0115 - val_mse: 3.2806e-04\n",
      "Epoch 27/200\n",
      "2440/2440 [==============================] - 1s 240us/step - loss: 3.3194e-04 - mae: 0.0122 - mse: 3.3194e-04 - val_loss: 3.1316e-04 - val_mae: 0.0110 - val_mse: 3.1316e-04\n",
      "Epoch 28/200\n",
      "2440/2440 [==============================] - 1s 249us/step - loss: 3.1938e-04 - mae: 0.0119 - mse: 3.1938e-04 - val_loss: 3.0241e-04 - val_mae: 0.0107 - val_mse: 3.0241e-04\n",
      "Epoch 29/200\n",
      "2440/2440 [==============================] - 1s 259us/step - loss: 3.0934e-04 - mae: 0.0117 - mse: 3.0934e-04 - val_loss: 2.9543e-04 - val_mae: 0.0106 - val_mse: 2.9543e-04\n",
      "Epoch 30/200\n",
      "2440/2440 [==============================] - 1s 241us/step - loss: 3.0115e-04 - mae: 0.0115 - mse: 3.0115e-04 - val_loss: 2.9148e-04 - val_mae: 0.0106 - val_mse: 2.9148e-04\n",
      "Epoch 31/200\n",
      "2440/2440 [==============================] - 1s 231us/step - loss: 2.9408e-04 - mae: 0.0114 - mse: 2.9408e-04 - val_loss: 2.8977e-04 - val_mae: 0.0106 - val_mse: 2.8977e-04\n",
      "Epoch 32/200\n",
      "2440/2440 [==============================] - 1s 233us/step - loss: 2.8758e-04 - mae: 0.0113 - mse: 2.8758e-04 - val_loss: 2.8952e-04 - val_mae: 0.0107 - val_mse: 2.8952e-04\n",
      "Epoch 33/200\n",
      "2440/2440 [==============================] - 1s 230us/step - loss: 2.8133e-04 - mae: 0.0112 - mse: 2.8133e-04 - val_loss: 2.9001e-04 - val_mae: 0.0109 - val_mse: 2.9001e-04\n",
      "Epoch 34/200\n",
      "2440/2440 [==============================] - 1s 237us/step - loss: 2.7513e-04 - mae: 0.0111 - mse: 2.7513e-04 - val_loss: 2.9063e-04 - val_mae: 0.0110 - val_mse: 2.9063e-04\n",
      "Epoch 35/200\n",
      "2440/2440 [==============================] - 1s 220us/step - loss: 2.6890e-04 - mae: 0.0110 - mse: 2.6890e-04 - val_loss: 2.9083e-04 - val_mae: 0.0112 - val_mse: 2.9083e-04\n",
      "Epoch 36/200\n",
      "2440/2440 [==============================] - 1s 230us/step - loss: 2.6263e-04 - mae: 0.0108 - mse: 2.6263e-04 - val_loss: 2.9028e-04 - val_mae: 0.0112 - val_mse: 2.9028e-04\n",
      "Epoch 37/200\n",
      "2440/2440 [==============================] - 1s 334us/step - loss: 2.5636e-04 - mae: 0.0107 - mse: 2.5636e-04 - val_loss: 2.8885e-04 - val_mae: 0.0112 - val_mse: 2.8885e-04\n",
      "Epoch 38/200\n",
      "2440/2440 [==============================] - 0s 197us/step - loss: 2.5022e-04 - mae: 0.0106 - mse: 2.5022e-04 - val_loss: 2.8660e-04 - val_mae: 0.0111 - val_mse: 2.8660e-04\n",
      "Epoch 39/200\n",
      "2440/2440 [==============================] - 0s 201us/step - loss: 2.4430e-04 - mae: 0.0105 - mse: 2.4430e-04 - val_loss: 2.8368e-04 - val_mae: 0.0110 - val_mse: 2.8368e-04\n",
      "Epoch 40/200\n",
      "2440/2440 [==============================] - 1s 206us/step - loss: 2.3871e-04 - mae: 0.0104 - mse: 2.3871e-04 - val_loss: 2.8027e-04 - val_mae: 0.0108 - val_mse: 2.8027e-04\n",
      "Epoch 41/200\n",
      "2440/2440 [==============================] - 0s 190us/step - loss: 2.3350e-04 - mae: 0.0102 - mse: 2.3350e-04 - val_loss: 2.7658e-04 - val_mae: 0.0106 - val_mse: 2.7658e-04\n",
      "Epoch 42/200\n",
      "2440/2440 [==============================] - 0s 189us/step - loss: 2.2872e-04 - mae: 0.0101 - mse: 2.2872e-04 - val_loss: 2.7282e-04 - val_mae: 0.0104 - val_mse: 2.7282e-04\n",
      "Epoch 43/200\n",
      "2440/2440 [==============================] - 0s 184us/step - loss: 2.2435e-04 - mae: 0.0100 - mse: 2.2435e-04 - val_loss: 2.6921e-04 - val_mae: 0.0102 - val_mse: 2.6921e-04\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/2440 [==============================] - 0s 185us/step - loss: 2.2037e-04 - mae: 0.0099 - mse: 2.2037e-04 - val_loss: 2.6592e-04 - val_mae: 0.0100 - val_mse: 2.6592e-04\n",
      "Epoch 45/200\n",
      "2440/2440 [==============================] - 0s 183us/step - loss: 2.1673e-04 - mae: 0.0098 - mse: 2.1673e-04 - val_loss: 2.6301e-04 - val_mae: 0.0098 - val_mse: 2.6301e-04\n",
      "Epoch 46/200\n",
      "2440/2440 [==============================] - 0s 187us/step - loss: 2.1337e-04 - mae: 0.0098 - mse: 2.1337e-04 - val_loss: 2.6052e-04 - val_mae: 0.0097 - val_mse: 2.6052e-04\n",
      "Epoch 47/200\n",
      "2440/2440 [==============================] - 0s 189us/step - loss: 2.1025e-04 - mae: 0.0097 - mse: 2.1025e-04 - val_loss: 2.5837e-04 - val_mae: 0.0095 - val_mse: 2.5837e-04\n",
      "Epoch 48/200\n",
      "2440/2440 [==============================] - 0s 187us/step - loss: 2.0733e-04 - mae: 0.0096 - mse: 2.0733e-04 - val_loss: 2.5651e-04 - val_mae: 0.0094 - val_mse: 2.5651e-04\n",
      "Epoch 49/200\n",
      "2440/2440 [==============================] - 0s 187us/step - loss: 2.0458e-04 - mae: 0.0095 - mse: 2.0458e-04 - val_loss: 2.5484e-04 - val_mae: 0.0093 - val_mse: 2.5484e-04\n",
      "Epoch 50/200\n",
      "2440/2440 [==============================] - 0s 185us/step - loss: 2.0197e-04 - mae: 0.0094 - mse: 2.0197e-04 - val_loss: 2.5332e-04 - val_mae: 0.0092 - val_mse: 2.5332e-04\n",
      "Epoch 51/200\n",
      "2440/2440 [==============================] - 0s 183us/step - loss: 1.9949e-04 - mae: 0.0094 - mse: 1.9949e-04 - val_loss: 2.5186e-04 - val_mae: 0.0091 - val_mse: 2.5186e-04\n",
      "Epoch 52/200\n",
      "2440/2440 [==============================] - 0s 185us/step - loss: 1.9712e-04 - mae: 0.0093 - mse: 1.9712e-04 - val_loss: 2.5045e-04 - val_mae: 0.0091 - val_mse: 2.5045e-04\n",
      "Epoch 53/200\n",
      "2440/2440 [==============================] - 0s 184us/step - loss: 1.9487e-04 - mae: 0.0092 - mse: 1.9487e-04 - val_loss: 2.4905e-04 - val_mae: 0.0090 - val_mse: 2.4905e-04\n",
      "Epoch 54/200\n",
      "2440/2440 [==============================] - 1s 207us/step - loss: 1.9272e-04 - mae: 0.0092 - mse: 1.9272e-04 - val_loss: 2.4765e-04 - val_mae: 0.0090 - val_mse: 2.4765e-04\n",
      "Epoch 55/200\n",
      "2440/2440 [==============================] - 1s 280us/step - loss: 1.9068e-04 - mae: 0.0091 - mse: 1.9068e-04 - val_loss: 2.4625e-04 - val_mae: 0.0089 - val_mse: 2.4625e-04\n",
      "Epoch 56/200\n",
      "2440/2440 [==============================] - 1s 218us/step - loss: 1.8876e-04 - mae: 0.0091 - mse: 1.8876e-04 - val_loss: 2.4488e-04 - val_mae: 0.0089 - val_mse: 2.4488e-04\n",
      "Epoch 57/200\n",
      "2440/2440 [==============================] - 1s 227us/step - loss: 1.8693e-04 - mae: 0.0090 - mse: 1.8693e-04 - val_loss: 2.4352e-04 - val_mae: 0.0088 - val_mse: 2.4352e-04\n",
      "Epoch 58/200\n",
      "2440/2440 [==============================] - 1s 248us/step - loss: 1.8521e-04 - mae: 0.0090 - mse: 1.8521e-04 - val_loss: 2.4220e-04 - val_mae: 0.0088 - val_mse: 2.4220e-04\n",
      "Epoch 59/200\n",
      "2440/2440 [==============================] - 1s 245us/step - loss: 1.8358e-04 - mae: 0.0089 - mse: 1.8358e-04 - val_loss: 2.4090e-04 - val_mae: 0.0088 - val_mse: 2.4090e-04\n",
      "Epoch 60/200\n",
      "2440/2440 [==============================] - 1s 251us/step - loss: 1.8204e-04 - mae: 0.0089 - mse: 1.8204e-04 - val_loss: 2.3962e-04 - val_mae: 0.0087 - val_mse: 2.3962e-04\n",
      "Epoch 61/200\n",
      "2440/2440 [==============================] - 1s 249us/step - loss: 1.8057e-04 - mae: 0.0088 - mse: 1.8057e-04 - val_loss: 2.3837e-04 - val_mae: 0.0087 - val_mse: 2.3837e-04\n",
      "Epoch 62/200\n",
      "2440/2440 [==============================] - 1s 246us/step - loss: 1.7918e-04 - mae: 0.0088 - mse: 1.7918e-04 - val_loss: 2.3715e-04 - val_mae: 0.0087 - val_mse: 2.3715e-04\n",
      "Epoch 63/200\n",
      "2440/2440 [==============================] - 1s 254us/step - loss: 1.7786e-04 - mae: 0.0088 - mse: 1.7786e-04 - val_loss: 2.3596e-04 - val_mae: 0.0087 - val_mse: 2.3596e-04\n",
      "Epoch 64/200\n",
      "2440/2440 [==============================] - 1s 252us/step - loss: 1.7661e-04 - mae: 0.0087 - mse: 1.7661e-04 - val_loss: 2.3481e-04 - val_mae: 0.0086 - val_mse: 2.3481e-04\n",
      "Epoch 65/200\n",
      "2440/2440 [==============================] - 1s 231us/step - loss: 1.7542e-04 - mae: 0.0087 - mse: 1.7542e-04 - val_loss: 2.3372e-04 - val_mae: 0.0086 - val_mse: 2.3372e-04\n",
      "Epoch 66/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 1.7430e-04 - mae: 0.0087 - mse: 1.7430e-04 - val_loss: 2.3269e-04 - val_mae: 0.0086 - val_mse: 2.3269e-04\n",
      "Epoch 67/200\n",
      "2440/2440 [==============================] - 1s 225us/step - loss: 1.7324e-04 - mae: 0.0086 - mse: 1.7324e-04 - val_loss: 2.3173e-04 - val_mae: 0.0086 - val_mse: 2.3173e-04\n",
      "Epoch 68/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.7224e-04 - mae: 0.0086 - mse: 1.7224e-04 - val_loss: 2.3086e-04 - val_mae: 0.0086 - val_mse: 2.3086e-04\n",
      "Epoch 69/200\n",
      "2440/2440 [==============================] - 1s 225us/step - loss: 1.7130e-04 - mae: 0.0086 - mse: 1.7130e-04 - val_loss: 2.3009e-04 - val_mae: 0.0086 - val_mse: 2.3009e-04\n",
      "Epoch 70/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.7043e-04 - mae: 0.0086 - mse: 1.7043e-04 - val_loss: 2.2942e-04 - val_mae: 0.0085 - val_mse: 2.2942e-04\n",
      "Epoch 71/200\n",
      "2440/2440 [==============================] - 1s 233us/step - loss: 1.6961e-04 - mae: 0.0086 - mse: 1.6962e-04 - val_loss: 2.2887e-04 - val_mae: 0.0085 - val_mse: 2.2887e-04\n",
      "Epoch 72/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 1.6887e-04 - mae: 0.0085 - mse: 1.6887e-04 - val_loss: 2.2845e-04 - val_mae: 0.0086 - val_mse: 2.2845e-04\n",
      "Epoch 73/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.6819e-04 - mae: 0.0085 - mse: 1.6819e-04 - val_loss: 2.2817e-04 - val_mae: 0.0086 - val_mse: 2.2817e-04\n",
      "Epoch 74/200\n",
      "2440/2440 [==============================] - 1s 224us/step - loss: 1.6757e-04 - mae: 0.0085 - mse: 1.6757e-04 - val_loss: 2.2806e-04 - val_mae: 0.0086 - val_mse: 2.2806e-04\n",
      "Epoch 75/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 1.6702e-04 - mae: 0.0085 - mse: 1.6702e-04 - val_loss: 2.2813e-04 - val_mae: 0.0086 - val_mse: 2.2813e-04\n",
      "Epoch 76/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.6655e-04 - mae: 0.0085 - mse: 1.6655e-04 - val_loss: 2.2841e-04 - val_mae: 0.0087 - val_mse: 2.2841e-04\n",
      "Epoch 77/200\n",
      "2440/2440 [==============================] - 1s 239us/step - loss: 1.6614e-04 - mae: 0.0085 - mse: 1.6614e-04 - val_loss: 2.2894e-04 - val_mae: 0.0088 - val_mse: 2.2894e-04\n",
      "Epoch 78/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 1.6582e-04 - mae: 0.0085 - mse: 1.6582e-04 - val_loss: 2.2977e-04 - val_mae: 0.0089 - val_mse: 2.2977e-04\n",
      "Epoch 79/200\n",
      "2440/2440 [==============================] - 1s 231us/step - loss: 1.6558e-04 - mae: 0.0085 - mse: 1.6558e-04 - val_loss: 2.3094e-04 - val_mae: 0.0090 - val_mse: 2.3094e-04\n",
      "Epoch 80/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 1.6542e-04 - mae: 0.0085 - mse: 1.6542e-04 - val_loss: 2.3251e-04 - val_mae: 0.0091 - val_mse: 2.3251e-04\n",
      "Epoch 81/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.6533e-04 - mae: 0.0085 - mse: 1.6533e-04 - val_loss: 2.3450e-04 - val_mae: 0.0092 - val_mse: 2.3450e-04\n",
      "Epoch 82/200\n",
      "2440/2440 [==============================] - 1s 231us/step - loss: 1.6530e-04 - mae: 0.0085 - mse: 1.6530e-04 - val_loss: 2.3691e-04 - val_mae: 0.0094 - val_mse: 2.3691e-04\n",
      "Epoch 83/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 1.6528e-04 - mae: 0.0085 - mse: 1.6528e-04 - val_loss: 2.3958e-04 - val_mae: 0.0096 - val_mse: 2.3958e-04\n",
      "Epoch 84/200\n",
      "2440/2440 [==============================] - 1s 230us/step - loss: 1.6521e-04 - mae: 0.0085 - mse: 1.6521e-04 - val_loss: 2.4221e-04 - val_mae: 0.0098 - val_mse: 2.4221e-04\n",
      "Epoch 85/200\n",
      "2440/2440 [==============================] - 1s 235us/step - loss: 1.6498e-04 - mae: 0.0085 - mse: 1.6498e-04 - val_loss: 2.4427e-04 - val_mae: 0.0099 - val_mse: 2.4427e-04\n",
      "Epoch 86/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.6456e-04 - mae: 0.0085 - mse: 1.6456e-04 - val_loss: 2.4513e-04 - val_mae: 0.0100 - val_mse: 2.4513e-04\n",
      "Epoch 87/200\n",
      "2440/2440 [==============================] - 1s 226us/step - loss: 1.6395e-04 - mae: 0.0085 - mse: 1.6395e-04 - val_loss: 2.4443e-04 - val_mae: 0.0099 - val_mse: 2.4443e-04\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/2440 [==============================] - 1s 219us/step - loss: 1.6327e-04 - mae: 0.0085 - mse: 1.6327e-04 - val_loss: 2.4226e-04 - val_mae: 0.0098 - val_mse: 2.4226e-04\n",
      "Epoch 89/200\n",
      "2440/2440 [==============================] - 1s 209us/step - loss: 1.6264e-04 - mae: 0.0084 - mse: 1.6264e-04 - val_loss: 2.3916e-04 - val_mae: 0.0097 - val_mse: 2.3916e-04\n",
      "Epoch 90/200\n",
      "2440/2440 [==============================] - 1s 215us/step - loss: 1.6216e-04 - mae: 0.0084 - mse: 1.6216e-04 - val_loss: 2.3578e-04 - val_mae: 0.0095 - val_mse: 2.3578e-04\n",
      "Epoch 91/200\n",
      "2440/2440 [==============================] - 1s 208us/step - loss: 1.6185e-04 - mae: 0.0084 - mse: 1.6185e-04 - val_loss: 2.3255e-04 - val_mae: 0.0093 - val_mse: 2.3255e-04\n",
      "Epoch 92/200\n",
      "2440/2440 [==============================] - 1s 212us/step - loss: 1.6169e-04 - mae: 0.0084 - mse: 1.6169e-04 - val_loss: 2.2965e-04 - val_mae: 0.0091 - val_mse: 2.2965e-04\n",
      "Epoch 93/200\n",
      "2440/2440 [==============================] - 1s 217us/step - loss: 1.6165e-04 - mae: 0.0083 - mse: 1.6165e-04 - val_loss: 2.2713e-04 - val_mae: 0.0090 - val_mse: 2.2713e-04\n",
      "Epoch 94/200\n",
      "2440/2440 [==============================] - 1s 210us/step - loss: 1.6171e-04 - mae: 0.0083 - mse: 1.6171e-04 - val_loss: 2.2491e-04 - val_mae: 0.0088 - val_mse: 2.2491e-04\n",
      "Epoch 95/200\n",
      "2440/2440 [==============================] - 1s 215us/step - loss: 1.6183e-04 - mae: 0.0083 - mse: 1.6183e-04 - val_loss: 2.2293e-04 - val_mae: 0.0087 - val_mse: 2.2293e-04\n",
      "Epoch 96/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.6202e-04 - mae: 0.0083 - mse: 1.6202e-04 - val_loss: 2.2110e-04 - val_mae: 0.0086 - val_mse: 2.2110e-04\n",
      "Epoch 97/200\n",
      "2440/2440 [==============================] - 1s 209us/step - loss: 1.6226e-04 - mae: 0.0083 - mse: 1.6226e-04 - val_loss: 2.1936e-04 - val_mae: 0.0084 - val_mse: 2.1936e-04\n",
      "Epoch 98/200\n",
      "2440/2440 [==============================] - 1s 218us/step - loss: 1.6253e-04 - mae: 0.0083 - mse: 1.6253e-04 - val_loss: 2.1767e-04 - val_mae: 0.0083 - val_mse: 2.1767e-04\n",
      "Epoch 99/200\n",
      "2440/2440 [==============================] - 1s 214us/step - loss: 1.6284e-04 - mae: 0.0083 - mse: 1.6284e-04 - val_loss: 2.1599e-04 - val_mae: 0.0082 - val_mse: 2.1599e-04\n",
      "Epoch 100/200\n",
      "2440/2440 [==============================] - 1s 213us/step - loss: 1.6316e-04 - mae: 0.0083 - mse: 1.6316e-04 - val_loss: 2.1434e-04 - val_mae: 0.0080 - val_mse: 2.1434e-04\n",
      "Epoch 101/200\n",
      "2440/2440 [==============================] - 1s 214us/step - loss: 1.6347e-04 - mae: 0.0084 - mse: 1.6347e-04 - val_loss: 2.1277e-04 - val_mae: 0.0079 - val_mse: 2.1277e-04\n",
      "Epoch 102/200\n",
      "2440/2440 [==============================] - 1s 209us/step - loss: 1.6373e-04 - mae: 0.0084 - mse: 1.6373e-04 - val_loss: 2.1140e-04 - val_mae: 0.0078 - val_mse: 2.1140e-04\n",
      "Epoch 103/200\n",
      "2440/2440 [==============================] - 1s 208us/step - loss: 1.6381e-04 - mae: 0.0084 - mse: 1.6381e-04 - val_loss: 2.1043e-04 - val_mae: 0.0076 - val_mse: 2.1043e-04\n",
      "Epoch 104/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.6353e-04 - mae: 0.0084 - mse: 1.6353e-04 - val_loss: 2.1003e-04 - val_mae: 0.0075 - val_mse: 2.1003e-04\n",
      "Epoch 105/200\n",
      "2440/2440 [==============================] - 1s 217us/step - loss: 1.6265e-04 - mae: 0.0084 - mse: 1.6266e-04 - val_loss: 2.1027e-04 - val_mae: 0.0075 - val_mse: 2.1027e-04\n",
      "Epoch 106/200\n",
      "2440/2440 [==============================] - 1s 216us/step - loss: 1.6115e-04 - mae: 0.0083 - mse: 1.6115e-04 - val_loss: 2.1097e-04 - val_mae: 0.0076 - val_mse: 2.1097e-04\n",
      "Epoch 107/200\n",
      "2440/2440 [==============================] - 1s 220us/step - loss: 1.5930e-04 - mae: 0.0082 - mse: 1.5930e-04 - val_loss: 2.1186e-04 - val_mae: 0.0077 - val_mse: 2.1186e-04\n",
      "Epoch 108/200\n",
      "2440/2440 [==============================] - 1s 216us/step - loss: 1.5753e-04 - mae: 0.0081 - mse: 1.5753e-04 - val_loss: 2.1269e-04 - val_mae: 0.0078 - val_mse: 2.1269e-04\n",
      "Epoch 109/200\n",
      "2440/2440 [==============================] - 1s 217us/step - loss: 1.5609e-04 - mae: 0.0081 - mse: 1.5609e-04 - val_loss: 2.1334e-04 - val_mae: 0.0078 - val_mse: 2.1334e-04\n",
      "Epoch 110/200\n",
      "2440/2440 [==============================] - 1s 212us/step - loss: 1.5500e-04 - mae: 0.0080 - mse: 1.5500e-04 - val_loss: 2.1378e-04 - val_mae: 0.0079 - val_mse: 2.1378e-04\n",
      "Epoch 111/200\n",
      "2440/2440 [==============================] - 1s 216us/step - loss: 1.5417e-04 - mae: 0.0080 - mse: 1.5417e-04 - val_loss: 2.1405e-04 - val_mae: 0.0079 - val_mse: 2.1405e-04\n",
      "Epoch 112/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.5352e-04 - mae: 0.0080 - mse: 1.5352e-04 - val_loss: 2.1420e-04 - val_mae: 0.0080 - val_mse: 2.1420e-04\n",
      "Epoch 113/200\n",
      "2440/2440 [==============================] - 1s 214us/step - loss: 1.5300e-04 - mae: 0.0079 - mse: 1.5300e-04 - val_loss: 2.1427e-04 - val_mae: 0.0080 - val_mse: 2.1427e-04\n",
      "Epoch 114/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.5256e-04 - mae: 0.0079 - mse: 1.5256e-04 - val_loss: 2.1430e-04 - val_mae: 0.0080 - val_mse: 2.1430e-04\n",
      "Epoch 115/200\n",
      "2440/2440 [==============================] - 1s 212us/step - loss: 1.5217e-04 - mae: 0.0079 - mse: 1.5217e-04 - val_loss: 2.1429e-04 - val_mae: 0.0080 - val_mse: 2.1429e-04\n",
      "Epoch 116/200\n",
      "2440/2440 [==============================] - 1s 210us/step - loss: 1.5182e-04 - mae: 0.0079 - mse: 1.5182e-04 - val_loss: 2.1427e-04 - val_mae: 0.0080 - val_mse: 2.1427e-04\n",
      "Epoch 117/200\n",
      "2440/2440 [==============================] - 1s 215us/step - loss: 1.5150e-04 - mae: 0.0079 - mse: 1.5150e-04 - val_loss: 2.1425e-04 - val_mae: 0.0080 - val_mse: 2.1425e-04\n",
      "Epoch 118/200\n",
      "2440/2440 [==============================] - 1s 218us/step - loss: 1.5121e-04 - mae: 0.0078 - mse: 1.5121e-04 - val_loss: 2.1423e-04 - val_mae: 0.0080 - val_mse: 2.1423e-04\n",
      "Epoch 119/200\n",
      "2440/2440 [==============================] - 1s 210us/step - loss: 1.5092e-04 - mae: 0.0078 - mse: 1.5092e-04 - val_loss: 2.1421e-04 - val_mae: 0.0080 - val_mse: 2.1421e-04\n",
      "Epoch 120/200\n",
      "2440/2440 [==============================] - 1s 218us/step - loss: 1.5065e-04 - mae: 0.0078 - mse: 1.5065e-04 - val_loss: 2.1420e-04 - val_mae: 0.0080 - val_mse: 2.1420e-04\n",
      "Epoch 121/200\n",
      "2440/2440 [==============================] - 1s 213us/step - loss: 1.5039e-04 - mae: 0.0078 - mse: 1.5039e-04 - val_loss: 2.1420e-04 - val_mae: 0.0081 - val_mse: 2.1420e-04\n",
      "Epoch 122/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.5014e-04 - mae: 0.0078 - mse: 1.5014e-04 - val_loss: 2.1419e-04 - val_mae: 0.0081 - val_mse: 2.1419e-04\n",
      "Epoch 123/200\n",
      "2440/2440 [==============================] - 1s 216us/step - loss: 1.4990e-04 - mae: 0.0078 - mse: 1.4990e-04 - val_loss: 2.1419e-04 - val_mae: 0.0081 - val_mse: 2.1419e-04\n",
      "Epoch 124/200\n",
      "2440/2440 [==============================] - 1s 217us/step - loss: 1.4967e-04 - mae: 0.0078 - mse: 1.4967e-04 - val_loss: 2.1418e-04 - val_mae: 0.0081 - val_mse: 2.1418e-04\n",
      "Epoch 125/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.4944e-04 - mae: 0.0078 - mse: 1.4944e-04 - val_loss: 2.1417e-04 - val_mae: 0.0081 - val_mse: 2.1417e-04\n",
      "Epoch 126/200\n",
      "2440/2440 [==============================] - 1s 214us/step - loss: 1.4922e-04 - mae: 0.0078 - mse: 1.4922e-04 - val_loss: 2.1416e-04 - val_mae: 0.0081 - val_mse: 2.1416e-04\n",
      "Epoch 127/200\n",
      "2440/2440 [==============================] - 1s 210us/step - loss: 1.4901e-04 - mae: 0.0078 - mse: 1.4901e-04 - val_loss: 2.1413e-04 - val_mae: 0.0081 - val_mse: 2.1413e-04\n",
      "Epoch 128/200\n",
      "2440/2440 [==============================] - 1s 215us/step - loss: 1.4881e-04 - mae: 0.0078 - mse: 1.4881e-04 - val_loss: 2.1408e-04 - val_mae: 0.0081 - val_mse: 2.1408e-04\n",
      "Epoch 129/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.4861e-04 - mae: 0.0078 - mse: 1.4861e-04 - val_loss: 2.1401e-04 - val_mae: 0.0081 - val_mse: 2.1401e-04\n",
      "Epoch 130/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.4843e-04 - mae: 0.0078 - mse: 1.4843e-04 - val_loss: 2.1392e-04 - val_mae: 0.0081 - val_mse: 2.1392e-04\n",
      "Epoch 131/200\n",
      "2440/2440 [==============================] - 1s 215us/step - loss: 1.4826e-04 - mae: 0.0078 - mse: 1.4826e-04 - val_loss: 2.1379e-04 - val_mae: 0.0081 - val_mse: 2.1379e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "2440/2440 [==============================] - 1s 207us/step - loss: 1.4811e-04 - mae: 0.0078 - mse: 1.4811e-04 - val_loss: 2.1360e-04 - val_mae: 0.0081 - val_mse: 2.1360e-04\n",
      "Epoch 133/200\n",
      "2440/2440 [==============================] - 1s 214us/step - loss: 1.4799e-04 - mae: 0.0078 - mse: 1.4799e-04 - val_loss: 2.1336e-04 - val_mae: 0.0081 - val_mse: 2.1336e-04\n",
      "Epoch 134/200\n",
      "2440/2440 [==============================] - 1s 213us/step - loss: 1.4791e-04 - mae: 0.0078 - mse: 1.4791e-04 - val_loss: 2.1304e-04 - val_mae: 0.0081 - val_mse: 2.1304e-04\n",
      "Epoch 135/200\n",
      "2440/2440 [==============================] - 1s 213us/step - loss: 1.4788e-04 - mae: 0.0078 - mse: 1.4788e-04 - val_loss: 2.1262e-04 - val_mae: 0.0081 - val_mse: 2.1262e-04\n",
      "Epoch 136/200\n",
      "2440/2440 [==============================] - 1s 221us/step - loss: 1.4792e-04 - mae: 0.0078 - mse: 1.4792e-04 - val_loss: 2.1206e-04 - val_mae: 0.0080 - val_mse: 2.1206e-04\n",
      "Epoch 137/200\n",
      "2440/2440 [==============================] - 1s 217us/step - loss: 1.4807e-04 - mae: 0.0078 - mse: 1.4807e-04 - val_loss: 2.1132e-04 - val_mae: 0.0080 - val_mse: 2.1132e-04\n",
      "Epoch 138/200\n",
      "2440/2440 [==============================] - 1s 214us/step - loss: 1.4834e-04 - mae: 0.0078 - mse: 1.4834e-04 - val_loss: 2.1037e-04 - val_mae: 0.0079 - val_mse: 2.1037e-04\n",
      "Epoch 139/200\n",
      "2440/2440 [==============================] - 1s 210us/step - loss: 1.4878e-04 - mae: 0.0078 - mse: 1.4878e-04 - val_loss: 2.0916e-04 - val_mae: 0.0078 - val_mse: 2.0916e-04\n",
      "Epoch 140/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.4939e-04 - mae: 0.0079 - mse: 1.4939e-04 - val_loss: 2.0777e-04 - val_mae: 0.0077 - val_mse: 2.0777e-04\n",
      "Epoch 141/200\n",
      "2440/2440 [==============================] - 1s 212us/step - loss: 1.5009e-04 - mae: 0.0079 - mse: 1.5009e-04 - val_loss: 2.0644e-04 - val_mae: 0.0075 - val_mse: 2.0644e-04\n",
      "Epoch 142/200\n",
      "2440/2440 [==============================] - 1s 215us/step - loss: 1.5060e-04 - mae: 0.0079 - mse: 1.5060e-04 - val_loss: 2.0560e-04 - val_mae: 0.0074 - val_mse: 2.0560e-04\n",
      "Epoch 143/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 1.5053e-04 - mae: 0.0079 - mse: 1.5053e-04 - val_loss: 2.0562e-04 - val_mae: 0.0073 - val_mse: 2.0562e-04\n",
      "Epoch 144/200\n",
      "2440/2440 [==============================] - 1s 256us/step - loss: 1.4963e-04 - mae: 0.0079 - mse: 1.4963e-04 - val_loss: 2.0634e-04 - val_mae: 0.0074 - val_mse: 2.0634e-04\n",
      "Epoch 145/200\n",
      "2440/2440 [==============================] - 1s 291us/step - loss: 1.4826e-04 - mae: 0.0078 - mse: 1.4826e-04 - val_loss: 2.0721e-04 - val_mae: 0.0074 - val_mse: 2.0721e-04\n",
      "Epoch 146/200\n",
      "2440/2440 [==============================] - 1s 278us/step - loss: 1.4702e-04 - mae: 0.0078 - mse: 1.4702e-04 - val_loss: 2.0785e-04 - val_mae: 0.0075 - val_mse: 2.0785e-04\n",
      "Epoch 147/200\n",
      "2440/2440 [==============================] - 1s 290us/step - loss: 1.4618e-04 - mae: 0.0077 - mse: 1.4618e-04 - val_loss: 2.0821e-04 - val_mae: 0.0076 - val_mse: 2.0821e-04\n",
      "Epoch 148/200\n",
      "2440/2440 [==============================] - 1s 233us/step - loss: 1.4566e-04 - mae: 0.0077 - mse: 1.4566e-04 - val_loss: 2.0837e-04 - val_mae: 0.0076 - val_mse: 2.0837e-04\n",
      "Epoch 149/200\n",
      "2440/2440 [==============================] - 1s 258us/step - loss: 1.4531e-04 - mae: 0.0077 - mse: 1.4531e-04 - val_loss: 2.0842e-04 - val_mae: 0.0076 - val_mse: 2.0842e-04\n",
      "Epoch 150/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 1.4507e-04 - mae: 0.0077 - mse: 1.4507e-04 - val_loss: 2.0840e-04 - val_mae: 0.0076 - val_mse: 2.0840e-04\n",
      "Epoch 151/200\n",
      "2440/2440 [==============================] - 1s 257us/step - loss: 1.4490e-04 - mae: 0.0077 - mse: 1.4490e-04 - val_loss: 2.0835e-04 - val_mae: 0.0076 - val_mse: 2.0835e-04\n",
      "Epoch 152/200\n",
      "2440/2440 [==============================] - 1s 279us/step - loss: 1.4479e-04 - mae: 0.0077 - mse: 1.4479e-04 - val_loss: 2.0829e-04 - val_mae: 0.0076 - val_mse: 2.0829e-04\n",
      "Epoch 153/200\n",
      "2440/2440 [==============================] - 1s 264us/step - loss: 1.4473e-04 - mae: 0.0077 - mse: 1.4473e-04 - val_loss: 2.0825e-04 - val_mae: 0.0076 - val_mse: 2.0825e-04\n",
      "Epoch 154/200\n",
      "2440/2440 [==============================] - 1s 279us/step - loss: 1.4470e-04 - mae: 0.0077 - mse: 1.4470e-04 - val_loss: 2.0823e-04 - val_mae: 0.0076 - val_mse: 2.0823e-04\n",
      "Epoch 155/200\n",
      "2440/2440 [==============================] - 1s 303us/step - loss: 1.4472e-04 - mae: 0.0077 - mse: 1.4472e-04 - val_loss: 2.0827e-04 - val_mae: 0.0076 - val_mse: 2.0827e-04\n",
      "Epoch 156/200\n",
      "2440/2440 [==============================] - 1s 266us/step - loss: 1.4477e-04 - mae: 0.0077 - mse: 1.4477e-04 - val_loss: 2.0837e-04 - val_mae: 0.0076 - val_mse: 2.0837e-04\n",
      "Epoch 157/200\n",
      "2440/2440 [==============================] - 1s 256us/step - loss: 1.4485e-04 - mae: 0.0077 - mse: 1.4485e-04 - val_loss: 2.0857e-04 - val_mae: 0.0076 - val_mse: 2.0857e-04\n",
      "Epoch 158/200\n",
      "2440/2440 [==============================] - 1s 241us/step - loss: 1.4496e-04 - mae: 0.0077 - mse: 1.4496e-04 - val_loss: 2.0889e-04 - val_mae: 0.0076 - val_mse: 2.0889e-04\n",
      "Epoch 159/200\n",
      "2440/2440 [==============================] - 1s 251us/step - loss: 1.4511e-04 - mae: 0.0078 - mse: 1.4511e-04 - val_loss: 2.0936e-04 - val_mae: 0.0076 - val_mse: 2.0936e-04\n",
      "Epoch 160/200\n",
      "2440/2440 [==============================] - 1s 238us/step - loss: 1.4530e-04 - mae: 0.0078 - mse: 1.4530e-04 - val_loss: 2.1002e-04 - val_mae: 0.0076 - val_mse: 2.1002e-04\n",
      "Epoch 161/200\n",
      "2440/2440 [==============================] - 1s 226us/step - loss: 1.4554e-04 - mae: 0.0078 - mse: 1.4554e-04 - val_loss: 2.1091e-04 - val_mae: 0.0077 - val_mse: 2.1091e-04\n",
      "Epoch 162/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.4584e-04 - mae: 0.0078 - mse: 1.4584e-04 - val_loss: 2.1207e-04 - val_mae: 0.0077 - val_mse: 2.1207e-04\n",
      "Epoch 163/200\n",
      "2440/2440 [==============================] - 1s 235us/step - loss: 1.4621e-04 - mae: 0.0078 - mse: 1.4621e-04 - val_loss: 2.1355e-04 - val_mae: 0.0078 - val_mse: 2.1355e-04\n",
      "Epoch 164/200\n",
      "2440/2440 [==============================] - 1s 234us/step - loss: 1.4667e-04 - mae: 0.0079 - mse: 1.4667e-04 - val_loss: 2.1542e-04 - val_mae: 0.0078 - val_mse: 2.1542e-04\n",
      "Epoch 165/200\n",
      "2440/2440 [==============================] - 1s 227us/step - loss: 1.4727e-04 - mae: 0.0079 - mse: 1.4727e-04 - val_loss: 2.1788e-04 - val_mae: 0.0079 - val_mse: 2.1788e-04\n",
      "Epoch 166/200\n",
      "2440/2440 [==============================] - 1s 231us/step - loss: 1.4809e-04 - mae: 0.0080 - mse: 1.4809e-04 - val_loss: 2.2129e-04 - val_mae: 0.0081 - val_mse: 2.2129e-04\n",
      "Epoch 167/200\n",
      "2440/2440 [==============================] - 1s 226us/step - loss: 1.4926e-04 - mae: 0.0080 - mse: 1.4926e-04 - val_loss: 2.2626e-04 - val_mae: 0.0085 - val_mse: 2.2626e-04\n",
      "Epoch 168/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.5104e-04 - mae: 0.0081 - mse: 1.5104e-04 - val_loss: 2.3357e-04 - val_mae: 0.0090 - val_mse: 2.3357e-04\n",
      "Epoch 169/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 1.5390e-04 - mae: 0.0083 - mse: 1.5390e-04 - val_loss: 2.4389e-04 - val_mae: 0.0096 - val_mse: 2.4389e-04\n",
      "Epoch 170/200\n",
      "2440/2440 [==============================] - 1s 233us/step - loss: 1.5856e-04 - mae: 0.0085 - mse: 1.5856e-04 - val_loss: 2.5645e-04 - val_mae: 0.0103 - val_mse: 2.5645e-04\n",
      "Epoch 171/200\n",
      "2440/2440 [==============================] - 1s 223us/step - loss: 1.6573e-04 - mae: 0.0088 - mse: 1.6573e-04 - val_loss: 2.6786e-04 - val_mae: 0.0109 - val_mse: 2.6786e-04\n",
      "Epoch 172/200\n",
      "2440/2440 [==============================] - 1s 246us/step - loss: 1.7489e-04 - mae: 0.0093 - mse: 1.7489e-04 - val_loss: 2.6942e-04 - val_mae: 0.0108 - val_mse: 2.6942e-04\n",
      "Epoch 173/200\n",
      "2440/2440 [==============================] - 1s 234us/step - loss: 1.8106e-04 - mae: 0.0096 - mse: 1.8106e-04 - val_loss: 2.5114e-04 - val_mae: 0.0096 - val_mse: 2.5114e-04\n",
      "Epoch 174/200\n",
      "2440/2440 [==============================] - 1s 228us/step - loss: 1.7736e-04 - mae: 0.0094 - mse: 1.7736e-04 - val_loss: 2.2573e-04 - val_mae: 0.0082 - val_mse: 2.2573e-04\n",
      "Epoch 175/200\n",
      "2440/2440 [==============================] - 1s 229us/step - loss: 1.6513e-04 - mae: 0.0089 - mse: 1.6513e-04 - val_loss: 2.1405e-04 - val_mae: 0.0080 - val_mse: 2.1405e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200\n",
      "2440/2440 [==============================] - 1s 214us/step - loss: 1.4643e-04 - mae: 0.0079 - mse: 1.4643e-04 - val_loss: 2.0748e-04 - val_mae: 0.0078 - val_mse: 2.0748e-04\n",
      "Epoch 177/200\n",
      "2440/2440 [==============================] - 1s 211us/step - loss: 1.3587e-04 - mae: 0.0073 - mse: 1.3587e-04 - val_loss: 2.0584e-04 - val_mae: 0.0076 - val_mse: 2.0584e-04\n",
      "Epoch 178/200\n",
      "2440/2440 [==============================] - 1s 210us/step - loss: 1.3447e-04 - mae: 0.0073 - mse: 1.3447e-04 - val_loss: 2.0783e-04 - val_mae: 0.0077 - val_mse: 2.0783e-04\n",
      "Epoch 179/200\n",
      "2440/2440 [==============================] - 1s 212us/step - loss: 1.3484e-04 - mae: 0.0073 - mse: 1.3484e-04 - val_loss: 2.0812e-04 - val_mae: 0.0077 - val_mse: 2.0812e-04\n",
      "Epoch 180/200\n",
      "2440/2440 [==============================] - 1s 210us/step - loss: 1.3516e-04 - mae: 0.0073 - mse: 1.3516e-04 - val_loss: 2.0817e-04 - val_mae: 0.0076 - val_mse: 2.0817e-04\n",
      "Epoch 181/200\n",
      "2440/2440 [==============================] - 1s 208us/step - loss: 1.3537e-04 - mae: 0.0074 - mse: 1.3537e-04 - val_loss: 2.0834e-04 - val_mae: 0.0076 - val_mse: 2.0834e-04\n",
      "Epoch 182/200\n",
      "2440/2440 [==============================] - 1s 218us/step - loss: 1.3559e-04 - mae: 0.0074 - mse: 1.3559e-04 - val_loss: 2.0865e-04 - val_mae: 0.0076 - val_mse: 2.0865e-04\n",
      "Epoch 183/200\n",
      "2440/2440 [==============================] - 1s 209us/step - loss: 1.3582e-04 - mae: 0.0074 - mse: 1.3582e-04 - val_loss: 2.0905e-04 - val_mae: 0.0076 - val_mse: 2.0905e-04\n",
      "Epoch 184/200\n",
      "2440/2440 [==============================] - 1s 234us/step - loss: 1.3605e-04 - mae: 0.0074 - mse: 1.3605e-04 - val_loss: 2.0951e-04 - val_mae: 0.0076 - val_mse: 2.0951e-04\n",
      "Epoch 185/200\n",
      "2440/2440 [==============================] - 1s 237us/step - loss: 1.3627e-04 - mae: 0.0074 - mse: 1.3627e-04 - val_loss: 2.1003e-04 - val_mae: 0.0077 - val_mse: 2.1003e-04\n",
      "Epoch 186/200\n",
      "2440/2440 [==============================] - 1s 284us/step - loss: 1.3648e-04 - mae: 0.0075 - mse: 1.3648e-04 - val_loss: 2.1060e-04 - val_mae: 0.0077 - val_mse: 2.1060e-04\n",
      "Epoch 187/200\n",
      "2440/2440 [==============================] - 1s 306us/step - loss: 1.3668e-04 - mae: 0.0075 - mse: 1.3668e-04 - val_loss: 2.1119e-04 - val_mae: 0.0077 - val_mse: 2.1119e-04\n",
      "Epoch 188/200\n",
      "2440/2440 [==============================] - 1s 309us/step - loss: 1.3689e-04 - mae: 0.0075 - mse: 1.3689e-04 - val_loss: 2.1179e-04 - val_mae: 0.0078 - val_mse: 2.1179e-04\n",
      "Epoch 189/200\n",
      "2440/2440 [==============================] - 1s 287us/step - loss: 1.3709e-04 - mae: 0.0075 - mse: 1.3709e-04 - val_loss: 2.1238e-04 - val_mae: 0.0078 - val_mse: 2.1238e-04\n",
      "Epoch 190/200\n",
      "2440/2440 [==============================] - 1s 260us/step - loss: 1.3728e-04 - mae: 0.0075 - mse: 1.3728e-04 - val_loss: 2.1294e-04 - val_mae: 0.0079 - val_mse: 2.1294e-04\n",
      "Epoch 191/200\n",
      "2440/2440 [==============================] - 1s 299us/step - loss: 1.3747e-04 - mae: 0.0075 - mse: 1.3747e-04 - val_loss: 2.1344e-04 - val_mae: 0.0079 - val_mse: 2.1344e-04\n",
      "Epoch 192/200\n",
      "2440/2440 [==============================] - 1s 306us/step - loss: 1.3765e-04 - mae: 0.0076 - mse: 1.3765e-04 - val_loss: 2.1385e-04 - val_mae: 0.0079 - val_mse: 2.1385e-04\n",
      "Epoch 193/200\n",
      "2440/2440 [==============================] - 1s 291us/step - loss: 1.3780e-04 - mae: 0.0076 - mse: 1.3780e-04 - val_loss: 2.1415e-04 - val_mae: 0.0079 - val_mse: 2.1415e-04\n",
      "Epoch 194/200\n",
      "2440/2440 [==============================] - 1s 259us/step - loss: 1.3791e-04 - mae: 0.0076 - mse: 1.3791e-04 - val_loss: 2.1431e-04 - val_mae: 0.0080 - val_mse: 2.1431e-04\n",
      "Epoch 195/200\n",
      "2440/2440 [==============================] - 1s 222us/step - loss: 1.3799e-04 - mae: 0.0076 - mse: 1.3799e-04 - val_loss: 2.1431e-04 - val_mae: 0.0080 - val_mse: 2.1431e-04\n",
      "Epoch 196/200\n",
      "2440/2440 [==============================] - 1s 216us/step - loss: 1.3801e-04 - mae: 0.0076 - mse: 1.3801e-04 - val_loss: 2.1415e-04 - val_mae: 0.0080 - val_mse: 2.1415e-04\n",
      "Epoch 197/200\n",
      "2440/2440 [==============================] - 1s 306us/step - loss: 1.3798e-04 - mae: 0.0076 - mse: 1.3798e-04 - val_loss: 2.1385e-04 - val_mae: 0.0079 - val_mse: 2.1385e-04\n",
      "Epoch 198/200\n",
      "2440/2440 [==============================] - 1s 278us/step - loss: 1.3789e-04 - mae: 0.0076 - mse: 1.3789e-04 - val_loss: 2.1341e-04 - val_mae: 0.0079 - val_mse: 2.1341e-04\n",
      "Epoch 199/200\n",
      "2440/2440 [==============================] - 1s 257us/step - loss: 1.3775e-04 - mae: 0.0076 - mse: 1.3775e-04 - val_loss: 2.1288e-04 - val_mae: 0.0079 - val_mse: 2.1288e-04\n",
      "Epoch 200/200\n",
      "2440/2440 [==============================] - 1s 232us/step - loss: 1.3756e-04 - mae: 0.0076 - mse: 1.3756e-04 - val_loss: 2.1230e-04 - val_mae: 0.0079 - val_mse: 2.1230e-04\n"
     ]
    }
   ],
   "source": [
    "# Fit LSTM\n",
    "lstmhistory = lstm.fit(X_train_LSTM, y_train_LSTM,\n",
    "                       epochs=EPOCHS,\n",
    "                       validation_data=(X_test_LSTM, y_test_LSTM),\n",
    "                       verbose=1,\n",
    "                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1391423d0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph LSTM Error, mae and mse\n",
    "plt.plot(lstmhistory.history['loss'])\n",
    "plt.plot(lstmhistory.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Model WITHOUT Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/200\n",
      "4222/4222 [==============================] - 1s 306us/step - loss: 0.0325 - mae: 0.1143 - mse: 0.0325 - val_loss: 0.0241 - val_mae: 0.0972 - val_mse: 0.0241\n",
      "Epoch 2/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0229 - mae: 0.0835 - mse: 0.0229 - val_loss: 0.0204 - val_mae: 0.0805 - val_mse: 0.0204\n",
      "Epoch 3/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0200 - mae: 0.0719 - mse: 0.0200 - val_loss: 0.0185 - val_mae: 0.0724 - val_mse: 0.0185\n",
      "Epoch 4/200\n",
      "4222/4222 [==============================] - 1s 252us/step - loss: 0.0186 - mae: 0.0671 - mse: 0.0186 - val_loss: 0.0172 - val_mae: 0.0690 - val_mse: 0.0172\n",
      "Epoch 5/200\n",
      "4222/4222 [==============================] - 1s 243us/step - loss: 0.0174 - mae: 0.0649 - mse: 0.0174 - val_loss: 0.0158 - val_mae: 0.0702 - val_mse: 0.0158\n",
      "Epoch 6/200\n",
      "4222/4222 [==============================] - 1s 249us/step - loss: 0.0162 - mae: 0.0629 - mse: 0.0162 - val_loss: 0.0143 - val_mae: 0.0662 - val_mse: 0.0143\n",
      "Epoch 7/200\n",
      "4222/4222 [==============================] - 1s 234us/step - loss: 0.0153 - mae: 0.0603 - mse: 0.0153 - val_loss: 0.0134 - val_mae: 0.0620 - val_mse: 0.0134\n",
      "Epoch 8/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0148 - mae: 0.0592 - mse: 0.0148 - val_loss: 0.0130 - val_mae: 0.0605 - val_mse: 0.0130\n",
      "Epoch 9/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0147 - mae: 0.0593 - mse: 0.0147 - val_loss: 0.0128 - val_mae: 0.0617 - val_mse: 0.0128\n",
      "Epoch 10/200\n",
      "4222/4222 [==============================] - 1s 249us/step - loss: 0.0144 - mae: 0.0588 - mse: 0.0144 - val_loss: 0.0127 - val_mae: 0.0626 - val_mse: 0.0127\n",
      "Epoch 11/200\n",
      "4222/4222 [==============================] - 1s 247us/step - loss: 0.0141 - mae: 0.0580 - mse: 0.0141 - val_loss: 0.0125 - val_mae: 0.0619 - val_mse: 0.0125\n",
      "Epoch 12/200\n",
      "4222/4222 [==============================] - 1s 252us/step - loss: 0.0138 - mae: 0.0573 - mse: 0.0138 - val_loss: 0.0122 - val_mae: 0.0603 - val_mse: 0.0122\n",
      "Epoch 13/200\n",
      "4222/4222 [==============================] - 1s 253us/step - loss: 0.0136 - mae: 0.0565 - mse: 0.0136 - val_loss: 0.0118 - val_mae: 0.0569 - val_mse: 0.0118\n",
      "Epoch 14/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0133 - mae: 0.0555 - mse: 0.0133 - val_loss: 0.0114 - val_mae: 0.0525 - val_mse: 0.0114\n",
      "Epoch 15/200\n",
      "4222/4222 [==============================] - 1s 236us/step - loss: 0.0131 - mae: 0.0542 - mse: 0.0131 - val_loss: 0.0112 - val_mae: 0.0530 - val_mse: 0.0112\n",
      "Epoch 16/200\n",
      "4222/4222 [==============================] - 1s 240us/step - loss: 0.0129 - mae: 0.0532 - mse: 0.0129 - val_loss: 0.0110 - val_mae: 0.0529 - val_mse: 0.0110\n",
      "Epoch 17/200\n",
      "4222/4222 [==============================] - 1s 236us/step - loss: 0.0127 - mae: 0.0529 - mse: 0.0127 - val_loss: 0.0109 - val_mae: 0.0521 - val_mse: 0.0109\n",
      "Epoch 18/200\n",
      "4222/4222 [==============================] - 1s 253us/step - loss: 0.0126 - mae: 0.0526 - mse: 0.0126 - val_loss: 0.0107 - val_mae: 0.0516 - val_mse: 0.0107\n",
      "Epoch 19/200\n",
      "4222/4222 [==============================] - 1s 231us/step - loss: 0.0124 - mae: 0.0519 - mse: 0.0124 - val_loss: 0.0105 - val_mae: 0.0508 - val_mse: 0.0105\n",
      "Epoch 20/200\n",
      "4222/4222 [==============================] - 1s 239us/step - loss: 0.0122 - mae: 0.0512 - mse: 0.0122 - val_loss: 0.0104 - val_mae: 0.0494 - val_mse: 0.0104\n",
      "Epoch 21/200\n",
      "4222/4222 [==============================] - 1s 265us/step - loss: 0.0120 - mae: 0.0504 - mse: 0.0120 - val_loss: 0.0102 - val_mae: 0.0478 - val_mse: 0.0102\n",
      "Epoch 22/200\n",
      "4222/4222 [==============================] - 1s 251us/step - loss: 0.0117 - mae: 0.0498 - mse: 0.0117 - val_loss: 0.0100 - val_mae: 0.0486 - val_mse: 0.0100\n",
      "Epoch 23/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0115 - mae: 0.0493 - mse: 0.0115 - val_loss: 0.0099 - val_mae: 0.0500 - val_mse: 0.0099\n",
      "Epoch 24/200\n",
      "4222/4222 [==============================] - 1s 229us/step - loss: 0.0113 - mae: 0.0487 - mse: 0.0113 - val_loss: 0.0097 - val_mae: 0.0510 - val_mse: 0.0097\n",
      "Epoch 25/200\n",
      "4222/4222 [==============================] - 1s 239us/step - loss: 0.0110 - mae: 0.0479 - mse: 0.0110 - val_loss: 0.0095 - val_mae: 0.0507 - val_mse: 0.0095\n",
      "Epoch 26/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0108 - mae: 0.0469 - mse: 0.0108 - val_loss: 0.0093 - val_mae: 0.0499 - val_mse: 0.0093\n",
      "Epoch 27/200\n",
      "4222/4222 [==============================] - 1s 233us/step - loss: 0.0106 - mae: 0.0460 - mse: 0.0106 - val_loss: 0.0091 - val_mae: 0.0487 - val_mse: 0.0091\n",
      "Epoch 28/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0104 - mae: 0.0454 - mse: 0.0104 - val_loss: 0.0090 - val_mae: 0.0470 - val_mse: 0.0090\n",
      "Epoch 29/200\n",
      "4222/4222 [==============================] - 1s 220us/step - loss: 0.0102 - mae: 0.0446 - mse: 0.0102 - val_loss: 0.0088 - val_mae: 0.0451 - val_mse: 0.0088\n",
      "Epoch 30/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0100 - mae: 0.0442 - mse: 0.0100 - val_loss: 0.0086 - val_mae: 0.0445 - val_mse: 0.0086\n",
      "Epoch 31/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0098 - mae: 0.0441 - mse: 0.0098 - val_loss: 0.0085 - val_mae: 0.0452 - val_mse: 0.0085\n",
      "Epoch 32/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0097 - mae: 0.0441 - mse: 0.0097 - val_loss: 0.0084 - val_mae: 0.0453 - val_mse: 0.0084\n",
      "Epoch 33/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0096 - mae: 0.0439 - mse: 0.0096 - val_loss: 0.0083 - val_mae: 0.0450 - val_mse: 0.0083\n",
      "Epoch 34/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0095 - mae: 0.0437 - mse: 0.0095 - val_loss: 0.0082 - val_mae: 0.0445 - val_mse: 0.0082\n",
      "Epoch 35/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0094 - mae: 0.0434 - mse: 0.0094 - val_loss: 0.0080 - val_mae: 0.0443 - val_mse: 0.0080\n",
      "Epoch 36/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0092 - mae: 0.0430 - mse: 0.0092 - val_loss: 0.0080 - val_mae: 0.0444 - val_mse: 0.0080\n",
      "Epoch 37/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0089 - mae: 0.0426 - mse: 0.0089 - val_loss: 0.0080 - val_mae: 0.0448 - val_mse: 0.0080\n",
      "Epoch 38/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0087 - mae: 0.0421 - mse: 0.0087 - val_loss: 0.0080 - val_mae: 0.0455 - val_mse: 0.0080\n",
      "Epoch 39/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0084 - mae: 0.0416 - mse: 0.0084 - val_loss: 0.0080 - val_mae: 0.0466 - val_mse: 0.0080\n",
      "Epoch 40/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0082 - mae: 0.0411 - mse: 0.0082 - val_loss: 0.0081 - val_mae: 0.0478 - val_mse: 0.0081\n",
      "Epoch 41/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0079 - mae: 0.0404 - mse: 0.0079 - val_loss: 0.0082 - val_mae: 0.0479 - val_mse: 0.0082\n",
      "Epoch 42/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0077 - mae: 0.0398 - mse: 0.0077 - val_loss: 0.0080 - val_mae: 0.0448 - val_mse: 0.0080\n",
      "Epoch 43/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0074 - mae: 0.0389 - mse: 0.0074 - val_loss: 0.0076 - val_mae: 0.0444 - val_mse: 0.0076\n",
      "Epoch 44/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0071 - mae: 0.0380 - mse: 0.0071 - val_loss: 0.0074 - val_mae: 0.0444 - val_mse: 0.0074\n",
      "Epoch 45/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0067 - mae: 0.0375 - mse: 0.0067 - val_loss: 0.0074 - val_mae: 0.0432 - val_mse: 0.0074\n",
      "Epoch 46/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0064 - mae: 0.0368 - mse: 0.0064 - val_loss: 0.0074 - val_mae: 0.0412 - val_mse: 0.0074\n",
      "Epoch 47/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0061 - mae: 0.0360 - mse: 0.0061 - val_loss: 0.0074 - val_mae: 0.0397 - val_mse: 0.0074\n",
      "Epoch 48/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0059 - mae: 0.0353 - mse: 0.0059 - val_loss: 0.0074 - val_mae: 0.0392 - val_mse: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0056 - mae: 0.0348 - mse: 0.0056 - val_loss: 0.0075 - val_mae: 0.0392 - val_mse: 0.0075\n",
      "Epoch 50/200\n",
      "4222/4222 [==============================] - 1s 207us/step - loss: 0.0055 - mae: 0.0343 - mse: 0.0055 - val_loss: 0.0075 - val_mae: 0.0393 - val_mse: 0.0075\n",
      "Epoch 51/200\n",
      "4222/4222 [==============================] - 1s 207us/step - loss: 0.0052 - mae: 0.0337 - mse: 0.0052 - val_loss: 0.0074 - val_mae: 0.0386 - val_mse: 0.0074\n",
      "Epoch 52/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0050 - mae: 0.0331 - mse: 0.0050 - val_loss: 0.0074 - val_mae: 0.0378 - val_mse: 0.0074\n",
      "Epoch 53/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0048 - mae: 0.0326 - mse: 0.0048 - val_loss: 0.0074 - val_mae: 0.0389 - val_mse: 0.0074\n",
      "Epoch 54/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0046 - mae: 0.0321 - mse: 0.0046 - val_loss: 0.0074 - val_mae: 0.0408 - val_mse: 0.0074\n",
      "Epoch 55/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0044 - mae: 0.0313 - mse: 0.0044 - val_loss: 0.0072 - val_mae: 0.0403 - val_mse: 0.0072\n",
      "Epoch 56/200\n",
      "4222/4222 [==============================] - 1s 216us/step - loss: 0.0043 - mae: 0.0302 - mse: 0.0043 - val_loss: 0.0070 - val_mae: 0.0393 - val_mse: 0.0070\n",
      "Epoch 57/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0041 - mae: 0.0294 - mse: 0.0041 - val_loss: 0.0068 - val_mae: 0.0382 - val_mse: 0.0068\n",
      "Epoch 58/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0039 - mae: 0.0287 - mse: 0.0039 - val_loss: 0.0065 - val_mae: 0.0368 - val_mse: 0.0065\n",
      "Epoch 59/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0038 - mae: 0.0282 - mse: 0.0038 - val_loss: 0.0063 - val_mae: 0.0354 - val_mse: 0.0063\n",
      "Epoch 60/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0037 - mae: 0.0278 - mse: 0.0037 - val_loss: 0.0061 - val_mae: 0.0339 - val_mse: 0.0061\n",
      "Epoch 61/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0036 - mae: 0.0275 - mse: 0.0036 - val_loss: 0.0059 - val_mae: 0.0334 - val_mse: 0.0059\n",
      "Epoch 62/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0035 - mae: 0.0273 - mse: 0.0035 - val_loss: 0.0057 - val_mae: 0.0344 - val_mse: 0.0057\n",
      "Epoch 63/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0034 - mae: 0.0271 - mse: 0.0034 - val_loss: 0.0056 - val_mae: 0.0351 - val_mse: 0.0056\n",
      "Epoch 64/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0033 - mae: 0.0267 - mse: 0.0033 - val_loss: 0.0055 - val_mae: 0.0351 - val_mse: 0.0055\n",
      "Epoch 65/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0032 - mae: 0.0262 - mse: 0.0032 - val_loss: 0.0054 - val_mae: 0.0348 - val_mse: 0.0054\n",
      "Epoch 66/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0032 - mae: 0.0257 - mse: 0.0032 - val_loss: 0.0054 - val_mae: 0.0346 - val_mse: 0.0054\n",
      "Epoch 67/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0031 - mae: 0.0253 - mse: 0.0031 - val_loss: 0.0053 - val_mae: 0.0343 - val_mse: 0.0053\n",
      "Epoch 68/200\n",
      "4222/4222 [==============================] - 1s 207us/step - loss: 0.0031 - mae: 0.0249 - mse: 0.0031 - val_loss: 0.0052 - val_mae: 0.0340 - val_mse: 0.0052\n",
      "Epoch 69/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0030 - mae: 0.0246 - mse: 0.0030 - val_loss: 0.0051 - val_mae: 0.0336 - val_mse: 0.0051\n",
      "Epoch 70/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0029 - mae: 0.0242 - mse: 0.0029 - val_loss: 0.0050 - val_mae: 0.0330 - val_mse: 0.0050\n",
      "Epoch 71/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0029 - mae: 0.0239 - mse: 0.0029 - val_loss: 0.0049 - val_mae: 0.0324 - val_mse: 0.0049\n",
      "Epoch 72/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0028 - mae: 0.0235 - mse: 0.0028 - val_loss: 0.0047 - val_mae: 0.0317 - val_mse: 0.0047\n",
      "Epoch 73/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0028 - mae: 0.0232 - mse: 0.0028 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 74/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0027 - mae: 0.0229 - mse: 0.0027 - val_loss: 0.0043 - val_mae: 0.0302 - val_mse: 0.0043\n",
      "Epoch 75/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0027 - mae: 0.0227 - mse: 0.0027 - val_loss: 0.0041 - val_mae: 0.0294 - val_mse: 0.0041\n",
      "Epoch 76/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0026 - mae: 0.0225 - mse: 0.0026 - val_loss: 0.0039 - val_mae: 0.0286 - val_mse: 0.0039\n",
      "Epoch 77/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0026 - mae: 0.0223 - mse: 0.0026 - val_loss: 0.0037 - val_mae: 0.0279 - val_mse: 0.0037\n",
      "Epoch 78/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0025 - mae: 0.0221 - mse: 0.0025 - val_loss: 0.0036 - val_mae: 0.0274 - val_mse: 0.0036\n",
      "Epoch 79/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0025 - mae: 0.0219 - mse: 0.0025 - val_loss: 0.0036 - val_mae: 0.0271 - val_mse: 0.0036\n",
      "Epoch 80/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0025 - mae: 0.0217 - mse: 0.0025 - val_loss: 0.0035 - val_mae: 0.0267 - val_mse: 0.0035\n",
      "Epoch 81/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0024 - mae: 0.0214 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0263 - val_mse: 0.0034\n",
      "Epoch 82/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0024 - mae: 0.0211 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0258 - val_mse: 0.0034\n",
      "Epoch 83/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0023 - mae: 0.0208 - mse: 0.0023 - val_loss: 0.0033 - val_mae: 0.0254 - val_mse: 0.0033\n",
      "Epoch 84/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0023 - mae: 0.0206 - mse: 0.0023 - val_loss: 0.0032 - val_mae: 0.0249 - val_mse: 0.0032\n",
      "Epoch 85/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0022 - mae: 0.0204 - mse: 0.0022 - val_loss: 0.0031 - val_mae: 0.0246 - val_mse: 0.0031\n",
      "Epoch 86/200\n",
      "4222/4222 [==============================] - 1s 205us/step - loss: 0.0022 - mae: 0.0203 - mse: 0.0022 - val_loss: 0.0030 - val_mae: 0.0242 - val_mse: 0.0030\n",
      "Epoch 87/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0022 - mae: 0.0203 - mse: 0.0022 - val_loss: 0.0029 - val_mae: 0.0239 - val_mse: 0.0029\n",
      "Epoch 88/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0021 - mae: 0.0202 - mse: 0.0021 - val_loss: 0.0029 - val_mae: 0.0236 - val_mse: 0.0029\n",
      "Epoch 89/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0021 - mae: 0.0201 - mse: 0.0021 - val_loss: 0.0028 - val_mae: 0.0233 - val_mse: 0.0028\n",
      "Epoch 90/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0021 - mae: 0.0199 - mse: 0.0021 - val_loss: 0.0028 - val_mae: 0.0231 - val_mse: 0.0028\n",
      "Epoch 91/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0020 - mae: 0.0197 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0229 - val_mse: 0.0027\n",
      "Epoch 92/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0020 - mae: 0.0195 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0230 - val_mse: 0.0027\n",
      "Epoch 93/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0020 - mae: 0.0193 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0231 - val_mse: 0.0027\n",
      "Epoch 94/200\n",
      "4222/4222 [==============================] - 1s 206us/step - loss: 0.0020 - mae: 0.0191 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0230 - val_mse: 0.0027\n",
      "Epoch 95/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0019 - mae: 0.0189 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0229 - val_mse: 0.0027\n",
      "Epoch 96/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0019 - mae: 0.0187 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0227 - val_mse: 0.0027\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 1s 215us/step - loss: 0.0019 - mae: 0.0186 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0226 - val_mse: 0.0027\n",
      "Epoch 98/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0019 - mae: 0.0184 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0224 - val_mse: 0.0027\n",
      "Epoch 99/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0018 - mae: 0.0183 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0222 - val_mse: 0.0027\n",
      "Epoch 100/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0018 - mae: 0.0182 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0220 - val_mse: 0.0027\n",
      "Epoch 101/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0018 - mae: 0.0182 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0219 - val_mse: 0.0027\n",
      "Epoch 102/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0018 - mae: 0.0181 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0220 - val_mse: 0.0027\n",
      "Epoch 103/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0018 - mae: 0.0180 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0223 - val_mse: 0.0027\n",
      "Epoch 104/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0018 - mae: 0.0180 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0225 - val_mse: 0.0027\n",
      "Epoch 105/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0018 - mae: 0.0181 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0223 - val_mse: 0.0028\n",
      "Epoch 106/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0018 - mae: 0.0183 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0222 - val_mse: 0.0028\n",
      "Epoch 107/200\n",
      "4222/4222 [==============================] - 1s 215us/step - loss: 0.0018 - mae: 0.0185 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0218 - val_mse: 0.0028\n",
      "Epoch 108/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0018 - mae: 0.0183 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0217 - val_mse: 0.0027\n",
      "Epoch 109/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0027 - val_mae: 0.0221 - val_mse: 0.0027\n",
      "Epoch 110/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0028 - val_mae: 0.0221 - val_mse: 0.0028\n",
      "Epoch 111/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0028 - val_mae: 0.0220 - val_mse: 0.0028\n",
      "Epoch 112/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0028 - val_mae: 0.0216 - val_mse: 0.0028\n",
      "Epoch 113/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0017 - mae: 0.0178 - mse: 0.0017 - val_loss: 0.0029 - val_mae: 0.0220 - val_mse: 0.0029\n",
      "Epoch 114/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0030 - val_mae: 0.0225 - val_mse: 0.0030\n",
      "Epoch 115/200\n",
      "4222/4222 [==============================] - 1s 216us/step - loss: 0.0017 - mae: 0.0178 - mse: 0.0017 - val_loss: 0.0029 - val_mae: 0.0225 - val_mse: 0.0029\n",
      "Epoch 116/200\n",
      "4222/4222 [==============================] - 1s 235us/step - loss: 0.0016 - mae: 0.0173 - mse: 0.0016 - val_loss: 0.0028 - val_mae: 0.0229 - val_mse: 0.0028\n",
      "Epoch 117/200\n",
      "4222/4222 [==============================] - 1s 255us/step - loss: 0.0016 - mae: 0.0169 - mse: 0.0016 - val_loss: 0.0029 - val_mae: 0.0233 - val_mse: 0.0029\n",
      "Epoch 118/200\n",
      "4222/4222 [==============================] - 1s 249us/step - loss: 0.0015 - mae: 0.0169 - mse: 0.0015 - val_loss: 0.0029 - val_mae: 0.0229 - val_mse: 0.0029\n",
      "Epoch 119/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0016 - mae: 0.0176 - mse: 0.0016 - val_loss: 0.0029 - val_mae: 0.0224 - val_mse: 0.0029\n",
      "Epoch 120/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0029 - val_mae: 0.0228 - val_mse: 0.0029\n",
      "Epoch 121/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0017 - mae: 0.0178 - mse: 0.0017 - val_loss: 0.0030 - val_mae: 0.0233 - val_mse: 0.0030\n",
      "Epoch 122/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0017 - mae: 0.0181 - mse: 0.0017 - val_loss: 0.0028 - val_mae: 0.0218 - val_mse: 0.0028\n",
      "Epoch 123/200\n",
      "4222/4222 [==============================] - 1s 231us/step - loss: 0.0017 - mae: 0.0178 - mse: 0.0017 - val_loss: 0.0031 - val_mae: 0.0226 - val_mse: 0.0031\n",
      "Epoch 124/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0017 - mae: 0.0183 - mse: 0.0017 - val_loss: 0.0029 - val_mae: 0.0218 - val_mse: 0.0029\n",
      "Epoch 125/200\n",
      "4222/4222 [==============================] - 1s 234us/step - loss: 0.0018 - mae: 0.0179 - mse: 0.0018 - val_loss: 0.0031 - val_mae: 0.0229 - val_mse: 0.0031\n",
      "Epoch 126/200\n",
      "4222/4222 [==============================] - 1s 241us/step - loss: 0.0016 - mae: 0.0180 - mse: 0.0016 - val_loss: 0.0031 - val_mae: 0.0233 - val_mse: 0.0031\n",
      "Epoch 127/200\n",
      "4222/4222 [==============================] - 1s 232us/step - loss: 0.0021 - mae: 0.0187 - mse: 0.0021 - val_loss: 0.0029 - val_mae: 0.0219 - val_mse: 0.0029\n",
      "Epoch 128/200\n",
      "4222/4222 [==============================] - 1s 235us/step - loss: 0.0014 - mae: 0.0164 - mse: 0.0014 - val_loss: 0.0029 - val_mae: 0.0219 - val_mse: 0.0029\n",
      "Epoch 129/200\n",
      "4222/4222 [==============================] - 1s 237us/step - loss: 0.0018 - mae: 0.0177 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0217 - val_mse: 0.0028\n",
      "Epoch 130/200\n",
      "4222/4222 [==============================] - 1s 233us/step - loss: 0.0013 - mae: 0.0161 - mse: 0.0013 - val_loss: 0.0027 - val_mae: 0.0216 - val_mse: 0.0027\n",
      "Epoch 131/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0018 - mae: 0.0175 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0215 - val_mse: 0.0027\n",
      "Epoch 132/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0013 - mae: 0.0152 - mse: 0.0013 - val_loss: 0.0027 - val_mae: 0.0217 - val_mse: 0.0027\n",
      "Epoch 133/200\n",
      "4222/4222 [==============================] - 1s 235us/step - loss: 0.0019 - mae: 0.0182 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0219 - val_mse: 0.0027\n",
      "Epoch 134/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0013 - mae: 0.0156 - mse: 0.0013 - val_loss: 0.0026 - val_mae: 0.0212 - val_mse: 0.0026\n",
      "Epoch 135/200\n",
      "4222/4222 [==============================] - 1s 229us/step - loss: 0.0019 - mae: 0.0176 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0221 - val_mse: 0.0027\n",
      "Epoch 136/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0013 - mae: 0.0154 - mse: 0.0013 - val_loss: 0.0027 - val_mae: 0.0217 - val_mse: 0.0027\n",
      "Epoch 137/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0019 - mae: 0.0182 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0214 - val_mse: 0.0025\n",
      "Epoch 138/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0013 - mae: 0.0158 - mse: 0.0013 - val_loss: 0.0026 - val_mae: 0.0217 - val_mse: 0.0026\n",
      "Epoch 139/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0018 - mae: 0.0173 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0219 - val_mse: 0.0028\n",
      "Epoch 140/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0012 - mae: 0.0149 - mse: 0.0012 - val_loss: 0.0026 - val_mae: 0.0214 - val_mse: 0.0026\n",
      "Epoch 141/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0018 - mae: 0.0171 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0228 - val_mse: 0.0028\n",
      "Epoch 142/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0012 - mae: 0.0151 - mse: 0.0012 - val_loss: 0.0027 - val_mae: 0.0215 - val_mse: 0.0027\n",
      "Epoch 143/200\n",
      "4222/4222 [==============================] - 1s 232us/step - loss: 0.0018 - mae: 0.0173 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0217 - val_mse: 0.0028\n",
      "Epoch 144/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0012 - mae: 0.0147 - mse: 0.0012 - val_loss: 0.0027 - val_mae: 0.0216 - val_mse: 0.0027\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0017 - mae: 0.0172 - mse: 0.0017 - val_loss: 0.0029 - val_mae: 0.0226 - val_mse: 0.0029\n",
      "Epoch 146/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0012 - mae: 0.0150 - mse: 0.0012 - val_loss: 0.0027 - val_mae: 0.0216 - val_mse: 0.0027\n",
      "Epoch 147/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0019 - mae: 0.0176 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0218 - val_mse: 0.0028\n",
      "Epoch 148/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0012 - mae: 0.0145 - mse: 0.0012 - val_loss: 0.0026 - val_mae: 0.0212 - val_mse: 0.0026\n",
      "Epoch 149/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0018 - mae: 0.0179 - mse: 0.0018 - val_loss: 0.0026 - val_mae: 0.0208 - val_mse: 0.0026\n",
      "Epoch 150/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0013 - mae: 0.0152 - mse: 0.0013 - val_loss: 0.0025 - val_mae: 0.0212 - val_mse: 0.0025\n",
      "Epoch 151/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0017 - mae: 0.0168 - mse: 0.0017 - val_loss: 0.0026 - val_mae: 0.0212 - val_mse: 0.0026\n",
      "Epoch 152/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0012 - mae: 0.0147 - mse: 0.0012 - val_loss: 0.0025 - val_mae: 0.0208 - val_mse: 0.0025\n",
      "Epoch 153/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0018 - mae: 0.0171 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0215 - val_mse: 0.0027\n",
      "Epoch 154/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0013 - mae: 0.0151 - mse: 0.0013 - val_loss: 0.0024 - val_mae: 0.0209 - val_mse: 0.0024\n",
      "Epoch 155/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0017 - mae: 0.0170 - mse: 0.0017 - val_loss: 0.0025 - val_mae: 0.0210 - val_mse: 0.0025\n",
      "Epoch 156/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0012 - mae: 0.0145 - mse: 0.0012 - val_loss: 0.0024 - val_mae: 0.0213 - val_mse: 0.0024\n",
      "Epoch 157/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0018 - mae: 0.0172 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0222 - val_mse: 0.0027\n",
      "Epoch 158/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0013 - mae: 0.0152 - mse: 0.0013 - val_loss: 0.0023 - val_mae: 0.0216 - val_mse: 0.0023\n",
      "Epoch 159/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0018 - mae: 0.0172 - mse: 0.0018 - val_loss: 0.0026 - val_mae: 0.0206 - val_mse: 0.0026\n",
      "Epoch 160/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0013 - mae: 0.0155 - mse: 0.0013 - val_loss: 0.0024 - val_mae: 0.0217 - val_mse: 0.0024\n",
      "Epoch 161/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0019 - mae: 0.0180 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0200 - val_mse: 0.0024\n",
      "Epoch 162/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0013 - mae: 0.0156 - mse: 0.0013 - val_loss: 0.0021 - val_mae: 0.0201 - val_mse: 0.0021\n",
      "Epoch 163/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0018 - mae: 0.0173 - mse: 0.0018 - val_loss: 0.0023 - val_mae: 0.0196 - val_mse: 0.0023\n",
      "Epoch 164/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0015 - mae: 0.0172 - mse: 0.0015 - val_loss: 0.0020 - val_mae: 0.0195 - val_mse: 0.0020\n",
      "Epoch 165/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0017 - mae: 0.0168 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0203 - val_mse: 0.0023\n",
      "Epoch 166/200\n",
      "4222/4222 [==============================] - 1s 207us/step - loss: 0.0012 - mae: 0.0140 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0196 - val_mse: 0.0021\n",
      "Epoch 167/200\n",
      "4222/4222 [==============================] - 1s 206us/step - loss: 0.0018 - mae: 0.0171 - mse: 0.0018 - val_loss: 0.0023 - val_mae: 0.0194 - val_mse: 0.0023\n",
      "Epoch 168/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0012 - mae: 0.0146 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0191 - val_mse: 0.0021\n",
      "Epoch 169/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0017 - mae: 0.0167 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0190 - val_mse: 0.0023\n",
      "Epoch 170/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0012 - mae: 0.0138 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0198 - val_mse: 0.0021\n",
      "Epoch 171/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0018 - mae: 0.0170 - mse: 0.0018 - val_loss: 0.0024 - val_mae: 0.0193 - val_mse: 0.0024\n",
      "Epoch 172/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0012 - mae: 0.0144 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0191 - val_mse: 0.0021\n",
      "Epoch 173/200\n",
      "4222/4222 [==============================] - 1s 215us/step - loss: 0.0017 - mae: 0.0164 - mse: 0.0017 - val_loss: 0.0024 - val_mae: 0.0187 - val_mse: 0.0024\n",
      "Epoch 174/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0013 - mae: 0.0150 - mse: 0.0013 - val_loss: 0.0022 - val_mae: 0.0198 - val_mse: 0.0022\n",
      "Epoch 175/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0018 - mae: 0.0170 - mse: 0.0018 - val_loss: 0.0022 - val_mae: 0.0189 - val_mse: 0.0022\n",
      "Epoch 176/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0011 - mae: 0.0142 - mse: 0.0011 - val_loss: 0.0021 - val_mae: 0.0199 - val_mse: 0.0021\n",
      "Epoch 177/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0019 - mae: 0.0173 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0187 - val_mse: 0.0022\n",
      "Epoch 178/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0012 - mae: 0.0145 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0189 - val_mse: 0.0021\n",
      "Epoch 179/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0017 - mae: 0.0163 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0185 - val_mse: 0.0023\n",
      "Epoch 180/200\n",
      "4222/4222 [==============================] - 1s 215us/step - loss: 0.0012 - mae: 0.0146 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0193 - val_mse: 0.0021\n",
      "Epoch 181/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0017 - mae: 0.0163 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0185 - val_mse: 0.0023\n",
      "Epoch 182/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0013 - mae: 0.0154 - mse: 0.0013 - val_loss: 0.0021 - val_mae: 0.0193 - val_mse: 0.0021\n",
      "Epoch 183/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0017 - mae: 0.0166 - mse: 0.0017 - val_loss: 0.0024 - val_mae: 0.0186 - val_mse: 0.0024\n",
      "Epoch 184/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0012 - mae: 0.0143 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0191 - val_mse: 0.0021\n",
      "Epoch 185/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0019 - mae: 0.0178 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0184 - val_mse: 0.0021\n",
      "Epoch 186/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0014 - mae: 0.0151 - mse: 0.0014 - val_loss: 0.0021 - val_mae: 0.0188 - val_mse: 0.0021\n",
      "Epoch 187/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0016 - mae: 0.0158 - mse: 0.0016 - val_loss: 0.0024 - val_mae: 0.0190 - val_mse: 0.0024\n",
      "Epoch 188/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0013 - mae: 0.0155 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0189 - val_mse: 0.0020\n",
      "Epoch 189/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0011 - mae: 0.0135 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0185 - val_mse: 0.0020\n",
      "Epoch 190/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0017 - mae: 0.0162 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0191 - val_mse: 0.0023\n",
      "Epoch 191/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0012 - mae: 0.0144 - mse: 0.0012 - val_loss: 0.0019 - val_mae: 0.0184 - val_mse: 0.0019\n",
      "Epoch 192/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0016 - mae: 0.0160 - mse: 0.0016 - val_loss: 0.0023 - val_mae: 0.0198 - val_mse: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0013 - mae: 0.0153 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0184 - val_mse: 0.0020\n",
      "Epoch 194/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0011 - mae: 0.0144 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0199 - val_mse: 0.0020\n",
      "Epoch 195/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0019 - mae: 0.0179 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0186 - val_mse: 0.0020\n",
      "Epoch 196/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0013 - mae: 0.0148 - mse: 0.0013 - val_loss: 0.0021 - val_mae: 0.0185 - val_mse: 0.0021\n",
      "Epoch 197/200\n",
      "4222/4222 [==============================] - 1s 217us/step - loss: 0.0016 - mae: 0.0158 - mse: 0.0016 - val_loss: 0.0022 - val_mae: 0.0188 - val_mse: 0.0022\n",
      "Epoch 198/200\n",
      "4222/4222 [==============================] - 1s 217us/step - loss: 0.0011 - mae: 0.0140 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0195 - val_mse: 0.0020\n",
      "Epoch 199/200\n",
      "4222/4222 [==============================] - 1s 215us/step - loss: 0.0017 - mae: 0.0166 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0194 - val_mse: 0.0023\n",
      "Epoch 200/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0018 - mae: 0.0174 - mse: 0.0018 - val_loss: 0.0021 - val_mae: 0.0189 - val_mse: 0.0021\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_LSTM_nomob, y_LSTM_nomob = get_LSTM_states_dataset(state_cases_df, n_steps=N_STEPS)\n",
    "X_train_LSTM_nomob, X_test_LSTM_nomob, y_train_LSTM_nomob, y_test_LSTM_nomob = train_test_split(X_LSTM_nomob, y_LSTM_nomob, test_size=SPLIT, shuffle=False)\n",
    "\n",
    "# Set up model\n",
    "n_lstm_features = X_train_LSTM_nomob.shape[2]\n",
    "lstm_nomob = get_lstm(N_STEPS, n_lstm_features)\n",
    "\n",
    "# Fit LSTM\n",
    "lstm_nomob_history = lstm_nomob.fit(X_train_LSTM_nomob, y_train_LSTM_nomob,\n",
    "                                     epochs=EPOCHS,\n",
    "                                     validation_data=(X_test_LSTM_nomob, y_test_LSTM_nomob),\n",
    "                                     verbose=1,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13a1f3050>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph LSTM Error, mae and mse\n",
    "plt.plot(lstm_nomob_history.history['loss'])\n",
    "plt.plot(lstm_nomob_history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STACKED LSTM Model with Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Stacked LSTM, Boo's model\n",
    "def get_stacked_lstm(n_steps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    model.add(LSTM(128, input_shape=(n_steps, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss='mse', metrics=['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "n_lstm_features = X_train_LSTM.shape[2]\n",
    "slstm = get_stacked_lstm(N_STEPS, n_lstm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2440 samples, validate on 610 samples\n",
      "Epoch 1/200\n",
      "2440/2440 [==============================] - 2s 748us/step - loss: 0.0191 - mae: 0.0854 - mse: 0.0191 - val_loss: 0.0025 - val_mae: 0.0332 - val_mse: 0.0025\n",
      "Epoch 2/200\n",
      "2440/2440 [==============================] - 1s 442us/step - loss: 0.0026 - mae: 0.0369 - mse: 0.0026 - val_loss: 0.0021 - val_mae: 0.0330 - val_mse: 0.0021\n",
      "Epoch 3/200\n",
      "2440/2440 [==============================] - 1s 452us/step - loss: 0.0024 - mae: 0.0356 - mse: 0.0024 - val_loss: 0.0018 - val_mae: 0.0324 - val_mse: 0.0018\n",
      "Epoch 4/200\n",
      "2440/2440 [==============================] - 1s 456us/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0019 - val_loss: 0.0016 - val_mae: 0.0314 - val_mse: 0.0016\n",
      "Epoch 5/200\n",
      "2440/2440 [==============================] - 1s 526us/step - loss: 0.0016 - mae: 0.0298 - mse: 0.0016 - val_loss: 0.0013 - val_mae: 0.0260 - val_mse: 0.0013\n",
      "Epoch 6/200\n",
      "2440/2440 [==============================] - 1s 488us/step - loss: 0.0015 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.0011 - val_mae: 0.0216 - val_mse: 0.0011\n",
      "Epoch 7/200\n",
      "2440/2440 [==============================] - 1s 471us/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0015 - val_loss: 0.0011 - val_mae: 0.0214 - val_mse: 0.0011\n",
      "Epoch 8/200\n",
      "2440/2440 [==============================] - 1s 445us/step - loss: 0.0014 - mae: 0.0279 - mse: 0.0014 - val_loss: 0.0011 - val_mae: 0.0207 - val_mse: 0.0011\n",
      "Epoch 9/200\n",
      "2440/2440 [==============================] - 1s 445us/step - loss: 0.0013 - mae: 0.0258 - mse: 0.0013 - val_loss: 9.6802e-04 - val_mae: 0.0194 - val_mse: 9.6802e-04\n",
      "Epoch 10/200\n",
      "2440/2440 [==============================] - 1s 531us/step - loss: 0.0011 - mae: 0.0241 - mse: 0.0011 - val_loss: 9.0330e-04 - val_mae: 0.0186 - val_mse: 9.0330e-04\n",
      "Epoch 11/200\n",
      "2440/2440 [==============================] - 1s 508us/step - loss: 0.0010 - mae: 0.0231 - mse: 0.0010 - val_loss: 8.5027e-04 - val_mae: 0.0179 - val_mse: 8.5027e-04\n",
      "Epoch 12/200\n",
      "2440/2440 [==============================] - 1s 456us/step - loss: 9.8850e-04 - mae: 0.0224 - mse: 9.8850e-04 - val_loss: 8.0050e-04 - val_mae: 0.0173 - val_mse: 8.0050e-04\n",
      "Epoch 13/200\n",
      "2440/2440 [==============================] - 1s 454us/step - loss: 9.3095e-04 - mae: 0.0217 - mse: 9.3095e-04 - val_loss: 7.5220e-04 - val_mae: 0.0167 - val_mse: 7.5220e-04\n",
      "Epoch 14/200\n",
      "2440/2440 [==============================] - 1s 541us/step - loss: 8.7347e-04 - mae: 0.0210 - mse: 8.7347e-04 - val_loss: 7.0653e-04 - val_mae: 0.0162 - val_mse: 7.0653e-04\n",
      "Epoch 15/200\n",
      "2440/2440 [==============================] - 1s 526us/step - loss: 8.1863e-04 - mae: 0.0203 - mse: 8.1863e-04 - val_loss: 6.6414e-04 - val_mae: 0.0157 - val_mse: 6.6414e-04\n",
      "Epoch 16/200\n",
      "2440/2440 [==============================] - 1s 485us/step - loss: 7.6636e-04 - mae: 0.0196 - mse: 7.6636e-04 - val_loss: 6.2482e-04 - val_mae: 0.0153 - val_mse: 6.2482e-04\n",
      "Epoch 17/200\n",
      "2440/2440 [==============================] - 1s 461us/step - loss: 7.1575e-04 - mae: 0.0189 - mse: 7.1575e-04 - val_loss: 5.8783e-04 - val_mae: 0.0149 - val_mse: 5.8783e-04\n",
      "Epoch 18/200\n",
      "2440/2440 [==============================] - 1s 461us/step - loss: 6.6641e-04 - mae: 0.0181 - mse: 6.6641e-04 - val_loss: 5.5219e-04 - val_mae: 0.0144 - val_mse: 5.5219e-04\n",
      "Epoch 19/200\n",
      "2440/2440 [==============================] - 1s 466us/step - loss: 6.1878e-04 - mae: 0.0173 - mse: 6.1878e-04 - val_loss: 5.1759e-04 - val_mae: 0.0140 - val_mse: 5.1759e-04\n",
      "Epoch 20/200\n",
      "2440/2440 [==============================] - 1s 460us/step - loss: 5.7400e-04 - mae: 0.0165 - mse: 5.7400e-04 - val_loss: 4.8585e-04 - val_mae: 0.0136 - val_mse: 4.8585e-04\n",
      "Epoch 21/200\n",
      "2440/2440 [==============================] - 1s 465us/step - loss: 5.3324e-04 - mae: 0.0159 - mse: 5.3324e-04 - val_loss: 4.6072e-04 - val_mae: 0.0136 - val_mse: 4.6072e-04\n",
      "Epoch 22/200\n",
      "2440/2440 [==============================] - 1s 493us/step - loss: 4.9709e-04 - mae: 0.0154 - mse: 4.9709e-04 - val_loss: 4.4512e-04 - val_mae: 0.0140 - val_mse: 4.4512e-04\n",
      "Epoch 23/200\n",
      "2440/2440 [==============================] - 1s 566us/step - loss: 4.6654e-04 - mae: 0.0149 - mse: 4.6654e-04 - val_loss: 4.3795e-04 - val_mae: 0.0146 - val_mse: 4.3795e-04\n",
      "Epoch 24/200\n",
      "2440/2440 [==============================] - 1s 409us/step - loss: 4.4404e-04 - mae: 0.0146 - mse: 4.4404e-04 - val_loss: 4.3179e-04 - val_mae: 0.0150 - val_mse: 4.3179e-04\n",
      "Epoch 25/200\n",
      "2440/2440 [==============================] - 1s 388us/step - loss: 4.3143e-04 - mae: 0.0145 - mse: 4.3143e-04 - val_loss: 4.1825e-04 - val_mae: 0.0150 - val_mse: 4.1825e-04\n",
      "Epoch 26/200\n",
      "2440/2440 [==============================] - 1s 383us/step - loss: 4.2775e-04 - mae: 0.0145 - mse: 4.2775e-04 - val_loss: 3.9638e-04 - val_mae: 0.0144 - val_mse: 3.9638e-04\n",
      "Epoch 27/200\n",
      "2440/2440 [==============================] - 1s 396us/step - loss: 4.3165e-04 - mae: 0.0146 - mse: 4.3165e-04 - val_loss: 3.6797e-04 - val_mae: 0.0134 - val_mse: 3.6797e-04\n",
      "Epoch 28/200\n",
      "2440/2440 [==============================] - 1s 392us/step - loss: 4.4300e-04 - mae: 0.0149 - mse: 4.4300e-04 - val_loss: 3.3828e-04 - val_mae: 0.0120 - val_mse: 3.3828e-04\n",
      "Epoch 29/200\n",
      "2440/2440 [==============================] - 1s 391us/step - loss: 4.5631e-04 - mae: 0.0152 - mse: 4.5631e-04 - val_loss: 3.2115e-04 - val_mae: 0.0111 - val_mse: 3.2115e-04\n",
      "Epoch 30/200\n",
      "2440/2440 [==============================] - 1s 393us/step - loss: 4.5698e-04 - mae: 0.0153 - mse: 4.5698e-04 - val_loss: 3.1892e-04 - val_mae: 0.0111 - val_mse: 3.1892e-04\n",
      "Epoch 31/200\n",
      "2440/2440 [==============================] - 1s 392us/step - loss: 4.3091e-04 - mae: 0.0148 - mse: 4.3091e-04 - val_loss: 3.2600e-04 - val_mae: 0.0114 - val_mse: 3.2600e-04\n",
      "Epoch 32/200\n",
      "2440/2440 [==============================] - 1s 387us/step - loss: 3.8924e-04 - mae: 0.0139 - mse: 3.8924e-04 - val_loss: 3.2433e-04 - val_mae: 0.0113 - val_mse: 3.2433e-04\n",
      "Epoch 33/200\n",
      "2440/2440 [==============================] - 1s 399us/step - loss: 3.5419e-04 - mae: 0.0132 - mse: 3.5419e-04 - val_loss: 3.1264e-04 - val_mae: 0.0109 - val_mse: 3.1264e-04\n",
      "Epoch 34/200\n",
      "2440/2440 [==============================] - 1s 538us/step - loss: 3.2866e-04 - mae: 0.0126 - mse: 3.2866e-04 - val_loss: 2.9961e-04 - val_mae: 0.0105 - val_mse: 2.9961e-04\n",
      "Epoch 35/200\n",
      "2440/2440 [==============================] - 1s 487us/step - loss: 3.1050e-04 - mae: 0.0123 - mse: 3.1050e-04 - val_loss: 2.8857e-04 - val_mae: 0.0102 - val_mse: 2.8857e-04\n",
      "Epoch 36/200\n",
      "2440/2440 [==============================] - 1s 472us/step - loss: 2.9756e-04 - mae: 0.0120 - mse: 2.9756e-04 - val_loss: 2.7998e-04 - val_mae: 0.0099 - val_mse: 2.7998e-04\n",
      "Epoch 37/200\n",
      "2440/2440 [==============================] - 1s 478us/step - loss: 2.8772e-04 - mae: 0.0118 - mse: 2.8772e-04 - val_loss: 2.7338e-04 - val_mae: 0.0097 - val_mse: 2.7338e-04\n",
      "Epoch 38/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 2.7938e-04 - mae: 0.0117 - mse: 2.7938e-04 - val_loss: 2.6812e-04 - val_mae: 0.0095 - val_mse: 2.6812e-04\n",
      "Epoch 39/200\n",
      "2440/2440 [==============================] - 1s 480us/step - loss: 2.7166e-04 - mae: 0.0115 - mse: 2.7166e-04 - val_loss: 2.6367e-04 - val_mae: 0.0094 - val_mse: 2.6367e-04\n",
      "Epoch 40/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 2.6428e-04 - mae: 0.0113 - mse: 2.6428e-04 - val_loss: 2.5969e-04 - val_mae: 0.0092 - val_mse: 2.5969e-04\n",
      "Epoch 41/200\n",
      "2440/2440 [==============================] - 1s 466us/step - loss: 2.5722e-04 - mae: 0.0112 - mse: 2.5722e-04 - val_loss: 2.5602e-04 - val_mae: 0.0091 - val_mse: 2.5602e-04\n",
      "Epoch 42/200\n",
      "2440/2440 [==============================] - 1s 480us/step - loss: 2.5060e-04 - mae: 0.0110 - mse: 2.5060e-04 - val_loss: 2.5260e-04 - val_mae: 0.0090 - val_mse: 2.5260e-04\n",
      "Epoch 43/200\n",
      "2440/2440 [==============================] - 1s 465us/step - loss: 2.4452e-04 - mae: 0.0109 - mse: 2.4452e-04 - val_loss: 2.4944e-04 - val_mae: 0.0089 - val_mse: 2.4944e-04\n",
      "Epoch 44/200\n",
      "2440/2440 [==============================] - 1s 466us/step - loss: 2.3904e-04 - mae: 0.0107 - mse: 2.3904e-04 - val_loss: 2.4657e-04 - val_mae: 0.0088 - val_mse: 2.4657e-04\n",
      "Epoch 45/200\n",
      "2440/2440 [==============================] - 1s 474us/step - loss: 2.3422e-04 - mae: 0.0106 - mse: 2.3422e-04 - val_loss: 2.4402e-04 - val_mae: 0.0087 - val_mse: 2.4402e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200\n",
      "2440/2440 [==============================] - 1s 431us/step - loss: 2.3007e-04 - mae: 0.0105 - mse: 2.3007e-04 - val_loss: 2.4178e-04 - val_mae: 0.0086 - val_mse: 2.4178e-04\n",
      "Epoch 47/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 2.2658e-04 - mae: 0.0104 - mse: 2.2658e-04 - val_loss: 2.3985e-04 - val_mae: 0.0085 - val_mse: 2.3985e-04\n",
      "Epoch 48/200\n",
      "2440/2440 [==============================] - 1s 433us/step - loss: 2.2368e-04 - mae: 0.0104 - mse: 2.2368e-04 - val_loss: 2.3821e-04 - val_mae: 0.0085 - val_mse: 2.3821e-04\n",
      "Epoch 49/200\n",
      "2440/2440 [==============================] - 1s 436us/step - loss: 2.2132e-04 - mae: 0.0103 - mse: 2.2132e-04 - val_loss: 2.3681e-04 - val_mae: 0.0085 - val_mse: 2.3681e-04\n",
      "Epoch 50/200\n",
      "2440/2440 [==============================] - 1s 431us/step - loss: 2.1941e-04 - mae: 0.0103 - mse: 2.1941e-04 - val_loss: 2.3561e-04 - val_mae: 0.0084 - val_mse: 2.3561e-04\n",
      "Epoch 51/200\n",
      "2440/2440 [==============================] - 1s 430us/step - loss: 2.1788e-04 - mae: 0.0102 - mse: 2.1788e-04 - val_loss: 2.3458e-04 - val_mae: 0.0084 - val_mse: 2.3458e-04\n",
      "Epoch 52/200\n",
      "2440/2440 [==============================] - 1s 440us/step - loss: 2.1664e-04 - mae: 0.0102 - mse: 2.1664e-04 - val_loss: 2.3368e-04 - val_mae: 0.0084 - val_mse: 2.3368e-04\n",
      "Epoch 53/200\n",
      "2440/2440 [==============================] - 1s 428us/step - loss: 2.1563e-04 - mae: 0.0102 - mse: 2.1563e-04 - val_loss: 2.3288e-04 - val_mae: 0.0084 - val_mse: 2.3288e-04\n",
      "Epoch 54/200\n",
      "2440/2440 [==============================] - 1s 428us/step - loss: 2.1478e-04 - mae: 0.0101 - mse: 2.1478e-04 - val_loss: 2.3217e-04 - val_mae: 0.0084 - val_mse: 2.3217e-04\n",
      "Epoch 55/200\n",
      "2440/2440 [==============================] - 1s 439us/step - loss: 2.1404e-04 - mae: 0.0101 - mse: 2.1404e-04 - val_loss: 2.3154e-04 - val_mae: 0.0085 - val_mse: 2.3154e-04\n",
      "Epoch 56/200\n",
      "2440/2440 [==============================] - 1s 437us/step - loss: 2.1336e-04 - mae: 0.0101 - mse: 2.1336e-04 - val_loss: 2.3097e-04 - val_mae: 0.0085 - val_mse: 2.3097e-04\n",
      "Epoch 57/200\n",
      "2440/2440 [==============================] - 1s 433us/step - loss: 2.1271e-04 - mae: 0.0101 - mse: 2.1271e-04 - val_loss: 2.3047e-04 - val_mae: 0.0085 - val_mse: 2.3047e-04\n",
      "Epoch 58/200\n",
      "2440/2440 [==============================] - 1s 432us/step - loss: 2.1207e-04 - mae: 0.0100 - mse: 2.1207e-04 - val_loss: 2.3004e-04 - val_mae: 0.0086 - val_mse: 2.3004e-04\n",
      "Epoch 59/200\n",
      "2440/2440 [==============================] - 1s 432us/step - loss: 2.1142e-04 - mae: 0.0100 - mse: 2.1142e-04 - val_loss: 2.2966e-04 - val_mae: 0.0086 - val_mse: 2.2966e-04\n",
      "Epoch 60/200\n",
      "2440/2440 [==============================] - 1s 430us/step - loss: 2.1075e-04 - mae: 0.0100 - mse: 2.1075e-04 - val_loss: 2.2936e-04 - val_mae: 0.0086 - val_mse: 2.2936e-04\n",
      "Epoch 61/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 2.1005e-04 - mae: 0.0100 - mse: 2.1005e-04 - val_loss: 2.2911e-04 - val_mae: 0.0087 - val_mse: 2.2911e-04\n",
      "Epoch 62/200\n",
      "2440/2440 [==============================] - 1s 433us/step - loss: 2.0934e-04 - mae: 0.0099 - mse: 2.0934e-04 - val_loss: 2.2893e-04 - val_mae: 0.0087 - val_mse: 2.2893e-04\n",
      "Epoch 63/200\n",
      "2440/2440 [==============================] - 1s 438us/step - loss: 2.0861e-04 - mae: 0.0099 - mse: 2.0861e-04 - val_loss: 2.2881e-04 - val_mae: 0.0087 - val_mse: 2.2881e-04\n",
      "Epoch 64/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 2.0786e-04 - mae: 0.0099 - mse: 2.0786e-04 - val_loss: 2.2875e-04 - val_mae: 0.0088 - val_mse: 2.2875e-04\n",
      "Epoch 65/200\n",
      "2440/2440 [==============================] - 1s 441us/step - loss: 2.0711e-04 - mae: 0.0099 - mse: 2.0711e-04 - val_loss: 2.2875e-04 - val_mae: 0.0088 - val_mse: 2.2875e-04\n",
      "Epoch 66/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 2.0634e-04 - mae: 0.0098 - mse: 2.0634e-04 - val_loss: 2.2880e-04 - val_mae: 0.0089 - val_mse: 2.2880e-04\n",
      "Epoch 67/200\n",
      "2440/2440 [==============================] - 1s 432us/step - loss: 2.0557e-04 - mae: 0.0098 - mse: 2.0557e-04 - val_loss: 2.2889e-04 - val_mae: 0.0089 - val_mse: 2.2889e-04\n",
      "Epoch 68/200\n",
      "2440/2440 [==============================] - 1s 438us/step - loss: 2.0480e-04 - mae: 0.0098 - mse: 2.0480e-04 - val_loss: 2.2903e-04 - val_mae: 0.0089 - val_mse: 2.2903e-04\n",
      "Epoch 69/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 2.0404e-04 - mae: 0.0098 - mse: 2.0404e-04 - val_loss: 2.2920e-04 - val_mae: 0.0090 - val_mse: 2.2920e-04\n",
      "Epoch 70/200\n",
      "2440/2440 [==============================] - 1s 434us/step - loss: 2.0327e-04 - mae: 0.0097 - mse: 2.0327e-04 - val_loss: 2.2940e-04 - val_mae: 0.0090 - val_mse: 2.2940e-04\n",
      "Epoch 71/200\n",
      "2440/2440 [==============================] - 1s 424us/step - loss: 2.0252e-04 - mae: 0.0097 - mse: 2.0252e-04 - val_loss: 2.2964e-04 - val_mae: 0.0091 - val_mse: 2.2964e-04\n",
      "Epoch 72/200\n",
      "2440/2440 [==============================] - 1s 438us/step - loss: 2.0178e-04 - mae: 0.0097 - mse: 2.0178e-04 - val_loss: 2.2990e-04 - val_mae: 0.0091 - val_mse: 2.2990e-04\n",
      "Epoch 73/200\n",
      "2440/2440 [==============================] - 1s 436us/step - loss: 2.0105e-04 - mae: 0.0097 - mse: 2.0105e-04 - val_loss: 2.3018e-04 - val_mae: 0.0091 - val_mse: 2.3018e-04\n",
      "Epoch 74/200\n",
      "2440/2440 [==============================] - 1s 432us/step - loss: 2.0034e-04 - mae: 0.0096 - mse: 2.0034e-04 - val_loss: 2.3049e-04 - val_mae: 0.0092 - val_mse: 2.3049e-04\n",
      "Epoch 75/200\n",
      "2440/2440 [==============================] - 1s 430us/step - loss: 1.9966e-04 - mae: 0.0096 - mse: 1.9966e-04 - val_loss: 2.3081e-04 - val_mae: 0.0092 - val_mse: 2.3081e-04\n",
      "Epoch 76/200\n",
      "2440/2440 [==============================] - 1s 443us/step - loss: 1.9901e-04 - mae: 0.0096 - mse: 1.9901e-04 - val_loss: 2.3114e-04 - val_mae: 0.0093 - val_mse: 2.3114e-04\n",
      "Epoch 77/200\n",
      "2440/2440 [==============================] - 1s 432us/step - loss: 1.9840e-04 - mae: 0.0096 - mse: 1.9840e-04 - val_loss: 2.3150e-04 - val_mae: 0.0093 - val_mse: 2.3150e-04\n",
      "Epoch 78/200\n",
      "2440/2440 [==============================] - 1s 438us/step - loss: 1.9784e-04 - mae: 0.0096 - mse: 1.9784e-04 - val_loss: 2.3187e-04 - val_mae: 0.0093 - val_mse: 2.3187e-04\n",
      "Epoch 79/200\n",
      "2440/2440 [==============================] - 1s 436us/step - loss: 1.9733e-04 - mae: 0.0095 - mse: 1.9733e-04 - val_loss: 2.3227e-04 - val_mae: 0.0094 - val_mse: 2.3227e-04\n",
      "Epoch 80/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 1.9688e-04 - mae: 0.0095 - mse: 1.9688e-04 - val_loss: 2.3271e-04 - val_mae: 0.0094 - val_mse: 2.3271e-04\n",
      "Epoch 81/200\n",
      "2440/2440 [==============================] - 1s 432us/step - loss: 1.9650e-04 - mae: 0.0095 - mse: 1.9650e-04 - val_loss: 2.3319e-04 - val_mae: 0.0095 - val_mse: 2.3319e-04\n",
      "Epoch 82/200\n",
      "2440/2440 [==============================] - 1s 438us/step - loss: 1.9619e-04 - mae: 0.0095 - mse: 1.9619e-04 - val_loss: 2.3375e-04 - val_mae: 0.0095 - val_mse: 2.3375e-04\n",
      "Epoch 83/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 1.9596e-04 - mae: 0.0095 - mse: 1.9596e-04 - val_loss: 2.3440e-04 - val_mae: 0.0096 - val_mse: 2.3440e-04\n",
      "Epoch 84/200\n",
      "2440/2440 [==============================] - 1s 433us/step - loss: 1.9582e-04 - mae: 0.0095 - mse: 1.9582e-04 - val_loss: 2.3518e-04 - val_mae: 0.0096 - val_mse: 2.3518e-04\n",
      "Epoch 85/200\n",
      "2440/2440 [==============================] - 1s 439us/step - loss: 1.9577e-04 - mae: 0.0095 - mse: 1.9577e-04 - val_loss: 2.3613e-04 - val_mae: 0.0097 - val_mse: 2.3613e-04\n",
      "Epoch 86/200\n",
      "2440/2440 [==============================] - 1s 431us/step - loss: 1.9584e-04 - mae: 0.0095 - mse: 1.9584e-04 - val_loss: 2.3729e-04 - val_mae: 0.0098 - val_mse: 2.3729e-04\n",
      "Epoch 87/200\n",
      "2440/2440 [==============================] - 1s 443us/step - loss: 1.9603e-04 - mae: 0.0095 - mse: 1.9603e-04 - val_loss: 2.3872e-04 - val_mae: 0.0099 - val_mse: 2.3872e-04\n",
      "Epoch 88/200\n",
      "2440/2440 [==============================] - 1s 515us/step - loss: 1.9637e-04 - mae: 0.0095 - mse: 1.9637e-04 - val_loss: 2.4050e-04 - val_mae: 0.0100 - val_mse: 2.4050e-04\n",
      "Epoch 89/200\n",
      "2440/2440 [==============================] - 1s 463us/step - loss: 1.9689e-04 - mae: 0.0095 - mse: 1.9689e-04 - val_loss: 2.4271e-04 - val_mae: 0.0101 - val_mse: 2.4271e-04\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/2440 [==============================] - 1s 435us/step - loss: 1.9763e-04 - mae: 0.0096 - mse: 1.9763e-04 - val_loss: 2.4546e-04 - val_mae: 0.0103 - val_mse: 2.4546e-04\n",
      "Epoch 91/200\n",
      "2440/2440 [==============================] - 1s 427us/step - loss: 1.9866e-04 - mae: 0.0096 - mse: 1.9866e-04 - val_loss: 2.4886e-04 - val_mae: 0.0104 - val_mse: 2.4886e-04\n",
      "Epoch 92/200\n",
      "2440/2440 [==============================] - 1s 436us/step - loss: 2.0008e-04 - mae: 0.0096 - mse: 2.0008e-04 - val_loss: 2.5308e-04 - val_mae: 0.0107 - val_mse: 2.5308e-04\n",
      "Epoch 93/200\n",
      "2440/2440 [==============================] - 1s 430us/step - loss: 2.0202e-04 - mae: 0.0097 - mse: 2.0202e-04 - val_loss: 2.5827e-04 - val_mae: 0.0109 - val_mse: 2.5827e-04\n",
      "Epoch 94/200\n",
      "2440/2440 [==============================] - 1s 428us/step - loss: 2.0469e-04 - mae: 0.0098 - mse: 2.0469e-04 - val_loss: 2.6453e-04 - val_mae: 0.0112 - val_mse: 2.6453e-04\n",
      "Epoch 95/200\n",
      "2440/2440 [==============================] - 1s 507us/step - loss: 2.0839e-04 - mae: 0.0099 - mse: 2.0839e-04 - val_loss: 2.7185e-04 - val_mae: 0.0116 - val_mse: 2.7185e-04\n",
      "Epoch 96/200\n",
      "2440/2440 [==============================] - 1s 463us/step - loss: 2.1351e-04 - mae: 0.0101 - mse: 2.1351e-04 - val_loss: 2.7979e-04 - val_mae: 0.0119 - val_mse: 2.7979e-04\n",
      "Epoch 97/200\n",
      "2440/2440 [==============================] - 1s 499us/step - loss: 2.2049e-04 - mae: 0.0103 - mse: 2.2049e-04 - val_loss: 2.8699e-04 - val_mae: 0.0122 - val_mse: 2.8699e-04\n",
      "Epoch 98/200\n",
      "2440/2440 [==============================] - 1s 526us/step - loss: 2.2945e-04 - mae: 0.0106 - mse: 2.2945e-04 - val_loss: 2.9037e-04 - val_mae: 0.0124 - val_mse: 2.9037e-04\n",
      "Epoch 99/200\n",
      "2440/2440 [==============================] - 1s 492us/step - loss: 2.3915e-04 - mae: 0.0109 - mse: 2.3915e-04 - val_loss: 2.8462e-04 - val_mae: 0.0121 - val_mse: 2.8462e-04\n",
      "Epoch 100/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 2.4496e-04 - mae: 0.0111 - mse: 2.4496e-04 - val_loss: 2.6509e-04 - val_mae: 0.0113 - val_mse: 2.6509e-04\n",
      "Epoch 101/200\n",
      "2440/2440 [==============================] - 1s 466us/step - loss: 2.3912e-04 - mae: 0.0110 - mse: 2.3912e-04 - val_loss: 2.3786e-04 - val_mae: 0.0098 - val_mse: 2.3786e-04\n",
      "Epoch 102/200\n",
      "2440/2440 [==============================] - 1s 489us/step - loss: 2.2058e-04 - mae: 0.0106 - mse: 2.2058e-04 - val_loss: 2.1952e-04 - val_mae: 0.0083 - val_mse: 2.1952e-04\n",
      "Epoch 103/200\n",
      "2440/2440 [==============================] - 1s 478us/step - loss: 2.0046e-04 - mae: 0.0099 - mse: 2.0046e-04 - val_loss: 2.1201e-04 - val_mae: 0.0076 - val_mse: 2.1201e-04\n",
      "Epoch 104/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 1.8729e-04 - mae: 0.0094 - mse: 1.8729e-04 - val_loss: 2.0938e-04 - val_mae: 0.0073 - val_mse: 2.0938e-04\n",
      "Epoch 105/200\n",
      "2440/2440 [==============================] - 1s 473us/step - loss: 1.8107e-04 - mae: 0.0091 - mse: 1.8107e-04 - val_loss: 2.0854e-04 - val_mae: 0.0073 - val_mse: 2.0854e-04\n",
      "Epoch 106/200\n",
      "2440/2440 [==============================] - 1s 480us/step - loss: 1.7904e-04 - mae: 0.0090 - mse: 1.7904e-04 - val_loss: 2.0858e-04 - val_mae: 0.0074 - val_mse: 2.0858e-04\n",
      "Epoch 107/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 1.7886e-04 - mae: 0.0090 - mse: 1.7886e-04 - val_loss: 2.0914e-04 - val_mae: 0.0075 - val_mse: 2.0914e-04\n",
      "Epoch 108/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 1.7929e-04 - mae: 0.0090 - mse: 1.7929e-04 - val_loss: 2.0994e-04 - val_mae: 0.0076 - val_mse: 2.0994e-04\n",
      "Epoch 109/200\n",
      "2440/2440 [==============================] - 1s 472us/step - loss: 1.7989e-04 - mae: 0.0090 - mse: 1.7989e-04 - val_loss: 2.1083e-04 - val_mae: 0.0078 - val_mse: 2.1083e-04\n",
      "Epoch 110/200\n",
      "2440/2440 [==============================] - 1s 479us/step - loss: 1.8054e-04 - mae: 0.0090 - mse: 1.8054e-04 - val_loss: 2.1171e-04 - val_mae: 0.0079 - val_mse: 2.1171e-04\n",
      "Epoch 111/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 1.8122e-04 - mae: 0.0091 - mse: 1.8122e-04 - val_loss: 2.1253e-04 - val_mae: 0.0080 - val_mse: 2.1253e-04\n",
      "Epoch 112/200\n",
      "2440/2440 [==============================] - 1s 477us/step - loss: 1.8194e-04 - mae: 0.0091 - mse: 1.8194e-04 - val_loss: 2.1326e-04 - val_mae: 0.0081 - val_mse: 2.1326e-04\n",
      "Epoch 113/200\n",
      "2440/2440 [==============================] - 1s 477us/step - loss: 1.8267e-04 - mae: 0.0091 - mse: 1.8267e-04 - val_loss: 2.1385e-04 - val_mae: 0.0081 - val_mse: 2.1385e-04\n",
      "Epoch 114/200\n",
      "2440/2440 [==============================] - 1s 477us/step - loss: 1.8340e-04 - mae: 0.0091 - mse: 1.8340e-04 - val_loss: 2.1428e-04 - val_mae: 0.0082 - val_mse: 2.1428e-04\n",
      "Epoch 115/200\n",
      "2440/2440 [==============================] - 1s 477us/step - loss: 1.8410e-04 - mae: 0.0092 - mse: 1.8410e-04 - val_loss: 2.1455e-04 - val_mae: 0.0082 - val_mse: 2.1455e-04\n",
      "Epoch 116/200\n",
      "2440/2440 [==============================] - 1s 481us/step - loss: 1.8471e-04 - mae: 0.0092 - mse: 1.8471e-04 - val_loss: 2.1462e-04 - val_mae: 0.0082 - val_mse: 2.1462e-04\n",
      "Epoch 117/200\n",
      "2440/2440 [==============================] - 1s 476us/step - loss: 1.8518e-04 - mae: 0.0092 - mse: 1.8518e-04 - val_loss: 2.1450e-04 - val_mae: 0.0082 - val_mse: 2.1450e-04\n",
      "Epoch 118/200\n",
      "2440/2440 [==============================] - 1s 473us/step - loss: 1.8544e-04 - mae: 0.0092 - mse: 1.8544e-04 - val_loss: 2.1419e-04 - val_mae: 0.0082 - val_mse: 2.1419e-04\n",
      "Epoch 119/200\n",
      "2440/2440 [==============================] - 1s 467us/step - loss: 1.8543e-04 - mae: 0.0092 - mse: 1.8543e-04 - val_loss: 2.1372e-04 - val_mae: 0.0081 - val_mse: 2.1372e-04\n",
      "Epoch 120/200\n",
      "2440/2440 [==============================] - 1s 472us/step - loss: 1.8509e-04 - mae: 0.0092 - mse: 1.8509e-04 - val_loss: 2.1311e-04 - val_mae: 0.0080 - val_mse: 2.1311e-04\n",
      "Epoch 121/200\n",
      "2440/2440 [==============================] - 1s 489us/step - loss: 1.8440e-04 - mae: 0.0092 - mse: 1.8440e-04 - val_loss: 2.1241e-04 - val_mae: 0.0079 - val_mse: 2.1241e-04\n",
      "Epoch 122/200\n",
      "2440/2440 [==============================] - 1s 479us/step - loss: 1.8337e-04 - mae: 0.0092 - mse: 1.8337e-04 - val_loss: 2.1169e-04 - val_mae: 0.0078 - val_mse: 2.1169e-04\n",
      "Epoch 123/200\n",
      "2440/2440 [==============================] - 1s 483us/step - loss: 1.8207e-04 - mae: 0.0091 - mse: 1.8207e-04 - val_loss: 2.1100e-04 - val_mae: 0.0077 - val_mse: 2.1100e-04\n",
      "Epoch 124/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 1.8063e-04 - mae: 0.0091 - mse: 1.8063e-04 - val_loss: 2.1039e-04 - val_mae: 0.0076 - val_mse: 2.1039e-04\n",
      "Epoch 125/200\n",
      "2440/2440 [==============================] - 1s 472us/step - loss: 1.7919e-04 - mae: 0.0090 - mse: 1.7919e-04 - val_loss: 2.0989e-04 - val_mae: 0.0076 - val_mse: 2.0989e-04\n",
      "Epoch 126/200\n",
      "2440/2440 [==============================] - 1s 474us/step - loss: 1.7789e-04 - mae: 0.0090 - mse: 1.7789e-04 - val_loss: 2.0952e-04 - val_mae: 0.0075 - val_mse: 2.0952e-04\n",
      "Epoch 127/200\n",
      "2440/2440 [==============================] - 1s 478us/step - loss: 1.7679e-04 - mae: 0.0089 - mse: 1.7679e-04 - val_loss: 2.0927e-04 - val_mae: 0.0075 - val_mse: 2.0927e-04\n",
      "Epoch 128/200\n",
      "2440/2440 [==============================] - 1s 475us/step - loss: 1.7595e-04 - mae: 0.0089 - mse: 1.7595e-04 - val_loss: 2.0916e-04 - val_mae: 0.0075 - val_mse: 2.0916e-04\n",
      "Epoch 129/200\n",
      "2440/2440 [==============================] - 1s 473us/step - loss: 1.7534e-04 - mae: 0.0089 - mse: 1.7534e-04 - val_loss: 2.0915e-04 - val_mae: 0.0075 - val_mse: 2.0915e-04\n",
      "Epoch 130/200\n",
      "2440/2440 [==============================] - 1s 476us/step - loss: 1.7495e-04 - mae: 0.0088 - mse: 1.7495e-04 - val_loss: 2.0915e-04 - val_mae: 0.0075 - val_mse: 2.0915e-04\n",
      "Epoch 131/200\n",
      "2440/2440 [==============================] - 1s 460us/step - loss: 1.7468e-04 - mae: 0.0088 - mse: 1.7468e-04 - val_loss: 2.0913e-04 - val_mae: 0.0075 - val_mse: 2.0913e-04\n",
      "Epoch 132/200\n",
      "2440/2440 [==============================] - 1s 476us/step - loss: 1.7444e-04 - mae: 0.0088 - mse: 1.7444e-04 - val_loss: 2.0916e-04 - val_mae: 0.0075 - val_mse: 2.0916e-04\n",
      "Epoch 133/200\n",
      "2440/2440 [==============================] - 1s 463us/step - loss: 1.7409e-04 - mae: 0.0088 - mse: 1.7409e-04 - val_loss: 2.0931e-04 - val_mae: 0.0075 - val_mse: 2.0931e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200\n",
      "2440/2440 [==============================] - 1s 427us/step - loss: 1.7364e-04 - mae: 0.0088 - mse: 1.7364e-04 - val_loss: 2.0959e-04 - val_mae: 0.0075 - val_mse: 2.0959e-04\n",
      "Epoch 135/200\n",
      "2440/2440 [==============================] - 1s 435us/step - loss: 1.7321e-04 - mae: 0.0088 - mse: 1.7321e-04 - val_loss: 2.0994e-04 - val_mae: 0.0076 - val_mse: 2.0994e-04\n",
      "Epoch 136/200\n",
      "2440/2440 [==============================] - 1s 424us/step - loss: 1.7284e-04 - mae: 0.0087 - mse: 1.7284e-04 - val_loss: 2.1029e-04 - val_mae: 0.0076 - val_mse: 2.1029e-04\n",
      "Epoch 137/200\n",
      "2440/2440 [==============================] - 1s 428us/step - loss: 1.7253e-04 - mae: 0.0087 - mse: 1.7253e-04 - val_loss: 2.1059e-04 - val_mae: 0.0076 - val_mse: 2.1059e-04\n",
      "Epoch 138/200\n",
      "2440/2440 [==============================] - 1s 417us/step - loss: 1.7225e-04 - mae: 0.0087 - mse: 1.7225e-04 - val_loss: 2.1083e-04 - val_mae: 0.0076 - val_mse: 2.1083e-04\n",
      "Epoch 139/200\n",
      "2440/2440 [==============================] - 1s 425us/step - loss: 1.7198e-04 - mae: 0.0087 - mse: 1.7198e-04 - val_loss: 2.1102e-04 - val_mae: 0.0076 - val_mse: 2.1102e-04\n",
      "Epoch 140/200\n",
      "2440/2440 [==============================] - 1s 419us/step - loss: 1.7169e-04 - mae: 0.0087 - mse: 1.7169e-04 - val_loss: 2.1119e-04 - val_mae: 0.0077 - val_mse: 2.1119e-04\n",
      "Epoch 141/200\n",
      "2440/2440 [==============================] - 1s 428us/step - loss: 1.7139e-04 - mae: 0.0087 - mse: 1.7139e-04 - val_loss: 2.1138e-04 - val_mae: 0.0077 - val_mse: 2.1138e-04\n",
      "Epoch 142/200\n",
      "2440/2440 [==============================] - 1s 419us/step - loss: 1.7106e-04 - mae: 0.0087 - mse: 1.7106e-04 - val_loss: 2.1160e-04 - val_mae: 0.0077 - val_mse: 2.1160e-04\n",
      "Epoch 143/200\n",
      "2440/2440 [==============================] - 1s 428us/step - loss: 1.7071e-04 - mae: 0.0087 - mse: 1.7071e-04 - val_loss: 2.1182e-04 - val_mae: 0.0078 - val_mse: 2.1182e-04\n",
      "Epoch 144/200\n",
      "2440/2440 [==============================] - 1s 421us/step - loss: 1.7038e-04 - mae: 0.0086 - mse: 1.7038e-04 - val_loss: 2.1194e-04 - val_mae: 0.0078 - val_mse: 2.1194e-04\n",
      "Epoch 145/200\n",
      "2440/2440 [==============================] - 1s 425us/step - loss: 1.7010e-04 - mae: 0.0086 - mse: 1.7010e-04 - val_loss: 2.1197e-04 - val_mae: 0.0078 - val_mse: 2.1197e-04\n",
      "Epoch 146/200\n",
      "2440/2440 [==============================] - 1s 430us/step - loss: 1.6982e-04 - mae: 0.0086 - mse: 1.6982e-04 - val_loss: 2.1216e-04 - val_mae: 0.0078 - val_mse: 2.1216e-04\n",
      "Epoch 147/200\n",
      "2440/2440 [==============================] - 1s 429us/step - loss: 1.6938e-04 - mae: 0.0086 - mse: 1.6938e-04 - val_loss: 2.1256e-04 - val_mae: 0.0079 - val_mse: 2.1256e-04\n",
      "Epoch 148/200\n",
      "2440/2440 [==============================] - 1s 429us/step - loss: 1.6879e-04 - mae: 0.0085 - mse: 1.6879e-04 - val_loss: 2.1280e-04 - val_mae: 0.0079 - val_mse: 2.1280e-04\n",
      "Epoch 149/200\n",
      "2440/2440 [==============================] - 1s 436us/step - loss: 1.6837e-04 - mae: 0.0085 - mse: 1.6837e-04 - val_loss: 2.1273e-04 - val_mae: 0.0079 - val_mse: 2.1273e-04\n",
      "Epoch 150/200\n",
      "2440/2440 [==============================] - 1s 431us/step - loss: 1.6830e-04 - mae: 0.0085 - mse: 1.6830e-04 - val_loss: 2.1241e-04 - val_mae: 0.0079 - val_mse: 2.1241e-04\n",
      "Epoch 151/200\n",
      "2440/2440 [==============================] - 1s 425us/step - loss: 1.6860e-04 - mae: 0.0085 - mse: 1.6860e-04 - val_loss: 2.1194e-04 - val_mae: 0.0079 - val_mse: 2.1194e-04\n",
      "Epoch 152/200\n",
      "2440/2440 [==============================] - 1s 431us/step - loss: 1.6917e-04 - mae: 0.0085 - mse: 1.6917e-04 - val_loss: 2.1140e-04 - val_mae: 0.0079 - val_mse: 2.1140e-04\n",
      "Epoch 153/200\n",
      "2440/2440 [==============================] - 1s 456us/step - loss: 1.6985e-04 - mae: 0.0085 - mse: 1.6985e-04 - val_loss: 2.1091e-04 - val_mae: 0.0078 - val_mse: 2.1091e-04\n",
      "Epoch 154/200\n",
      "2440/2440 [==============================] - 1s 521us/step - loss: 1.7037e-04 - mae: 0.0085 - mse: 1.7037e-04 - val_loss: 2.1063e-04 - val_mae: 0.0078 - val_mse: 2.1063e-04\n",
      "Epoch 155/200\n",
      "2440/2440 [==============================] - 1s 490us/step - loss: 1.7041e-04 - mae: 0.0085 - mse: 1.7041e-04 - val_loss: 2.1072e-04 - val_mae: 0.0079 - val_mse: 2.1072e-04\n",
      "Epoch 156/200\n",
      "2440/2440 [==============================] - 1s 499us/step - loss: 1.6985e-04 - mae: 0.0085 - mse: 1.6985e-04 - val_loss: 2.1113e-04 - val_mae: 0.0079 - val_mse: 2.1113e-04\n",
      "Epoch 157/200\n",
      "2440/2440 [==============================] - 1s 461us/step - loss: 1.6911e-04 - mae: 0.0085 - mse: 1.6911e-04 - val_loss: 2.1169e-04 - val_mae: 0.0079 - val_mse: 2.1169e-04\n",
      "Epoch 158/200\n",
      "2440/2440 [==============================] - 1s 469us/step - loss: 1.6875e-04 - mae: 0.0085 - mse: 1.6875e-04 - val_loss: 2.1221e-04 - val_mae: 0.0080 - val_mse: 2.1221e-04\n",
      "Epoch 159/200\n",
      "2440/2440 [==============================] - 1s 461us/step - loss: 1.6884e-04 - mae: 0.0085 - mse: 1.6884e-04 - val_loss: 2.1256e-04 - val_mae: 0.0080 - val_mse: 2.1256e-04\n",
      "Epoch 160/200\n",
      "2440/2440 [==============================] - 1s 467us/step - loss: 1.6905e-04 - mae: 0.0085 - mse: 1.6905e-04 - val_loss: 2.1265e-04 - val_mae: 0.0080 - val_mse: 2.1265e-04\n",
      "Epoch 161/200\n",
      "2440/2440 [==============================] - 1s 466us/step - loss: 1.6912e-04 - mae: 0.0085 - mse: 1.6912e-04 - val_loss: 2.1255e-04 - val_mae: 0.0080 - val_mse: 2.1255e-04\n",
      "Epoch 162/200\n",
      "2440/2440 [==============================] - 1s 471us/step - loss: 1.6883e-04 - mae: 0.0085 - mse: 1.6883e-04 - val_loss: 2.1247e-04 - val_mae: 0.0080 - val_mse: 2.1247e-04\n",
      "Epoch 163/200\n",
      "2440/2440 [==============================] - 1s 466us/step - loss: 1.6816e-04 - mae: 0.0085 - mse: 1.6816e-04 - val_loss: 2.1237e-04 - val_mae: 0.0079 - val_mse: 2.1237e-04\n",
      "Epoch 164/200\n",
      "2440/2440 [==============================] - 1s 467us/step - loss: 1.6725e-04 - mae: 0.0085 - mse: 1.6725e-04 - val_loss: 2.1213e-04 - val_mae: 0.0079 - val_mse: 2.1213e-04\n",
      "Epoch 165/200\n",
      "2440/2440 [==============================] - 1s 468us/step - loss: 1.6621e-04 - mae: 0.0084 - mse: 1.6621e-04 - val_loss: 2.1195e-04 - val_mae: 0.0079 - val_mse: 2.1195e-04\n",
      "Epoch 166/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 1.6512e-04 - mae: 0.0084 - mse: 1.6512e-04 - val_loss: 2.1213e-04 - val_mae: 0.0079 - val_mse: 2.1213e-04\n",
      "Epoch 167/200\n",
      "2440/2440 [==============================] - 1s 472us/step - loss: 1.6424e-04 - mae: 0.0084 - mse: 1.6424e-04 - val_loss: 2.1268e-04 - val_mae: 0.0079 - val_mse: 2.1268e-04\n",
      "Epoch 168/200\n",
      "2440/2440 [==============================] - 1s 497us/step - loss: 1.6382e-04 - mae: 0.0084 - mse: 1.6382e-04 - val_loss: 2.1329e-04 - val_mae: 0.0080 - val_mse: 2.1329e-04\n",
      "Epoch 169/200\n",
      "2440/2440 [==============================] - 1s 491us/step - loss: 1.6378e-04 - mae: 0.0084 - mse: 1.6378e-04 - val_loss: 2.1365e-04 - val_mae: 0.0081 - val_mse: 2.1365e-04\n",
      "Epoch 170/200\n",
      "2440/2440 [==============================] - 1s 548us/step - loss: 1.6386e-04 - mae: 0.0084 - mse: 1.6386e-04 - val_loss: 2.1375e-04 - val_mae: 0.0081 - val_mse: 2.1375e-04\n",
      "Epoch 171/200\n",
      "2440/2440 [==============================] - 1s 529us/step - loss: 1.6376e-04 - mae: 0.0083 - mse: 1.6376e-04 - val_loss: 2.1389e-04 - val_mae: 0.0081 - val_mse: 2.1389e-04\n",
      "Epoch 172/200\n",
      "2440/2440 [==============================] - 1s 471us/step - loss: 1.6316e-04 - mae: 0.0083 - mse: 1.6316e-04 - val_loss: 2.1438e-04 - val_mae: 0.0080 - val_mse: 2.1438e-04\n",
      "Epoch 173/200\n",
      "2440/2440 [==============================] - 1s 465us/step - loss: 1.6224e-04 - mae: 0.0083 - mse: 1.6224e-04 - val_loss: 2.1500e-04 - val_mae: 0.0081 - val_mse: 2.1500e-04\n",
      "Epoch 174/200\n",
      "2440/2440 [==============================] - 1s 524us/step - loss: 1.6156e-04 - mae: 0.0083 - mse: 1.6156e-04 - val_loss: 2.1526e-04 - val_mae: 0.0081 - val_mse: 2.1526e-04\n",
      "Epoch 175/200\n",
      "2440/2440 [==============================] - 1s 494us/step - loss: 1.6119e-04 - mae: 0.0083 - mse: 1.6119e-04 - val_loss: 2.1497e-04 - val_mae: 0.0081 - val_mse: 2.1497e-04\n",
      "Epoch 176/200\n",
      "2440/2440 [==============================] - 1s 427us/step - loss: 1.6082e-04 - mae: 0.0082 - mse: 1.6082e-04 - val_loss: 2.1438e-04 - val_mae: 0.0081 - val_mse: 2.1438e-04\n",
      "Epoch 177/200\n",
      "2440/2440 [==============================] - 1s 429us/step - loss: 1.6031e-04 - mae: 0.0082 - mse: 1.6031e-04 - val_loss: 2.1386e-04 - val_mae: 0.0080 - val_mse: 2.1386e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "2440/2440 [==============================] - 1s 468us/step - loss: 1.5968e-04 - mae: 0.0081 - mse: 1.5968e-04 - val_loss: 2.1353e-04 - val_mae: 0.0080 - val_mse: 2.1353e-04\n",
      "Epoch 179/200\n",
      "2440/2440 [==============================] - 1s 472us/step - loss: 1.5910e-04 - mae: 0.0081 - mse: 1.5910e-04 - val_loss: 2.1323e-04 - val_mae: 0.0080 - val_mse: 2.1323e-04\n",
      "Epoch 180/200\n",
      "2440/2440 [==============================] - 1s 487us/step - loss: 1.5874e-04 - mae: 0.0081 - mse: 1.5874e-04 - val_loss: 2.1282e-04 - val_mae: 0.0080 - val_mse: 2.1282e-04\n",
      "Epoch 181/200\n",
      "2440/2440 [==============================] - 1s 499us/step - loss: 1.5853e-04 - mae: 0.0081 - mse: 1.5853e-04 - val_loss: 2.1241e-04 - val_mae: 0.0080 - val_mse: 2.1241e-04\n",
      "Epoch 182/200\n",
      "2440/2440 [==============================] - 1s 493us/step - loss: 1.5819e-04 - mae: 0.0081 - mse: 1.5819e-04 - val_loss: 2.1218e-04 - val_mae: 0.0079 - val_mse: 2.1218e-04\n",
      "Epoch 183/200\n",
      "2440/2440 [==============================] - 1s 498us/step - loss: 1.5760e-04 - mae: 0.0080 - mse: 1.5760e-04 - val_loss: 2.1218e-04 - val_mae: 0.0079 - val_mse: 2.1218e-04\n",
      "Epoch 184/200\n",
      "2440/2440 [==============================] - 1s 470us/step - loss: 1.5689e-04 - mae: 0.0080 - mse: 1.5689e-04 - val_loss: 2.1236e-04 - val_mae: 0.0079 - val_mse: 2.1236e-04\n",
      "Epoch 185/200\n",
      "2440/2440 [==============================] - 1s 465us/step - loss: 1.5618e-04 - mae: 0.0080 - mse: 1.5618e-04 - val_loss: 2.1265e-04 - val_mae: 0.0079 - val_mse: 2.1265e-04\n",
      "Epoch 186/200\n",
      "2440/2440 [==============================] - 1s 451us/step - loss: 1.5556e-04 - mae: 0.0080 - mse: 1.5556e-04 - val_loss: 2.1292e-04 - val_mae: 0.0080 - val_mse: 2.1292e-04\n",
      "Epoch 187/200\n",
      "2440/2440 [==============================] - 1s 453us/step - loss: 1.5512e-04 - mae: 0.0080 - mse: 1.5512e-04 - val_loss: 2.1304e-04 - val_mae: 0.0080 - val_mse: 2.1304e-04\n",
      "Epoch 188/200\n",
      "2440/2440 [==============================] - 1s 453us/step - loss: 1.5484e-04 - mae: 0.0080 - mse: 1.5484e-04 - val_loss: 2.1304e-04 - val_mae: 0.0079 - val_mse: 2.1304e-04\n",
      "Epoch 189/200\n",
      "2440/2440 [==============================] - 1s 450us/step - loss: 1.5461e-04 - mae: 0.0079 - mse: 1.5461e-04 - val_loss: 2.1301e-04 - val_mae: 0.0079 - val_mse: 2.1301e-04\n",
      "Epoch 190/200\n",
      "2440/2440 [==============================] - 1s 461us/step - loss: 1.5432e-04 - mae: 0.0079 - mse: 1.5432e-04 - val_loss: 2.1299e-04 - val_mae: 0.0079 - val_mse: 2.1299e-04\n",
      "Epoch 191/200\n",
      "2440/2440 [==============================] - 1s 452us/step - loss: 1.5395e-04 - mae: 0.0079 - mse: 1.5395e-04 - val_loss: 2.1303e-04 - val_mae: 0.0079 - val_mse: 2.1303e-04\n",
      "Epoch 192/200\n",
      "2440/2440 [==============================] - 1s 463us/step - loss: 1.5350e-04 - mae: 0.0079 - mse: 1.5350e-04 - val_loss: 2.1314e-04 - val_mae: 0.0079 - val_mse: 2.1314e-04\n",
      "Epoch 193/200\n",
      "2440/2440 [==============================] - 1s 464us/step - loss: 1.5317e-04 - mae: 0.0079 - mse: 1.5317e-04 - val_loss: 2.1325e-04 - val_mae: 0.0079 - val_mse: 2.1325e-04\n",
      "Epoch 194/200\n",
      "2440/2440 [==============================] - 1s 465us/step - loss: 1.5313e-04 - mae: 0.0079 - mse: 1.5313e-04 - val_loss: 2.1336e-04 - val_mae: 0.0079 - val_mse: 2.1336e-04\n",
      "Epoch 195/200\n",
      "2440/2440 [==============================] - 1s 468us/step - loss: 1.5334e-04 - mae: 0.0079 - mse: 1.5334e-04 - val_loss: 2.1360e-04 - val_mae: 0.0079 - val_mse: 2.1360e-04\n",
      "Epoch 196/200\n",
      "2440/2440 [==============================] - 1s 465us/step - loss: 1.5359e-04 - mae: 0.0079 - mse: 1.5359e-04 - val_loss: 2.1406e-04 - val_mae: 0.0079 - val_mse: 2.1406e-04\n",
      "Epoch 197/200\n",
      "2440/2440 [==============================] - 1s 469us/step - loss: 1.5380e-04 - mae: 0.0079 - mse: 1.5380e-04 - val_loss: 2.1478e-04 - val_mae: 0.0080 - val_mse: 2.1478e-04\n",
      "Epoch 198/200\n",
      "2440/2440 [==============================] - 1s 455us/step - loss: 1.5403e-04 - mae: 0.0079 - mse: 1.5403e-04 - val_loss: 2.1577e-04 - val_mae: 0.0080 - val_mse: 2.1577e-04\n",
      "Epoch 199/200\n",
      "2440/2440 [==============================] - 1s 451us/step - loss: 1.5435e-04 - mae: 0.0079 - mse: 1.5435e-04 - val_loss: 2.1713e-04 - val_mae: 0.0080 - val_mse: 2.1713e-04\n",
      "Epoch 200/200\n",
      "2440/2440 [==============================] - 1s 457us/step - loss: 1.5478e-04 - mae: 0.0079 - mse: 1.5478e-04 - val_loss: 2.1907e-04 - val_mae: 0.0081 - val_mse: 2.1907e-04\n"
     ]
    }
   ],
   "source": [
    "# Use same data from earlier to fit the model\n",
    "slstmhistory = slstm.fit(X_train_LSTM, y_train_LSTM,\n",
    "                       epochs=EPOCHS,\n",
    "                       validation_data=(X_test_LSTM, y_test_LSTM),\n",
    "                       verbose=1,\n",
    "                       shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacked LSTM Model WITHOUT Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/200\n",
      "4222/4222 [==============================] - 2s 365us/step - loss: 0.0343 - mae: 0.1183 - mse: 0.0343 - val_loss: 0.0245 - val_mae: 0.0988 - val_mse: 0.0245\n",
      "Epoch 2/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0231 - mae: 0.0850 - mse: 0.0231 - val_loss: 0.0206 - val_mae: 0.0815 - val_mse: 0.0206\n",
      "Epoch 3/200\n",
      "4222/4222 [==============================] - 1s 240us/step - loss: 0.0199 - mae: 0.0723 - mse: 0.0199 - val_loss: 0.0184 - val_mae: 0.0725 - val_mse: 0.0184\n",
      "Epoch 4/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0183 - mae: 0.0672 - mse: 0.0183 - val_loss: 0.0168 - val_mae: 0.0710 - val_mse: 0.0168\n",
      "Epoch 5/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0167 - mae: 0.0640 - mse: 0.0167 - val_loss: 0.0149 - val_mae: 0.0689 - val_mse: 0.0149\n",
      "Epoch 6/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0157 - mae: 0.0615 - mse: 0.0157 - val_loss: 0.0138 - val_mae: 0.0627 - val_mse: 0.0138\n",
      "Epoch 7/200\n",
      "4222/4222 [==============================] - 1s 237us/step - loss: 0.0151 - mae: 0.0602 - mse: 0.0151 - val_loss: 0.0134 - val_mae: 0.0603 - val_mse: 0.0134\n",
      "Epoch 8/200\n",
      "4222/4222 [==============================] - 1s 249us/step - loss: 0.0149 - mae: 0.0599 - mse: 0.0149 - val_loss: 0.0131 - val_mae: 0.0610 - val_mse: 0.0131\n",
      "Epoch 9/200\n",
      "4222/4222 [==============================] - 1s 238us/step - loss: 0.0147 - mae: 0.0595 - mse: 0.0147 - val_loss: 0.0130 - val_mae: 0.0627 - val_mse: 0.0130\n",
      "Epoch 10/200\n",
      "4222/4222 [==============================] - 1s 242us/step - loss: 0.0145 - mae: 0.0590 - mse: 0.0145 - val_loss: 0.0129 - val_mae: 0.0635 - val_mse: 0.0129\n",
      "Epoch 11/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0142 - mae: 0.0583 - mse: 0.0142 - val_loss: 0.0127 - val_mae: 0.0631 - val_mse: 0.0127\n",
      "Epoch 12/200\n",
      "4222/4222 [==============================] - 1s 231us/step - loss: 0.0140 - mae: 0.0577 - mse: 0.0140 - val_loss: 0.0125 - val_mae: 0.0626 - val_mse: 0.0125\n",
      "Epoch 13/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0138 - mae: 0.0573 - mse: 0.0138 - val_loss: 0.0124 - val_mae: 0.0621 - val_mse: 0.0124\n",
      "Epoch 14/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0137 - mae: 0.0570 - mse: 0.0137 - val_loss: 0.0122 - val_mae: 0.0612 - val_mse: 0.0122\n",
      "Epoch 15/200\n",
      "4222/4222 [==============================] - 1s 229us/step - loss: 0.0135 - mae: 0.0567 - mse: 0.0135 - val_loss: 0.0119 - val_mae: 0.0593 - val_mse: 0.0119\n",
      "Epoch 16/200\n",
      "4222/4222 [==============================] - 1s 264us/step - loss: 0.0134 - mae: 0.0563 - mse: 0.0134 - val_loss: 0.0116 - val_mae: 0.0560 - val_mse: 0.0116\n",
      "Epoch 17/200\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 0.0132 - mae: 0.0557 - mse: 0.0132 - val_loss: 0.0114 - val_mae: 0.0517 - val_mse: 0.0114\n",
      "Epoch 18/200\n",
      "4222/4222 [==============================] - 1s 192us/step - loss: 0.0130 - mae: 0.0545 - mse: 0.0130 - val_loss: 0.0112 - val_mae: 0.0536 - val_mse: 0.0112\n",
      "Epoch 19/200\n",
      "4222/4222 [==============================] - 1s 195us/step - loss: 0.0128 - mae: 0.0533 - mse: 0.0128 - val_loss: 0.0110 - val_mae: 0.0505 - val_mse: 0.0110\n",
      "Epoch 20/200\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 0.0126 - mae: 0.0530 - mse: 0.0126 - val_loss: 0.0108 - val_mae: 0.0521 - val_mse: 0.0108\n",
      "Epoch 21/200\n",
      "4222/4222 [==============================] - 1s 199us/step - loss: 0.0124 - mae: 0.0522 - mse: 0.0124 - val_loss: 0.0106 - val_mae: 0.0503 - val_mse: 0.0106\n",
      "Epoch 22/200\n",
      "4222/4222 [==============================] - 1s 192us/step - loss: 0.0122 - mae: 0.0514 - mse: 0.0122 - val_loss: 0.0104 - val_mae: 0.0490 - val_mse: 0.0104\n",
      "Epoch 23/200\n",
      "4222/4222 [==============================] - 1s 201us/step - loss: 0.0119 - mae: 0.0506 - mse: 0.0119 - val_loss: 0.0103 - val_mae: 0.0483 - val_mse: 0.0103\n",
      "Epoch 24/200\n",
      "4222/4222 [==============================] - 1s 205us/step - loss: 0.0117 - mae: 0.0500 - mse: 0.0117 - val_loss: 0.0101 - val_mae: 0.0485 - val_mse: 0.0101\n",
      "Epoch 25/200\n",
      "4222/4222 [==============================] - 1s 199us/step - loss: 0.0115 - mae: 0.0494 - mse: 0.0115 - val_loss: 0.0100 - val_mae: 0.0494 - val_mse: 0.0100\n",
      "Epoch 26/200\n",
      "4222/4222 [==============================] - 1s 207us/step - loss: 0.0113 - mae: 0.0488 - mse: 0.0113 - val_loss: 0.0098 - val_mae: 0.0500 - val_mse: 0.0098\n",
      "Epoch 27/200\n",
      "4222/4222 [==============================] - 1s 196us/step - loss: 0.0110 - mae: 0.0479 - mse: 0.0110 - val_loss: 0.0096 - val_mae: 0.0478 - val_mse: 0.0096\n",
      "Epoch 28/200\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 0.0108 - mae: 0.0475 - mse: 0.0108 - val_loss: 0.0094 - val_mae: 0.0457 - val_mse: 0.0094\n",
      "Epoch 29/200\n",
      "4222/4222 [==============================] - 1s 196us/step - loss: 0.0106 - mae: 0.0475 - mse: 0.0106 - val_loss: 0.0092 - val_mae: 0.0470 - val_mse: 0.0092\n",
      "Epoch 30/200\n",
      "4222/4222 [==============================] - 1s 198us/step - loss: 0.0103 - mae: 0.0467 - mse: 0.0103 - val_loss: 0.0090 - val_mae: 0.0458 - val_mse: 0.0090\n",
      "Epoch 31/200\n",
      "4222/4222 [==============================] - 1s 193us/step - loss: 0.0101 - mae: 0.0455 - mse: 0.0101 - val_loss: 0.0087 - val_mae: 0.0455 - val_mse: 0.0087\n",
      "Epoch 32/200\n",
      "4222/4222 [==============================] - 1s 191us/step - loss: 0.0098 - mae: 0.0446 - mse: 0.0098 - val_loss: 0.0085 - val_mae: 0.0452 - val_mse: 0.0085\n",
      "Epoch 33/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0095 - mae: 0.0440 - mse: 0.0095 - val_loss: 0.0083 - val_mae: 0.0454 - val_mse: 0.0083\n",
      "Epoch 34/200\n",
      "4222/4222 [==============================] - 1s 185us/step - loss: 0.0093 - mae: 0.0437 - mse: 0.0093 - val_loss: 0.0082 - val_mae: 0.0457 - val_mse: 0.0082\n",
      "Epoch 35/200\n",
      "4222/4222 [==============================] - 1s 192us/step - loss: 0.0090 - mae: 0.0434 - mse: 0.0090 - val_loss: 0.0081 - val_mae: 0.0460 - val_mse: 0.0081\n",
      "Epoch 36/200\n",
      "4222/4222 [==============================] - 1s 196us/step - loss: 0.0087 - mae: 0.0432 - mse: 0.0087 - val_loss: 0.0079 - val_mae: 0.0459 - val_mse: 0.0079\n",
      "Epoch 37/200\n",
      "4222/4222 [==============================] - 1s 185us/step - loss: 0.0084 - mae: 0.0429 - mse: 0.0084 - val_loss: 0.0076 - val_mae: 0.0457 - val_mse: 0.0076\n",
      "Epoch 38/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0080 - mae: 0.0422 - mse: 0.0080 - val_loss: 0.0074 - val_mae: 0.0462 - val_mse: 0.0074\n",
      "Epoch 39/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0075 - mae: 0.0410 - mse: 0.0075 - val_loss: 0.0071 - val_mae: 0.0446 - val_mse: 0.0071\n",
      "Epoch 40/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0071 - mae: 0.0393 - mse: 0.0071 - val_loss: 0.0068 - val_mae: 0.0410 - val_mse: 0.0068\n",
      "Epoch 41/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0068 - mae: 0.0377 - mse: 0.0068 - val_loss: 0.0064 - val_mae: 0.0388 - val_mse: 0.0064\n",
      "Epoch 42/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0064 - mae: 0.0364 - mse: 0.0064 - val_loss: 0.0060 - val_mae: 0.0390 - val_mse: 0.0060\n",
      "Epoch 43/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0061 - mae: 0.0353 - mse: 0.0061 - val_loss: 0.0055 - val_mae: 0.0378 - val_mse: 0.0055\n",
      "Epoch 44/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0056 - mae: 0.0343 - mse: 0.0056 - val_loss: 0.0050 - val_mae: 0.0352 - val_mse: 0.0050\n",
      "Epoch 45/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0053 - mae: 0.0336 - mse: 0.0053 - val_loss: 0.0046 - val_mae: 0.0345 - val_mse: 0.0046\n",
      "Epoch 46/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0050 - mae: 0.0330 - mse: 0.0050 - val_loss: 0.0044 - val_mae: 0.0346 - val_mse: 0.0044\n",
      "Epoch 47/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0047 - mae: 0.0325 - mse: 0.0047 - val_loss: 0.0042 - val_mae: 0.0349 - val_mse: 0.0042\n",
      "Epoch 48/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0045 - mae: 0.0321 - mse: 0.0045 - val_loss: 0.0041 - val_mae: 0.0341 - val_mse: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0042 - mae: 0.0314 - mse: 0.0042 - val_loss: 0.0040 - val_mae: 0.0314 - val_mse: 0.0040\n",
      "Epoch 50/200\n",
      "4222/4222 [==============================] - 1s 206us/step - loss: 0.0041 - mae: 0.0305 - mse: 0.0041 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 51/200\n",
      "4222/4222 [==============================] - 1s 232us/step - loss: 0.0039 - mae: 0.0299 - mse: 0.0039 - val_loss: 0.0042 - val_mae: 0.0316 - val_mse: 0.0042\n",
      "Epoch 52/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0038 - mae: 0.0296 - mse: 0.0038 - val_loss: 0.0042 - val_mae: 0.0324 - val_mse: 0.0042\n",
      "Epoch 53/200\n",
      "4222/4222 [==============================] - 1s 254us/step - loss: 0.0037 - mae: 0.0293 - mse: 0.0037 - val_loss: 0.0042 - val_mae: 0.0329 - val_mse: 0.0042\n",
      "Epoch 54/200\n",
      "4222/4222 [==============================] - 1s 239us/step - loss: 0.0036 - mae: 0.0289 - mse: 0.0036 - val_loss: 0.0042 - val_mae: 0.0331 - val_mse: 0.0042\n",
      "Epoch 55/200\n",
      "4222/4222 [==============================] - 1s 233us/step - loss: 0.0035 - mae: 0.0290 - mse: 0.0035 - val_loss: 0.0040 - val_mae: 0.0327 - val_mse: 0.0040\n",
      "Epoch 56/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0036 - mae: 0.0293 - mse: 0.0036 - val_loss: 0.0040 - val_mae: 0.0316 - val_mse: 0.0040\n",
      "Epoch 57/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0036 - mae: 0.0290 - mse: 0.0036 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 58/200\n",
      "4222/4222 [==============================] - 1s 220us/step - loss: 0.0034 - mae: 0.0277 - mse: 0.0034 - val_loss: 0.0040 - val_mae: 0.0322 - val_mse: 0.0040\n",
      "Epoch 59/200\n",
      "4222/4222 [==============================] - 1s 219us/step - loss: 0.0032 - mae: 0.0264 - mse: 0.0032 - val_loss: 0.0040 - val_mae: 0.0326 - val_mse: 0.0040\n",
      "Epoch 60/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0031 - mae: 0.0259 - mse: 0.0031 - val_loss: 0.0040 - val_mae: 0.0322 - val_mse: 0.0040\n",
      "Epoch 61/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0030 - mae: 0.0253 - mse: 0.0030 - val_loss: 0.0040 - val_mae: 0.0314 - val_mse: 0.0040\n",
      "Epoch 62/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0029 - mae: 0.0249 - mse: 0.0029 - val_loss: 0.0039 - val_mae: 0.0306 - val_mse: 0.0039\n",
      "Epoch 63/200\n",
      "4222/4222 [==============================] - 1s 220us/step - loss: 0.0029 - mae: 0.0247 - mse: 0.0029 - val_loss: 0.0038 - val_mae: 0.0297 - val_mse: 0.0038\n",
      "Epoch 64/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0028 - mae: 0.0245 - mse: 0.0028 - val_loss: 0.0037 - val_mae: 0.0290 - val_mse: 0.0037\n",
      "Epoch 65/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0028 - mae: 0.0244 - mse: 0.0028 - val_loss: 0.0036 - val_mae: 0.0285 - val_mse: 0.0036\n",
      "Epoch 66/200\n",
      "4222/4222 [==============================] - 1s 217us/step - loss: 0.0027 - mae: 0.0242 - mse: 0.0027 - val_loss: 0.0035 - val_mae: 0.0281 - val_mse: 0.0035\n",
      "Epoch 67/200\n",
      "4222/4222 [==============================] - 1s 220us/step - loss: 0.0027 - mae: 0.0240 - mse: 0.0027 - val_loss: 0.0035 - val_mae: 0.0278 - val_mse: 0.0035\n",
      "Epoch 68/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0026 - mae: 0.0238 - mse: 0.0026 - val_loss: 0.0034 - val_mae: 0.0274 - val_mse: 0.0034\n",
      "Epoch 69/200\n",
      "4222/4222 [==============================] - 1s 220us/step - loss: 0.0025 - mae: 0.0234 - mse: 0.0025 - val_loss: 0.0033 - val_mae: 0.0270 - val_mse: 0.0033\n",
      "Epoch 70/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0025 - mae: 0.0231 - mse: 0.0025 - val_loss: 0.0033 - val_mae: 0.0267 - val_mse: 0.0033\n",
      "Epoch 71/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0024 - mae: 0.0229 - mse: 0.0024 - val_loss: 0.0032 - val_mae: 0.0265 - val_mse: 0.0032\n",
      "Epoch 72/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0024 - mae: 0.0226 - mse: 0.0024 - val_loss: 0.0032 - val_mae: 0.0263 - val_mse: 0.0032\n",
      "Epoch 73/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0024 - mae: 0.0224 - mse: 0.0024 - val_loss: 0.0032 - val_mae: 0.0260 - val_mse: 0.0032\n",
      "Epoch 74/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0023 - mae: 0.0222 - mse: 0.0023 - val_loss: 0.0031 - val_mae: 0.0258 - val_mse: 0.0031\n",
      "Epoch 75/200\n",
      "4222/4222 [==============================] - 1s 218us/step - loss: 0.0023 - mae: 0.0221 - mse: 0.0023 - val_loss: 0.0031 - val_mae: 0.0255 - val_mse: 0.0031\n",
      "Epoch 76/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0022 - mae: 0.0219 - mse: 0.0022 - val_loss: 0.0030 - val_mae: 0.0253 - val_mse: 0.0030\n",
      "Epoch 77/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0022 - mae: 0.0218 - mse: 0.0022 - val_loss: 0.0030 - val_mae: 0.0251 - val_mse: 0.0030\n",
      "Epoch 78/200\n",
      "4222/4222 [==============================] - 1s 234us/step - loss: 0.0022 - mae: 0.0216 - mse: 0.0022 - val_loss: 0.0030 - val_mae: 0.0250 - val_mse: 0.0030\n",
      "Epoch 79/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0022 - mae: 0.0217 - mse: 0.0022 - val_loss: 0.0028 - val_mae: 0.0242 - val_mse: 0.0028\n",
      "Epoch 80/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0021 - mae: 0.0209 - mse: 0.0021 - val_loss: 0.0030 - val_mae: 0.0245 - val_mse: 0.0030\n",
      "Epoch 81/200\n",
      "4222/4222 [==============================] - 1s 234us/step - loss: 0.0021 - mae: 0.0212 - mse: 0.0021 - val_loss: 0.0028 - val_mae: 0.0240 - val_mse: 0.0028\n",
      "Epoch 82/200\n",
      "4222/4222 [==============================] - 1s 240us/step - loss: 0.0036 - mae: 0.0287 - mse: 0.0036 - val_loss: 0.0031 - val_mae: 0.0272 - val_mse: 0.0031\n",
      "Epoch 83/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0021 - mae: 0.0208 - mse: 0.0021 - val_loss: 0.0028 - val_mae: 0.0239 - val_mse: 0.0028\n",
      "Epoch 84/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0033 - mae: 0.0262 - mse: 0.0033 - val_loss: 0.0028 - val_mae: 0.0241 - val_mse: 0.0028\n",
      "Epoch 85/200\n",
      "4222/4222 [==============================] - 1s 231us/step - loss: 0.0021 - mae: 0.0208 - mse: 0.0021 - val_loss: 0.0026 - val_mae: 0.0232 - val_mse: 0.0026\n",
      "Epoch 86/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0022 - mae: 0.0207 - mse: 0.0022 - val_loss: 0.0027 - val_mae: 0.0247 - val_mse: 0.0027\n",
      "Epoch 87/200\n",
      "4222/4222 [==============================] - 1s 254us/step - loss: 0.0022 - mae: 0.0208 - mse: 0.0022 - val_loss: 0.0027 - val_mae: 0.0247 - val_mse: 0.0027\n",
      "Epoch 88/200\n",
      "4222/4222 [==============================] - 1s 246us/step - loss: 0.0020 - mae: 0.0201 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0248 - val_mse: 0.0027\n",
      "Epoch 89/200\n",
      "4222/4222 [==============================] - 1s 232us/step - loss: 0.0020 - mae: 0.0201 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0251 - val_mse: 0.0028\n",
      "Epoch 90/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0019 - mae: 0.0199 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0255 - val_mse: 0.0028\n",
      "Epoch 91/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0019 - mae: 0.0198 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0256 - val_mse: 0.0028\n",
      "Epoch 92/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0019 - mae: 0.0195 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0254 - val_mse: 0.0028\n",
      "Epoch 93/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0019 - mae: 0.0200 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0240 - val_mse: 0.0028\n",
      "Epoch 94/200\n",
      "4222/4222 [==============================] - 1s 230us/step - loss: 0.0018 - mae: 0.0194 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0246 - val_mse: 0.0028\n",
      "Epoch 95/200\n",
      "4222/4222 [==============================] - 1s 256us/step - loss: 0.0018 - mae: 0.0194 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0247 - val_mse: 0.0027\n",
      "Epoch 96/200\n",
      "4222/4222 [==============================] - 1s 260us/step - loss: 0.0018 - mae: 0.0196 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0241 - val_mse: 0.0027\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0020 - mae: 0.0201 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0228 - val_mse: 0.0027\n",
      "Epoch 98/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0019 - mae: 0.0194 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0236 - val_mse: 0.0027\n",
      "Epoch 99/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0034 - mae: 0.0265 - mse: 0.0034 - val_loss: 0.0029 - val_mae: 0.0223 - val_mse: 0.0029\n",
      "Epoch 100/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0021 - mae: 0.0215 - mse: 0.0021 - val_loss: 0.0025 - val_mae: 0.0231 - val_mse: 0.0025\n",
      "Epoch 101/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0021 - mae: 0.0205 - mse: 0.0021 - val_loss: 0.0027 - val_mae: 0.0223 - val_mse: 0.0027\n",
      "Epoch 102/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0019 - mae: 0.0189 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0224 - val_mse: 0.0025\n",
      "Epoch 103/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0016 - mae: 0.0182 - mse: 0.0016 - val_loss: 0.0026 - val_mae: 0.0227 - val_mse: 0.0026\n",
      "Epoch 104/200\n",
      "4222/4222 [==============================] - 1s 189us/step - loss: 0.0021 - mae: 0.0199 - mse: 0.0021 - val_loss: 0.0027 - val_mae: 0.0225 - val_mse: 0.0027\n",
      "Epoch 105/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0016 - mae: 0.0182 - mse: 0.0016 - val_loss: 0.0025 - val_mae: 0.0226 - val_mse: 0.0025\n",
      "Epoch 106/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0021 - mae: 0.0202 - mse: 0.0021 - val_loss: 0.0029 - val_mae: 0.0238 - val_mse: 0.0029\n",
      "Epoch 107/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0020 - mae: 0.0214 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0232 - val_mse: 0.0026\n",
      "Epoch 108/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0015 - mae: 0.0175 - mse: 0.0015 - val_loss: 0.0025 - val_mae: 0.0233 - val_mse: 0.0025\n",
      "Epoch 109/200\n",
      "4222/4222 [==============================] - 1s 186us/step - loss: 0.0026 - mae: 0.0218 - mse: 0.0026 - val_loss: 0.0025 - val_mae: 0.0220 - val_mse: 0.0025\n",
      "Epoch 110/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0015 - mae: 0.0177 - mse: 0.0015 - val_loss: 0.0024 - val_mae: 0.0218 - val_mse: 0.0024\n",
      "Epoch 111/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0020 - mae: 0.0194 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0229 - val_mse: 0.0027\n",
      "Epoch 112/200\n",
      "4222/4222 [==============================] - 1s 187us/step - loss: 0.0015 - mae: 0.0175 - mse: 0.0015 - val_loss: 0.0024 - val_mae: 0.0221 - val_mse: 0.0024\n",
      "Epoch 113/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0020 - mae: 0.0197 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0234 - val_mse: 0.0029\n",
      "Epoch 114/200\n",
      "4222/4222 [==============================] - 1s 190us/step - loss: 0.0017 - mae: 0.0185 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0221 - val_mse: 0.0023\n",
      "Epoch 115/200\n",
      "4222/4222 [==============================] - 1s 189us/step - loss: 0.0019 - mae: 0.0194 - mse: 0.0019 - val_loss: 0.0029 - val_mae: 0.0230 - val_mse: 0.0029\n",
      "Epoch 116/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0026 - val_mae: 0.0222 - val_mse: 0.0026\n",
      "Epoch 117/200\n",
      "4222/4222 [==============================] - 1s 189us/step - loss: 0.0014 - mae: 0.0172 - mse: 0.0014 - val_loss: 0.0025 - val_mae: 0.0226 - val_mse: 0.0025\n",
      "Epoch 118/200\n",
      "4222/4222 [==============================] - 1s 188us/step - loss: 0.0023 - mae: 0.0206 - mse: 0.0023 - val_loss: 0.0025 - val_mae: 0.0221 - val_mse: 0.0025\n",
      "Epoch 119/200\n",
      "4222/4222 [==============================] - 1s 254us/step - loss: 0.0014 - mae: 0.0174 - mse: 0.0014 - val_loss: 0.0023 - val_mae: 0.0215 - val_mse: 0.0023\n",
      "Epoch 120/200\n",
      "4222/4222 [==============================] - 1s 250us/step - loss: 0.0020 - mae: 0.0195 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0227 - val_mse: 0.0028\n",
      "Epoch 121/200\n",
      "4222/4222 [==============================] - 1s 248us/step - loss: 0.0015 - mae: 0.0177 - mse: 0.0015 - val_loss: 0.0024 - val_mae: 0.0228 - val_mse: 0.0024\n",
      "Epoch 122/200\n",
      "4222/4222 [==============================] - 1s 248us/step - loss: 0.0020 - mae: 0.0197 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0220 - val_mse: 0.0028\n",
      "Epoch 123/200\n",
      "4222/4222 [==============================] - 1s 254us/step - loss: 0.0015 - mae: 0.0176 - mse: 0.0015 - val_loss: 0.0023 - val_mae: 0.0216 - val_mse: 0.0023\n",
      "Epoch 124/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0018 - mae: 0.0189 - mse: 0.0018 - val_loss: 0.0028 - val_mae: 0.0224 - val_mse: 0.0028\n",
      "Epoch 125/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0014 - mae: 0.0172 - mse: 0.0014 - val_loss: 0.0024 - val_mae: 0.0220 - val_mse: 0.0024\n",
      "Epoch 126/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0019 - mae: 0.0199 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0215 - val_mse: 0.0027\n",
      "Epoch 127/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0015 - mae: 0.0175 - mse: 0.0015 - val_loss: 0.0022 - val_mae: 0.0208 - val_mse: 0.0022\n",
      "Epoch 128/200\n",
      "4222/4222 [==============================] - 1s 237us/step - loss: 0.0016 - mae: 0.0177 - mse: 0.0016 - val_loss: 0.0024 - val_mae: 0.0222 - val_mse: 0.0024\n",
      "Epoch 129/200\n",
      "4222/4222 [==============================] - 1s 253us/step - loss: 0.0016 - mae: 0.0187 - mse: 0.0016 - val_loss: 0.0024 - val_mae: 0.0213 - val_mse: 0.0024\n",
      "Epoch 130/200\n",
      "4222/4222 [==============================] - 1s 240us/step - loss: 0.0013 - mae: 0.0169 - mse: 0.0013 - val_loss: 0.0022 - val_mae: 0.0216 - val_mse: 0.0022\n",
      "Epoch 131/200\n",
      "4222/4222 [==============================] - 1s 260us/step - loss: 0.0019 - mae: 0.0199 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0214 - val_mse: 0.0026\n",
      "Epoch 132/200\n",
      "4222/4222 [==============================] - 1s 256us/step - loss: 0.0014 - mae: 0.0174 - mse: 0.0014 - val_loss: 0.0023 - val_mae: 0.0215 - val_mse: 0.0023\n",
      "Epoch 133/200\n",
      "4222/4222 [==============================] - 1s 261us/step - loss: 0.0019 - mae: 0.0199 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0212 - val_mse: 0.0026\n",
      "Epoch 134/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0014 - mae: 0.0173 - mse: 0.0014 - val_loss: 0.0022 - val_mae: 0.0206 - val_mse: 0.0022\n",
      "Epoch 135/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0018 - mae: 0.0192 - mse: 0.0018 - val_loss: 0.0025 - val_mae: 0.0206 - val_mse: 0.0025\n",
      "Epoch 136/200\n",
      "4222/4222 [==============================] - 1s 216us/step - loss: 0.0014 - mae: 0.0170 - mse: 0.0014 - val_loss: 0.0022 - val_mae: 0.0205 - val_mse: 0.0022\n",
      "Epoch 137/200\n",
      "4222/4222 [==============================] - 1s 214us/step - loss: 0.0018 - mae: 0.0192 - mse: 0.0018 - val_loss: 0.0026 - val_mae: 0.0206 - val_mse: 0.0026\n",
      "Epoch 138/200\n",
      "4222/4222 [==============================] - 1s 245us/step - loss: 0.0014 - mae: 0.0171 - mse: 0.0014 - val_loss: 0.0027 - val_mae: 0.0235 - val_mse: 0.0027\n",
      "Epoch 139/200\n",
      "4222/4222 [==============================] - 1s 248us/step - loss: 0.0019 - mae: 0.0199 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0203 - val_mse: 0.0025\n",
      "Epoch 140/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0015 - mae: 0.0178 - mse: 0.0015 - val_loss: 0.0022 - val_mae: 0.0199 - val_mse: 0.0022\n",
      "Epoch 141/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0019 - mae: 0.0200 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0211 - val_mse: 0.0026\n",
      "Epoch 142/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0015 - mae: 0.0170 - mse: 0.0015 - val_loss: 0.0025 - val_mae: 0.0213 - val_mse: 0.0025\n",
      "Epoch 143/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0013 - mae: 0.0167 - mse: 0.0013 - val_loss: 0.0023 - val_mae: 0.0203 - val_mse: 0.0023\n",
      "Epoch 144/200\n",
      "4222/4222 [==============================] - 1s 264us/step - loss: 0.0018 - mae: 0.0186 - mse: 0.0018 - val_loss: 0.0025 - val_mae: 0.0199 - val_mse: 0.0025\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0014 - mae: 0.0166 - mse: 0.0014 - val_loss: 0.0023 - val_mae: 0.0205 - val_mse: 0.0023\n",
      "Epoch 146/200\n",
      "4222/4222 [==============================] - 1s 213us/step - loss: 0.0019 - mae: 0.0194 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0204 - val_mse: 0.0026\n",
      "Epoch 147/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0014 - mae: 0.0165 - mse: 0.0014 - val_loss: 0.0024 - val_mae: 0.0202 - val_mse: 0.0024\n",
      "Epoch 148/200\n",
      "4222/4222 [==============================] - 1s 259us/step - loss: 0.0017 - mae: 0.0180 - mse: 0.0017 - val_loss: 0.0025 - val_mae: 0.0202 - val_mse: 0.0025\n",
      "Epoch 149/200\n",
      "4222/4222 [==============================] - 1s 234us/step - loss: 0.0013 - mae: 0.0162 - mse: 0.0013 - val_loss: 0.0023 - val_mae: 0.0200 - val_mse: 0.0023\n",
      "Epoch 150/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0018 - mae: 0.0187 - mse: 0.0018 - val_loss: 0.0026 - val_mae: 0.0202 - val_mse: 0.0026\n",
      "Epoch 151/200\n",
      "4222/4222 [==============================] - 1s 206us/step - loss: 0.0014 - mae: 0.0161 - mse: 0.0014 - val_loss: 0.0027 - val_mae: 0.0215 - val_mse: 0.0027\n",
      "Epoch 152/200\n",
      "4222/4222 [==============================] - 1s 217us/step - loss: 0.0014 - mae: 0.0171 - mse: 0.0014 - val_loss: 0.0024 - val_mae: 0.0204 - val_mse: 0.0024\n",
      "Epoch 153/200\n",
      "4222/4222 [==============================] - 1s 212us/step - loss: 0.0018 - mae: 0.0190 - mse: 0.0018 - val_loss: 0.0026 - val_mae: 0.0203 - val_mse: 0.0026\n",
      "Epoch 154/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0014 - mae: 0.0163 - mse: 0.0014 - val_loss: 0.0024 - val_mae: 0.0204 - val_mse: 0.0024\n",
      "Epoch 155/200\n",
      "4222/4222 [==============================] - 1s 211us/step - loss: 0.0017 - mae: 0.0182 - mse: 0.0017 - val_loss: 0.0025 - val_mae: 0.0200 - val_mse: 0.0025\n",
      "Epoch 156/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0013 - mae: 0.0159 - mse: 0.0013 - val_loss: 0.0023 - val_mae: 0.0199 - val_mse: 0.0023\n",
      "Epoch 157/200\n",
      "4222/4222 [==============================] - 1s 233us/step - loss: 0.0017 - mae: 0.0181 - mse: 0.0017 - val_loss: 0.0025 - val_mae: 0.0201 - val_mse: 0.0025\n",
      "Epoch 158/200\n",
      "4222/4222 [==============================] - 1s 257us/step - loss: 0.0012 - mae: 0.0157 - mse: 0.0012 - val_loss: 0.0023 - val_mae: 0.0198 - val_mse: 0.0023\n",
      "Epoch 159/200\n",
      "4222/4222 [==============================] - 1s 241us/step - loss: 0.0017 - mae: 0.0182 - mse: 0.0017 - val_loss: 0.0025 - val_mae: 0.0199 - val_mse: 0.0025\n",
      "Epoch 160/200\n",
      "4222/4222 [==============================] - 1s 249us/step - loss: 0.0012 - mae: 0.0156 - mse: 0.0012 - val_loss: 0.0024 - val_mae: 0.0201 - val_mse: 0.0024\n",
      "Epoch 161/200\n",
      "4222/4222 [==============================] - 1s 247us/step - loss: 0.0017 - mae: 0.0183 - mse: 0.0017 - val_loss: 0.0025 - val_mae: 0.0195 - val_mse: 0.0025\n",
      "Epoch 162/200\n",
      "4222/4222 [==============================] - 1s 253us/step - loss: 0.0012 - mae: 0.0159 - mse: 0.0012 - val_loss: 0.0024 - val_mae: 0.0209 - val_mse: 0.0024\n",
      "Epoch 163/200\n",
      "4222/4222 [==============================] - 1s 249us/step - loss: 0.0016 - mae: 0.0178 - mse: 0.0016 - val_loss: 0.0021 - val_mae: 0.0195 - val_mse: 0.0021\n",
      "Epoch 164/200\n",
      "4222/4222 [==============================] - 1s 239us/step - loss: 0.0012 - mae: 0.0153 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0184 - val_mse: 0.0021\n",
      "Epoch 165/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0016 - mae: 0.0182 - mse: 0.0016 - val_loss: 0.0023 - val_mae: 0.0192 - val_mse: 0.0023\n",
      "Epoch 166/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0013 - mae: 0.0160 - mse: 0.0013 - val_loss: 0.0024 - val_mae: 0.0218 - val_mse: 0.0024\n",
      "Epoch 167/200\n",
      "4222/4222 [==============================] - 1s 219us/step - loss: 0.0018 - mae: 0.0184 - mse: 0.0018 - val_loss: 0.0025 - val_mae: 0.0201 - val_mse: 0.0025\n",
      "Epoch 168/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0012 - mae: 0.0152 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0183 - val_mse: 0.0021\n",
      "Epoch 169/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0016 - mae: 0.0179 - mse: 0.0016 - val_loss: 0.0020 - val_mae: 0.0190 - val_mse: 0.0020\n",
      "Epoch 170/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0011 - mae: 0.0146 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0186 - val_mse: 0.0020\n",
      "Epoch 171/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0016 - mae: 0.0179 - mse: 0.0016 - val_loss: 0.0022 - val_mae: 0.0189 - val_mse: 0.0022\n",
      "Epoch 172/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0012 - mae: 0.0155 - mse: 0.0012 - val_loss: 0.0020 - val_mae: 0.0185 - val_mse: 0.0020\n",
      "Epoch 173/200\n",
      "4222/4222 [==============================] - 1s 222us/step - loss: 0.0017 - mae: 0.0180 - mse: 0.0017 - val_loss: 0.0025 - val_mae: 0.0201 - val_mse: 0.0025\n",
      "Epoch 174/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0013 - mae: 0.0158 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0193 - val_mse: 0.0020\n",
      "Epoch 175/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0017 - mae: 0.0179 - mse: 0.0017 - val_loss: 0.0024 - val_mae: 0.0200 - val_mse: 0.0024\n",
      "Epoch 176/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0012 - mae: 0.0149 - mse: 0.0012 - val_loss: 0.0020 - val_mae: 0.0183 - val_mse: 0.0020\n",
      "Epoch 177/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0017 - mae: 0.0189 - mse: 0.0017 - val_loss: 0.0024 - val_mae: 0.0200 - val_mse: 0.0024\n",
      "Epoch 178/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0013 - mae: 0.0157 - mse: 0.0013 - val_loss: 0.0021 - val_mae: 0.0190 - val_mse: 0.0021\n",
      "Epoch 179/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0015 - mae: 0.0168 - mse: 0.0015 - val_loss: 0.0019 - val_mae: 0.0190 - val_mse: 0.0019\n",
      "Epoch 180/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0011 - mae: 0.0145 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0179 - val_mse: 0.0020\n",
      "Epoch 181/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0016 - mae: 0.0175 - mse: 0.0016 - val_loss: 0.0024 - val_mae: 0.0194 - val_mse: 0.0024\n",
      "Epoch 182/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0014 - mae: 0.0157 - mse: 0.0014 - val_loss: 0.0022 - val_mae: 0.0195 - val_mse: 0.0022\n",
      "Epoch 183/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0011 - mae: 0.0147 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0184 - val_mse: 0.0020\n",
      "Epoch 184/200\n",
      "4222/4222 [==============================] - 1s 229us/step - loss: 0.0018 - mae: 0.0184 - mse: 0.0018 - val_loss: 0.0024 - val_mae: 0.0191 - val_mse: 0.0024\n",
      "Epoch 185/200\n",
      "4222/4222 [==============================] - 1s 225us/step - loss: 0.0013 - mae: 0.0150 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0189 - val_mse: 0.0020\n",
      "Epoch 186/200\n",
      "4222/4222 [==============================] - 1s 226us/step - loss: 0.0012 - mae: 0.0146 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0189 - val_mse: 0.0021\n",
      "Epoch 187/200\n",
      "4222/4222 [==============================] - 1s 227us/step - loss: 0.0015 - mae: 0.0165 - mse: 0.0015 - val_loss: 0.0020 - val_mae: 0.0188 - val_mse: 0.0020\n",
      "Epoch 188/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0011 - mae: 0.0149 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0181 - val_mse: 0.0020\n",
      "Epoch 189/200\n",
      "4222/4222 [==============================] - 1s 224us/step - loss: 0.0017 - mae: 0.0172 - mse: 0.0017 - val_loss: 0.0024 - val_mae: 0.0201 - val_mse: 0.0024\n",
      "Epoch 190/200\n",
      "4222/4222 [==============================] - 1s 223us/step - loss: 0.0012 - mae: 0.0148 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0183 - val_mse: 0.0021\n",
      "Epoch 191/200\n",
      "4222/4222 [==============================] - 1s 221us/step - loss: 0.0014 - mae: 0.0159 - mse: 0.0014 - val_loss: 0.0020 - val_mae: 0.0189 - val_mse: 0.0020\n",
      "Epoch 192/200\n",
      "4222/4222 [==============================] - 1s 228us/step - loss: 0.0011 - mae: 0.0146 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0183 - val_mse: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0017 - mae: 0.0177 - mse: 0.0017 - val_loss: 0.0024 - val_mae: 0.0196 - val_mse: 0.0024\n",
      "Epoch 194/200\n",
      "4222/4222 [==============================] - 1s 207us/step - loss: 0.0013 - mae: 0.0149 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0183 - val_mse: 0.0020\n",
      "Epoch 195/200\n",
      "4222/4222 [==============================] - 1s 206us/step - loss: 0.0011 - mae: 0.0147 - mse: 0.0011 - val_loss: 0.0021 - val_mae: 0.0181 - val_mse: 0.0021\n",
      "Epoch 196/200\n",
      "4222/4222 [==============================] - 1s 208us/step - loss: 0.0017 - mae: 0.0174 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0203 - val_mse: 0.0023\n",
      "Epoch 197/200\n",
      "4222/4222 [==============================] - 1s 210us/step - loss: 0.0015 - mae: 0.0162 - mse: 0.0015 - val_loss: 0.0024 - val_mae: 0.0193 - val_mse: 0.0024\n",
      "Epoch 198/200\n",
      "4222/4222 [==============================] - 1s 205us/step - loss: 0.0012 - mae: 0.0155 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0186 - val_mse: 0.0021\n",
      "Epoch 199/200\n",
      "4222/4222 [==============================] - 1s 209us/step - loss: 0.0019 - mae: 0.0188 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0200 - val_mse: 0.0022\n",
      "Epoch 200/200\n",
      "4222/4222 [==============================] - 1s 206us/step - loss: 0.0013 - mae: 0.0148 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0184 - val_mse: 0.0020\n"
     ]
    }
   ],
   "source": [
    "# Reuse No-mobility Data\n",
    "# X_LSTM_nomob, y_LSTM_nomob = get_LSTM_states_dataset(state_cases_df, n_steps=N_STEPS)\n",
    "# X_train_LSTM_nomob, X_test_LSTM_nomob, y_train_LSTM_nomob, y_test_LSTM_nomob = train_test_split(X_LSTM_nomob, y_LSTM_nomob, test_size=SPLIT, shuffle=False)\n",
    "\n",
    "# Set up model\n",
    "n_lstm_features = X_train_LSTM_nomob.shape[2]\n",
    "slstm_nomob = get_lstm(N_STEPS, n_lstm_features)\n",
    "\n",
    "# Fit LSTM\n",
    "slstm_nomob_history = slstm_nomob.fit(X_train_LSTM_nomob, y_train_LSTM_nomob,\n",
    "                                     epochs=EPOCHS,\n",
    "                                     validation_data=(X_test_LSTM_nomob, y_test_LSTM_nomob),\n",
    "                                     verbose=1,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model with Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up CNN, Boo's model\n",
    "def get_CNN_model(n_steps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, \n",
    "                     activation='relu', \n",
    "                     input_shape=(n_steps, n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "n_CNN_features = X_train_CNN.shape[2]\n",
    "cnn = get_CNN_model(N_STEPS, n_CNN_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2440 samples, validate on 610 samples\n",
      "Epoch 1/200\n",
      "2440/2440 [==============================] - 0s 170us/step - loss: 0.0377 - mae: 0.1216 - mse: 0.0377 - val_loss: 0.0055 - val_mae: 0.0541 - val_mse: 0.0055\n",
      "Epoch 2/200\n",
      "2440/2440 [==============================] - 0s 56us/step - loss: 0.0034 - mae: 0.0453 - mse: 0.0034 - val_loss: 0.0028 - val_mae: 0.0359 - val_mse: 0.0028\n",
      "Epoch 3/200\n",
      "2440/2440 [==============================] - 0s 53us/step - loss: 0.0022 - mae: 0.0351 - mse: 0.0022 - val_loss: 0.0022 - val_mae: 0.0335 - val_mse: 0.0022\n",
      "Epoch 4/200\n",
      "2440/2440 [==============================] - 0s 54us/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0020\n",
      "Epoch 5/200\n",
      "2440/2440 [==============================] - 0s 53us/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0014 - val_loss: 0.0020 - val_mae: 0.0326 - val_mse: 0.0020\n",
      "Epoch 6/200\n",
      "2440/2440 [==============================] - 0s 50us/step - loss: 0.0012 - mae: 0.0258 - mse: 0.0012 - val_loss: 0.0020 - val_mae: 0.0331 - val_mse: 0.0020\n",
      "Epoch 7/200\n",
      "2440/2440 [==============================] - 0s 69us/step - loss: 0.0012 - mae: 0.0249 - mse: 0.0012 - val_loss: 0.0020 - val_mae: 0.0342 - val_mse: 0.0020\n",
      "Epoch 8/200\n",
      "2440/2440 [==============================] - 0s 55us/step - loss: 0.0011 - mae: 0.0244 - mse: 0.0011 - val_loss: 0.0019 - val_mae: 0.0331 - val_mse: 0.0019\n",
      "Epoch 9/200\n",
      "2440/2440 [==============================] - 0s 56us/step - loss: 0.0011 - mae: 0.0238 - mse: 0.0011 - val_loss: 0.0018 - val_mae: 0.0332 - val_mse: 0.0018\n",
      "Epoch 10/200\n",
      "2440/2440 [==============================] - 0s 54us/step - loss: 0.0010 - mae: 0.0238 - mse: 0.0010 - val_loss: 0.0019 - val_mae: 0.0347 - val_mse: 0.0019\n",
      "Epoch 11/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 0.0010 - mae: 0.0237 - mse: 0.0010 - val_loss: 0.0019 - val_mae: 0.0349 - val_mse: 0.0019\n",
      "Epoch 12/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 9.7491e-04 - mae: 0.0232 - mse: 9.7491e-04 - val_loss: 0.0018 - val_mae: 0.0348 - val_mse: 0.0018\n",
      "Epoch 13/200\n",
      "2440/2440 [==============================] - 0s 53us/step - loss: 9.5635e-04 - mae: 0.0230 - mse: 9.5635e-04 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0019\n",
      "Epoch 14/200\n",
      "2440/2440 [==============================] - 0s 64us/step - loss: 8.9301e-04 - mae: 0.0220 - mse: 8.9301e-04 - val_loss: 0.0017 - val_mae: 0.0345 - val_mse: 0.0017\n",
      "Epoch 15/200\n",
      "2440/2440 [==============================] - 0s 60us/step - loss: 8.3805e-04 - mae: 0.0211 - mse: 8.3805e-04 - val_loss: 0.0018 - val_mae: 0.0346 - val_mse: 0.0018\n",
      "Epoch 16/200\n",
      "2440/2440 [==============================] - 0s 52us/step - loss: 7.7943e-04 - mae: 0.0202 - mse: 7.7943e-04 - val_loss: 0.0017 - val_mae: 0.0342 - val_mse: 0.0017\n",
      "Epoch 17/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 7.3283e-04 - mae: 0.0195 - mse: 7.3283e-04 - val_loss: 0.0016 - val_mae: 0.0330 - val_mse: 0.0016\n",
      "Epoch 18/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 7.0438e-04 - mae: 0.0192 - mse: 7.0438e-04 - val_loss: 0.0017 - val_mae: 0.0335 - val_mse: 0.0017\n",
      "Epoch 19/200\n",
      "2440/2440 [==============================] - 0s 65us/step - loss: 6.8470e-04 - mae: 0.0189 - mse: 6.8470e-04 - val_loss: 0.0016 - val_mae: 0.0327 - val_mse: 0.0016\n",
      "Epoch 20/200\n",
      "2440/2440 [==============================] - 0s 63us/step - loss: 6.5672e-04 - mae: 0.0185 - mse: 6.5672e-04 - val_loss: 0.0015 - val_mae: 0.0313 - val_mse: 0.0015\n",
      "Epoch 21/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 6.4320e-04 - mae: 0.0184 - mse: 6.4320e-04 - val_loss: 0.0014 - val_mae: 0.0307 - val_mse: 0.0014\n",
      "Epoch 22/200\n",
      "2440/2440 [==============================] - 0s 60us/step - loss: 6.2430e-04 - mae: 0.0181 - mse: 6.2430e-04 - val_loss: 0.0014 - val_mae: 0.0305 - val_mse: 0.0014\n",
      "Epoch 23/200\n",
      "2440/2440 [==============================] - 0s 61us/step - loss: 6.0679e-04 - mae: 0.0178 - mse: 6.0679e-04 - val_loss: 0.0014 - val_mae: 0.0303 - val_mse: 0.0014\n",
      "Epoch 24/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 5.9030e-04 - mae: 0.0176 - mse: 5.9030e-04 - val_loss: 0.0014 - val_mae: 0.0297 - val_mse: 0.0014\n",
      "Epoch 25/200\n",
      "2440/2440 [==============================] - 0s 56us/step - loss: 5.7111e-04 - mae: 0.0173 - mse: 5.7111e-04 - val_loss: 0.0014 - val_mae: 0.0298 - val_mse: 0.0014\n",
      "Epoch 26/200\n",
      "2440/2440 [==============================] - 0s 50us/step - loss: 5.6334e-04 - mae: 0.0171 - mse: 5.6334e-04 - val_loss: 0.0013 - val_mae: 0.0291 - val_mse: 0.0013\n",
      "Epoch 27/200\n",
      "2440/2440 [==============================] - 0s 50us/step - loss: 5.3804e-04 - mae: 0.0167 - mse: 5.3804e-04 - val_loss: 0.0013 - val_mae: 0.0286 - val_mse: 0.0013\n",
      "Epoch 28/200\n",
      "2440/2440 [==============================] - 0s 58us/step - loss: 5.3503e-04 - mae: 0.0167 - mse: 5.3503e-04 - val_loss: 0.0013 - val_mae: 0.0281 - val_mse: 0.0013\n",
      "Epoch 29/200\n",
      "2440/2440 [==============================] - 0s 58us/step - loss: 5.2198e-04 - mae: 0.0165 - mse: 5.2198e-04 - val_loss: 0.0013 - val_mae: 0.0284 - val_mse: 0.0013\n",
      "Epoch 30/200\n",
      "2440/2440 [==============================] - 0s 60us/step - loss: 5.1933e-04 - mae: 0.0165 - mse: 5.1933e-04 - val_loss: 0.0013 - val_mae: 0.0295 - val_mse: 0.0013\n",
      "Epoch 31/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 5.1808e-04 - mae: 0.0165 - mse: 5.1808e-04 - val_loss: 0.0013 - val_mae: 0.0293 - val_mse: 0.0013\n",
      "Epoch 32/200\n",
      "2440/2440 [==============================] - 0s 60us/step - loss: 5.0693e-04 - mae: 0.0164 - mse: 5.0693e-04 - val_loss: 0.0013 - val_mae: 0.0288 - val_mse: 0.0013\n",
      "Epoch 33/200\n",
      "2440/2440 [==============================] - 0s 60us/step - loss: 4.9378e-04 - mae: 0.0161 - mse: 4.9378e-04 - val_loss: 0.0013 - val_mae: 0.0287 - val_mse: 0.0013\n",
      "Epoch 34/200\n",
      "2440/2440 [==============================] - 0s 58us/step - loss: 4.8143e-04 - mae: 0.0158 - mse: 4.8143e-04 - val_loss: 0.0012 - val_mae: 0.0278 - val_mse: 0.0012\n",
      "Epoch 35/200\n",
      "2440/2440 [==============================] - 0s 54us/step - loss: 4.6825e-04 - mae: 0.0156 - mse: 4.6825e-04 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012\n",
      "Epoch 36/200\n",
      "2440/2440 [==============================] - 0s 62us/step - loss: 4.6596e-04 - mae: 0.0156 - mse: 4.6596e-04 - val_loss: 0.0012 - val_mae: 0.0266 - val_mse: 0.0012\n",
      "Epoch 37/200\n",
      "2440/2440 [==============================] - 0s 67us/step - loss: 4.5228e-04 - mae: 0.0154 - mse: 4.5228e-04 - val_loss: 0.0011 - val_mae: 0.0262 - val_mse: 0.0011\n",
      "Epoch 38/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 4.5205e-04 - mae: 0.0154 - mse: 4.5205e-04 - val_loss: 0.0011 - val_mae: 0.0260 - val_mse: 0.0011\n",
      "Epoch 39/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 4.3709e-04 - mae: 0.0151 - mse: 4.3709e-04 - val_loss: 0.0011 - val_mae: 0.0263 - val_mse: 0.0011\n",
      "Epoch 40/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 4.3616e-04 - mae: 0.0151 - mse: 4.3616e-04 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011\n",
      "Epoch 41/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 4.2795e-04 - mae: 0.0150 - mse: 4.2795e-04 - val_loss: 0.0011 - val_mae: 0.0263 - val_mse: 0.0011\n",
      "Epoch 42/200\n",
      "2440/2440 [==============================] - 0s 51us/step - loss: 4.2386e-04 - mae: 0.0149 - mse: 4.2386e-04 - val_loss: 0.0011 - val_mae: 0.0261 - val_mse: 0.0011\n",
      "Epoch 43/200\n",
      "2440/2440 [==============================] - 0s 51us/step - loss: 4.1098e-04 - mae: 0.0147 - mse: 4.1098e-04 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 0.0011\n",
      "Epoch 44/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 4.0412e-04 - mae: 0.0146 - mse: 4.0412e-04 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 0.0011\n",
      "Epoch 45/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 4.0915e-04 - mae: 0.0147 - mse: 4.0915e-04 - val_loss: 0.0011 - val_mae: 0.0258 - val_mse: 0.0011\n",
      "Epoch 46/200\n",
      "2440/2440 [==============================] - 0s 49us/step - loss: 4.0318e-04 - mae: 0.0146 - mse: 4.0318e-04 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/2440 [==============================] - 0s 48us/step - loss: 3.9194e-04 - mae: 0.0144 - mse: 3.9194e-04 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011\n",
      "Epoch 48/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.9151e-04 - mae: 0.0144 - mse: 3.9151e-04 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 0.0011\n",
      "Epoch 49/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.8655e-04 - mae: 0.0144 - mse: 3.8655e-04 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 0.0011\n",
      "Epoch 50/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.8384e-04 - mae: 0.0144 - mse: 3.8384e-04 - val_loss: 0.0011 - val_mae: 0.0250 - val_mse: 0.0011\n",
      "Epoch 51/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 3.7370e-04 - mae: 0.0142 - mse: 3.7370e-04 - val_loss: 0.0010 - val_mae: 0.0249 - val_mse: 0.0010\n",
      "Epoch 52/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 3.7698e-04 - mae: 0.0144 - mse: 3.7698e-04 - val_loss: 0.0010 - val_mae: 0.0246 - val_mse: 0.0010\n",
      "Epoch 53/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.7110e-04 - mae: 0.0142 - mse: 3.7110e-04 - val_loss: 9.7880e-04 - val_mae: 0.0236 - val_mse: 9.7880e-04\n",
      "Epoch 54/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.6919e-04 - mae: 0.0142 - mse: 3.6919e-04 - val_loss: 9.7889e-04 - val_mae: 0.0236 - val_mse: 9.7889e-04\n",
      "Epoch 55/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.8377e-04 - mae: 0.0146 - mse: 3.8377e-04 - val_loss: 9.4912e-04 - val_mae: 0.0228 - val_mse: 9.4912e-04\n",
      "Epoch 56/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.8539e-04 - mae: 0.0147 - mse: 3.8539e-04 - val_loss: 8.9602e-04 - val_mae: 0.0214 - val_mse: 8.9602e-04\n",
      "Epoch 57/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.7973e-04 - mae: 0.0144 - mse: 3.7973e-04 - val_loss: 8.5786e-04 - val_mae: 0.0203 - val_mse: 8.5786e-04\n",
      "Epoch 58/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.7240e-04 - mae: 0.0141 - mse: 3.7240e-04 - val_loss: 8.7478e-04 - val_mae: 0.0209 - val_mse: 8.7478e-04\n",
      "Epoch 59/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.4503e-04 - mae: 0.0136 - mse: 3.4503e-04 - val_loss: 8.3228e-04 - val_mae: 0.0200 - val_mse: 8.3228e-04\n",
      "Epoch 60/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.4485e-04 - mae: 0.0137 - mse: 3.4485e-04 - val_loss: 8.2515e-04 - val_mae: 0.0198 - val_mse: 8.2515e-04\n",
      "Epoch 61/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.3709e-04 - mae: 0.0133 - mse: 3.3709e-04 - val_loss: 8.4565e-04 - val_mae: 0.0203 - val_mse: 8.4565e-04\n",
      "Epoch 62/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.2368e-04 - mae: 0.0130 - mse: 3.2368e-04 - val_loss: 8.4454e-04 - val_mae: 0.0204 - val_mse: 8.4454e-04\n",
      "Epoch 63/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.2171e-04 - mae: 0.0128 - mse: 3.2171e-04 - val_loss: 8.9896e-04 - val_mae: 0.0217 - val_mse: 8.9896e-04\n",
      "Epoch 64/200\n",
      "2440/2440 [==============================] - 0s 38us/step - loss: 3.5043e-04 - mae: 0.0133 - mse: 3.5043e-04 - val_loss: 9.5838e-04 - val_mae: 0.0230 - val_mse: 9.5838e-04\n",
      "Epoch 65/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.7854e-04 - mae: 0.0136 - mse: 3.7854e-04 - val_loss: 9.8693e-04 - val_mae: 0.0238 - val_mse: 9.8693e-04\n",
      "Epoch 66/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.5468e-04 - mae: 0.0134 - mse: 3.5468e-04 - val_loss: 8.0512e-04 - val_mae: 0.0193 - val_mse: 8.0512e-04\n",
      "Epoch 67/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 3.8123e-04 - mae: 0.0139 - mse: 3.8123e-04 - val_loss: 7.3409e-04 - val_mae: 0.0171 - val_mse: 7.3409e-04\n",
      "Epoch 68/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.7560e-04 - mae: 0.0142 - mse: 3.7560e-04 - val_loss: 7.9741e-04 - val_mae: 0.0186 - val_mse: 7.9741e-04\n",
      "Epoch 69/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.8482e-04 - mae: 0.0143 - mse: 3.8482e-04 - val_loss: 8.0185e-04 - val_mae: 0.0180 - val_mse: 8.0185e-04\n",
      "Epoch 70/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.7930e-04 - mae: 0.0143 - mse: 3.7930e-04 - val_loss: 7.2475e-04 - val_mae: 0.0170 - val_mse: 7.2475e-04\n",
      "Epoch 71/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.1063e-04 - mae: 0.0128 - mse: 3.1063e-04 - val_loss: 7.7167e-04 - val_mae: 0.0181 - val_mse: 7.7167e-04\n",
      "Epoch 72/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.2702e-04 - mae: 0.0127 - mse: 3.2702e-04 - val_loss: 0.0010 - val_mae: 0.0227 - val_mse: 0.0010\n",
      "Epoch 73/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.8243e-04 - mae: 0.0135 - mse: 3.8243e-04 - val_loss: 7.9391e-04 - val_mae: 0.0182 - val_mse: 7.9391e-04\n",
      "Epoch 74/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.9131e-04 - mae: 0.0138 - mse: 3.9131e-04 - val_loss: 7.1823e-04 - val_mae: 0.0171 - val_mse: 7.1823e-04\n",
      "Epoch 75/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.0295e-04 - mae: 0.0124 - mse: 3.0295e-04 - val_loss: 7.3029e-04 - val_mae: 0.0169 - val_mse: 7.3029e-04\n",
      "Epoch 76/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 2.9893e-04 - mae: 0.0122 - mse: 2.9893e-04 - val_loss: 7.9868e-04 - val_mae: 0.0180 - val_mse: 7.9868e-04\n",
      "Epoch 77/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.7673e-04 - mae: 0.0136 - mse: 3.7673e-04 - val_loss: 8.3371e-04 - val_mae: 0.0187 - val_mse: 8.3371e-04\n",
      "Epoch 78/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.5707e-04 - mae: 0.0132 - mse: 3.5707e-04 - val_loss: 7.4787e-04 - val_mae: 0.0174 - val_mse: 7.4787e-04\n",
      "Epoch 79/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.7218e-04 - mae: 0.0137 - mse: 3.7218e-04 - val_loss: 7.6930e-04 - val_mae: 0.0176 - val_mse: 7.6930e-04\n",
      "Epoch 80/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.9117e-04 - mae: 0.0141 - mse: 3.9117e-04 - val_loss: 7.5924e-04 - val_mae: 0.0175 - val_mse: 7.5924e-04\n",
      "Epoch 81/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 4.2612e-04 - mae: 0.0148 - mse: 4.2612e-04 - val_loss: 7.3512e-04 - val_mae: 0.0174 - val_mse: 7.3512e-04\n",
      "Epoch 82/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.9669e-04 - mae: 0.0143 - mse: 3.9669e-04 - val_loss: 8.9064e-04 - val_mae: 0.0212 - val_mse: 8.9064e-04\n",
      "Epoch 83/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 5.0157e-04 - mae: 0.0160 - mse: 5.0157e-04 - val_loss: 0.0013 - val_mae: 0.0272 - val_mse: 0.0013\n",
      "Epoch 84/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 5.2242e-04 - mae: 0.0160 - mse: 5.2242e-04 - val_loss: 8.5114e-04 - val_mae: 0.0190 - val_mse: 8.5114e-04\n",
      "Epoch 85/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.5318e-04 - mae: 0.0130 - mse: 3.5318e-04 - val_loss: 8.6654e-04 - val_mae: 0.0191 - val_mse: 8.6654e-04\n",
      "Epoch 86/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.1013e-04 - mae: 0.0122 - mse: 3.1013e-04 - val_loss: 8.1853e-04 - val_mae: 0.0185 - val_mse: 8.1853e-04\n",
      "Epoch 87/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.1433e-04 - mae: 0.0124 - mse: 3.1433e-04 - val_loss: 9.3327e-04 - val_mae: 0.0207 - val_mse: 9.3327e-04\n",
      "Epoch 88/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.2493e-04 - mae: 0.0126 - mse: 3.2493e-04 - val_loss: 8.0529e-04 - val_mae: 0.0182 - val_mse: 8.0529e-04\n",
      "Epoch 89/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 2.9060e-04 - mae: 0.0119 - mse: 2.9060e-04 - val_loss: 8.5001e-04 - val_mae: 0.0191 - val_mse: 8.5001e-04\n",
      "Epoch 90/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 2.8778e-04 - mae: 0.0119 - mse: 2.8778e-04 - val_loss: 8.1665e-04 - val_mae: 0.0185 - val_mse: 8.1665e-04\n",
      "Epoch 91/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 2.8849e-04 - mae: 0.0120 - mse: 2.8849e-04 - val_loss: 8.1982e-04 - val_mae: 0.0186 - val_mse: 8.1982e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 2.7985e-04 - mae: 0.0118 - mse: 2.7985e-04 - val_loss: 8.2504e-04 - val_mae: 0.0185 - val_mse: 8.2504e-04\n",
      "Epoch 93/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 2.7510e-04 - mae: 0.0117 - mse: 2.7510e-04 - val_loss: 7.9566e-04 - val_mae: 0.0179 - val_mse: 7.9566e-04\n",
      "Epoch 94/200\n",
      "2440/2440 [==============================] - 0s 53us/step - loss: 2.7008e-04 - mae: 0.0116 - mse: 2.7008e-04 - val_loss: 8.0897e-04 - val_mae: 0.0182 - val_mse: 8.0897e-04\n",
      "Epoch 95/200\n",
      "2440/2440 [==============================] - 0s 59us/step - loss: 2.6876e-04 - mae: 0.0115 - mse: 2.6876e-04 - val_loss: 8.1042e-04 - val_mae: 0.0181 - val_mse: 8.1042e-04\n",
      "Epoch 96/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 2.6846e-04 - mae: 0.0115 - mse: 2.6846e-04 - val_loss: 8.1431e-04 - val_mae: 0.0181 - val_mse: 8.1431e-04\n",
      "Epoch 97/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.6908e-04 - mae: 0.0116 - mse: 2.6908e-04 - val_loss: 7.9004e-04 - val_mae: 0.0176 - val_mse: 7.9004e-04\n",
      "Epoch 98/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 2.6630e-04 - mae: 0.0115 - mse: 2.6630e-04 - val_loss: 7.8532e-04 - val_mae: 0.0174 - val_mse: 7.8532e-04\n",
      "Epoch 99/200\n",
      "2440/2440 [==============================] - 0s 56us/step - loss: 2.6750e-04 - mae: 0.0115 - mse: 2.6750e-04 - val_loss: 7.8838e-04 - val_mae: 0.0176 - val_mse: 7.8838e-04\n",
      "Epoch 100/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 2.6817e-04 - mae: 0.0115 - mse: 2.6817e-04 - val_loss: 7.9960e-04 - val_mae: 0.0176 - val_mse: 7.9960e-04\n",
      "Epoch 101/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.7751e-04 - mae: 0.0118 - mse: 2.7751e-04 - val_loss: 8.0957e-04 - val_mae: 0.0180 - val_mse: 8.0957e-04\n",
      "Epoch 102/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 2.8506e-04 - mae: 0.0120 - mse: 2.8506e-04 - val_loss: 8.0926e-04 - val_mae: 0.0179 - val_mse: 8.0926e-04\n",
      "Epoch 103/200\n",
      "2440/2440 [==============================] - 0s 56us/step - loss: 2.8649e-04 - mae: 0.0120 - mse: 2.8649e-04 - val_loss: 8.0170e-04 - val_mae: 0.0181 - val_mse: 8.0170e-04\n",
      "Epoch 104/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 2.9514e-04 - mae: 0.0121 - mse: 2.9514e-04 - val_loss: 8.2289e-04 - val_mae: 0.0182 - val_mse: 8.2289e-04\n",
      "Epoch 105/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.9071e-04 - mae: 0.0121 - mse: 2.9071e-04 - val_loss: 8.2736e-04 - val_mae: 0.0181 - val_mse: 8.2736e-04\n",
      "Epoch 106/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 2.8966e-04 - mae: 0.0120 - mse: 2.8966e-04 - val_loss: 8.2134e-04 - val_mae: 0.0182 - val_mse: 8.2134e-04\n",
      "Epoch 107/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 2.9408e-04 - mae: 0.0121 - mse: 2.9408e-04 - val_loss: 8.2991e-04 - val_mae: 0.0179 - val_mse: 8.2991e-04\n",
      "Epoch 108/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 2.8520e-04 - mae: 0.0119 - mse: 2.8520e-04 - val_loss: 8.5055e-04 - val_mae: 0.0181 - val_mse: 8.5055e-04\n",
      "Epoch 109/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 2.9522e-04 - mae: 0.0120 - mse: 2.9522e-04 - val_loss: 8.3984e-04 - val_mae: 0.0181 - val_mse: 8.3984e-04\n",
      "Epoch 110/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.0358e-04 - mae: 0.0123 - mse: 3.0358e-04 - val_loss: 8.6074e-04 - val_mae: 0.0185 - val_mse: 8.6074e-04\n",
      "Epoch 111/200\n",
      "2440/2440 [==============================] - 0s 51us/step - loss: 3.4235e-04 - mae: 0.0130 - mse: 3.4235e-04 - val_loss: 8.6812e-04 - val_mae: 0.0185 - val_mse: 8.6812e-04\n",
      "Epoch 112/200\n",
      "2440/2440 [==============================] - 0s 55us/step - loss: 3.7463e-04 - mae: 0.0136 - mse: 3.7463e-04 - val_loss: 9.5386e-04 - val_mae: 0.0200 - val_mse: 9.5386e-04\n",
      "Epoch 113/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 5.5182e-04 - mae: 0.0164 - mse: 5.5182e-04 - val_loss: 9.1147e-04 - val_mae: 0.0195 - val_mse: 9.1147e-04\n",
      "Epoch 114/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 5.2017e-04 - mae: 0.0160 - mse: 5.2017e-04 - val_loss: 0.0012 - val_mae: 0.0233 - val_mse: 0.0012\n",
      "Epoch 115/200\n",
      "2440/2440 [==============================] - 0s 56us/step - loss: 4.3339e-04 - mae: 0.0145 - mse: 4.3339e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 0.0011\n",
      "Epoch 116/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 4.0474e-04 - mae: 0.0143 - mse: 4.0474e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 0.0011\n",
      "Epoch 117/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.4603e-04 - mae: 0.0130 - mse: 3.4603e-04 - val_loss: 0.0011 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 118/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.3784e-04 - mae: 0.0129 - mse: 3.3784e-04 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0012\n",
      "Epoch 119/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 3.2854e-04 - mae: 0.0125 - mse: 3.2854e-04 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 0.0011\n",
      "Epoch 120/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.1984e-04 - mae: 0.0123 - mse: 3.1984e-04 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0012\n",
      "Epoch 121/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.1169e-04 - mae: 0.0121 - mse: 3.1169e-04 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0012\n",
      "Epoch 122/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.1805e-04 - mae: 0.0122 - mse: 3.1805e-04 - val_loss: 0.0013 - val_mae: 0.0263 - val_mse: 0.0013\n",
      "Epoch 123/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 3.1559e-04 - mae: 0.0122 - mse: 3.1559e-04 - val_loss: 0.0013 - val_mae: 0.0264 - val_mse: 0.0013\n",
      "Epoch 124/200\n",
      "2440/2440 [==============================] - 0s 63us/step - loss: 3.2348e-04 - mae: 0.0124 - mse: 3.2348e-04 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0013\n",
      "Epoch 125/200\n",
      "2440/2440 [==============================] - 0s 54us/step - loss: 3.2062e-04 - mae: 0.0124 - mse: 3.2062e-04 - val_loss: 0.0014 - val_mae: 0.0268 - val_mse: 0.0014\n",
      "Epoch 126/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 3.1784e-04 - mae: 0.0121 - mse: 3.1784e-04 - val_loss: 0.0011 - val_mae: 0.0221 - val_mse: 0.0011\n",
      "Epoch 127/200\n",
      "2440/2440 [==============================] - 0s 54us/step - loss: 2.8586e-04 - mae: 0.0117 - mse: 2.8586e-04 - val_loss: 0.0015 - val_mae: 0.0281 - val_mse: 0.0015\n",
      "Epoch 128/200\n",
      "2440/2440 [==============================] - 0s 61us/step - loss: 3.2541e-04 - mae: 0.0124 - mse: 3.2541e-04 - val_loss: 0.0015 - val_mae: 0.0280 - val_mse: 0.0015\n",
      "Epoch 129/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 3.3621e-04 - mae: 0.0126 - mse: 3.3621e-04 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0015\n",
      "Epoch 130/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 3.6655e-04 - mae: 0.0132 - mse: 3.6655e-04 - val_loss: 0.0015 - val_mae: 0.0285 - val_mse: 0.0015\n",
      "Epoch 131/200\n",
      "2440/2440 [==============================] - 0s 55us/step - loss: 3.6299e-04 - mae: 0.0132 - mse: 3.6299e-04 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0015\n",
      "Epoch 132/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 3.9732e-04 - mae: 0.0137 - mse: 3.9732e-04 - val_loss: 0.0015 - val_mae: 0.0283 - val_mse: 0.0015\n",
      "Epoch 133/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 4.2179e-04 - mae: 0.0142 - mse: 4.2179e-04 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0015\n",
      "Epoch 134/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 4.2168e-04 - mae: 0.0141 - mse: 4.2168e-04 - val_loss: 0.0013 - val_mae: 0.0259 - val_mse: 0.0013\n",
      "Epoch 135/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 3.6679e-04 - mae: 0.0130 - mse: 3.6679e-04 - val_loss: 0.0013 - val_mae: 0.0254 - val_mse: 0.0013\n",
      "Epoch 136/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.6804e-04 - mae: 0.0130 - mse: 3.6804e-04 - val_loss: 0.0012 - val_mae: 0.0239 - val_mse: 0.0012\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/2440 [==============================] - 0s 43us/step - loss: 3.0129e-04 - mae: 0.0119 - mse: 3.0129e-04 - val_loss: 0.0011 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 138/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.9594e-04 - mae: 0.0116 - mse: 2.9594e-04 - val_loss: 0.0011 - val_mae: 0.0232 - val_mse: 0.0011\n",
      "Epoch 139/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 2.8123e-04 - mae: 0.0114 - mse: 2.8123e-04 - val_loss: 0.0011 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 140/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 2.7995e-04 - mae: 0.0114 - mse: 2.7995e-04 - val_loss: 0.0012 - val_mae: 0.0216 - val_mse: 0.0012\n",
      "Epoch 141/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 2.9953e-04 - mae: 0.0118 - mse: 2.9953e-04 - val_loss: 0.0012 - val_mae: 0.0237 - val_mse: 0.0012\n",
      "Epoch 142/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.6836e-04 - mae: 0.0111 - mse: 2.6836e-04 - val_loss: 0.0013 - val_mae: 0.0247 - val_mse: 0.0013\n",
      "Epoch 143/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.6442e-04 - mae: 0.0111 - mse: 2.6442e-04 - val_loss: 0.0012 - val_mae: 0.0237 - val_mse: 0.0012\n",
      "Epoch 144/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 2.5789e-04 - mae: 0.0110 - mse: 2.5789e-04 - val_loss: 0.0012 - val_mae: 0.0236 - val_mse: 0.0012\n",
      "Epoch 145/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 2.4873e-04 - mae: 0.0107 - mse: 2.4873e-04 - val_loss: 0.0013 - val_mae: 0.0237 - val_mse: 0.0013\n",
      "Epoch 146/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 2.5979e-04 - mae: 0.0109 - mse: 2.5979e-04 - val_loss: 0.0013 - val_mae: 0.0241 - val_mse: 0.0013\n",
      "Epoch 147/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.6148e-04 - mae: 0.0110 - mse: 2.6148e-04 - val_loss: 0.0013 - val_mae: 0.0238 - val_mse: 0.0013\n",
      "Epoch 148/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 2.7609e-04 - mae: 0.0112 - mse: 2.7609e-04 - val_loss: 0.0012 - val_mae: 0.0241 - val_mse: 0.0012\n",
      "Epoch 149/200\n",
      "2440/2440 [==============================] - 0s 52us/step - loss: 2.5770e-04 - mae: 0.0110 - mse: 2.5770e-04 - val_loss: 0.0013 - val_mae: 0.0244 - val_mse: 0.0013\n",
      "Epoch 150/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 2.7284e-04 - mae: 0.0112 - mse: 2.7284e-04 - val_loss: 0.0012 - val_mae: 0.0228 - val_mse: 0.0012\n",
      "Epoch 151/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 2.5595e-04 - mae: 0.0109 - mse: 2.5595e-04 - val_loss: 0.0013 - val_mae: 0.0240 - val_mse: 0.0013\n",
      "Epoch 152/200\n",
      "2440/2440 [==============================] - 0s 38us/step - loss: 2.6181e-04 - mae: 0.0110 - mse: 2.6181e-04 - val_loss: 0.0013 - val_mae: 0.0236 - val_mse: 0.0013\n",
      "Epoch 153/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 2.6518e-04 - mae: 0.0111 - mse: 2.6518e-04 - val_loss: 0.0014 - val_mae: 0.0236 - val_mse: 0.0014\n",
      "Epoch 154/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 2.8169e-04 - mae: 0.0114 - mse: 2.8169e-04 - val_loss: 0.0014 - val_mae: 0.0236 - val_mse: 0.0014\n",
      "Epoch 155/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 2.9011e-04 - mae: 0.0115 - mse: 2.9011e-04 - val_loss: 0.0014 - val_mae: 0.0236 - val_mse: 0.0014\n",
      "Epoch 156/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 2.9508e-04 - mae: 0.0117 - mse: 2.9508e-04 - val_loss: 0.0016 - val_mae: 0.0251 - val_mse: 0.0016\n",
      "Epoch 157/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.1194e-04 - mae: 0.0122 - mse: 3.1194e-04 - val_loss: 0.0015 - val_mae: 0.0243 - val_mse: 0.0015\n",
      "Epoch 158/200\n",
      "2440/2440 [==============================] - 0s 38us/step - loss: 3.1603e-04 - mae: 0.0120 - mse: 3.1603e-04 - val_loss: 0.0016 - val_mae: 0.0245 - val_mse: 0.0016\n",
      "Epoch 159/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 3.5090e-04 - mae: 0.0127 - mse: 3.5090e-04 - val_loss: 0.0016 - val_mae: 0.0248 - val_mse: 0.0016\n",
      "Epoch 160/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 3.6680e-04 - mae: 0.0130 - mse: 3.6680e-04 - val_loss: 0.0016 - val_mae: 0.0243 - val_mse: 0.0016\n",
      "Epoch 161/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 4.0791e-04 - mae: 0.0137 - mse: 4.0791e-04 - val_loss: 0.0015 - val_mae: 0.0232 - val_mse: 0.0015\n",
      "Epoch 162/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 4.3482e-04 - mae: 0.0141 - mse: 4.3482e-04 - val_loss: 0.0014 - val_mae: 0.0229 - val_mse: 0.0014\n",
      "Epoch 163/200\n",
      "2440/2440 [==============================] - 0s 39us/step - loss: 4.7066e-04 - mae: 0.0147 - mse: 4.7066e-04 - val_loss: 0.0013 - val_mae: 0.0220 - val_mse: 0.0013\n",
      "Epoch 164/200\n",
      "2440/2440 [==============================] - 0s 38us/step - loss: 5.8525e-04 - mae: 0.0165 - mse: 5.8525e-04 - val_loss: 0.0011 - val_mae: 0.0204 - val_mse: 0.0011\n",
      "Epoch 165/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 6.4725e-04 - mae: 0.0176 - mse: 6.4725e-04 - val_loss: 9.7427e-04 - val_mae: 0.0197 - val_mse: 9.7427e-04\n",
      "Epoch 166/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 7.2904e-04 - mae: 0.0187 - mse: 7.2904e-04 - val_loss: 0.0011 - val_mae: 0.0206 - val_mse: 0.0011\n",
      "Epoch 167/200\n",
      "2440/2440 [==============================] - 0s 49us/step - loss: 6.5802e-04 - mae: 0.0177 - mse: 6.5802e-04 - val_loss: 0.0011 - val_mae: 0.0205 - val_mse: 0.0011\n",
      "Epoch 168/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 5.8309e-04 - mae: 0.0163 - mse: 5.8309e-04 - val_loss: 9.7229e-04 - val_mae: 0.0187 - val_mse: 9.7229e-04\n",
      "Epoch 169/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 4.4606e-04 - mae: 0.0142 - mse: 4.4606e-04 - val_loss: 7.8028e-04 - val_mae: 0.0163 - val_mse: 7.8028e-04\n",
      "Epoch 170/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 3.3537e-04 - mae: 0.0123 - mse: 3.3537e-04 - val_loss: 7.3519e-04 - val_mae: 0.0158 - val_mse: 7.3519e-04\n",
      "Epoch 171/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 2.8187e-04 - mae: 0.0112 - mse: 2.8187e-04 - val_loss: 6.9437e-04 - val_mae: 0.0153 - val_mse: 6.9437e-04\n",
      "Epoch 172/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 2.5383e-04 - mae: 0.0106 - mse: 2.5383e-04 - val_loss: 7.0903e-04 - val_mae: 0.0154 - val_mse: 7.0903e-04\n",
      "Epoch 173/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 2.3510e-04 - mae: 0.0103 - mse: 2.3510e-04 - val_loss: 7.0335e-04 - val_mae: 0.0153 - val_mse: 7.0335e-04\n",
      "Epoch 174/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 2.2471e-04 - mae: 0.0100 - mse: 2.2471e-04 - val_loss: 7.1564e-04 - val_mae: 0.0155 - val_mse: 7.1564e-04\n",
      "Epoch 175/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 2.1162e-04 - mae: 0.0097 - mse: 2.1162e-04 - val_loss: 7.0477e-04 - val_mae: 0.0154 - val_mse: 7.0477e-04\n",
      "Epoch 176/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 2.0154e-04 - mae: 0.0095 - mse: 2.0154e-04 - val_loss: 6.9432e-04 - val_mae: 0.0155 - val_mse: 6.9432e-04\n",
      "Epoch 177/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 1.9476e-04 - mae: 0.0093 - mse: 1.9476e-04 - val_loss: 6.9585e-04 - val_mae: 0.0154 - val_mse: 6.9585e-04\n",
      "Epoch 178/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 1.8656e-04 - mae: 0.0091 - mse: 1.8656e-04 - val_loss: 6.8951e-04 - val_mae: 0.0153 - val_mse: 6.8951e-04\n",
      "Epoch 179/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 1.7922e-04 - mae: 0.0089 - mse: 1.7922e-04 - val_loss: 6.9028e-04 - val_mae: 0.0153 - val_mse: 6.9028e-04\n",
      "Epoch 180/200\n",
      "2440/2440 [==============================] - 0s 40us/step - loss: 1.7716e-04 - mae: 0.0089 - mse: 1.7716e-04 - val_loss: 6.9182e-04 - val_mae: 0.0154 - val_mse: 6.9182e-04\n",
      "Epoch 181/200\n",
      "2440/2440 [==============================] - 0s 48us/step - loss: 1.7084e-04 - mae: 0.0087 - mse: 1.7084e-04 - val_loss: 6.8688e-04 - val_mae: 0.0155 - val_mse: 6.8688e-04\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/2440 [==============================] - 0s 51us/step - loss: 1.6661e-04 - mae: 0.0085 - mse: 1.6661e-04 - val_loss: 6.8117e-04 - val_mae: 0.0155 - val_mse: 6.8117e-04\n",
      "Epoch 183/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 1.6168e-04 - mae: 0.0084 - mse: 1.6168e-04 - val_loss: 6.9781e-04 - val_mae: 0.0156 - val_mse: 6.9781e-04\n",
      "Epoch 184/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 1.6147e-04 - mae: 0.0084 - mse: 1.6147e-04 - val_loss: 6.9371e-04 - val_mae: 0.0158 - val_mse: 6.9371e-04\n",
      "Epoch 185/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 1.5904e-04 - mae: 0.0085 - mse: 1.5904e-04 - val_loss: 6.8003e-04 - val_mae: 0.0157 - val_mse: 6.8003e-04\n",
      "Epoch 186/200\n",
      "2440/2440 [==============================] - 0s 41us/step - loss: 1.5765e-04 - mae: 0.0084 - mse: 1.5765e-04 - val_loss: 7.0553e-04 - val_mae: 0.0161 - val_mse: 7.0553e-04\n",
      "Epoch 187/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 1.5701e-04 - mae: 0.0085 - mse: 1.5701e-04 - val_loss: 6.9776e-04 - val_mae: 0.0161 - val_mse: 6.9776e-04\n",
      "Epoch 188/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 1.5272e-04 - mae: 0.0083 - mse: 1.5272e-04 - val_loss: 6.9878e-04 - val_mae: 0.0164 - val_mse: 6.9878e-04\n",
      "Epoch 189/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 1.5191e-04 - mae: 0.0084 - mse: 1.5191e-04 - val_loss: 7.0576e-04 - val_mae: 0.0163 - val_mse: 7.0576e-04\n",
      "Epoch 190/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 1.4544e-04 - mae: 0.0082 - mse: 1.4544e-04 - val_loss: 7.2903e-04 - val_mae: 0.0167 - val_mse: 7.2903e-04\n",
      "Epoch 191/200\n",
      "2440/2440 [==============================] - 0s 42us/step - loss: 1.4731e-04 - mae: 0.0083 - mse: 1.4731e-04 - val_loss: 7.3391e-04 - val_mae: 0.0169 - val_mse: 7.3391e-04\n",
      "Epoch 192/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 1.4320e-04 - mae: 0.0082 - mse: 1.4320e-04 - val_loss: 7.2298e-04 - val_mae: 0.0168 - val_mse: 7.2298e-04\n",
      "Epoch 193/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 1.4260e-04 - mae: 0.0082 - mse: 1.4260e-04 - val_loss: 7.3251e-04 - val_mae: 0.0168 - val_mse: 7.3251e-04\n",
      "Epoch 194/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 1.4098e-04 - mae: 0.0081 - mse: 1.4098e-04 - val_loss: 7.3868e-04 - val_mae: 0.0168 - val_mse: 7.3868e-04\n",
      "Epoch 195/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 1.4702e-04 - mae: 0.0082 - mse: 1.4702e-04 - val_loss: 7.8329e-04 - val_mae: 0.0178 - val_mse: 7.8329e-04\n",
      "Epoch 196/200\n",
      "2440/2440 [==============================] - 0s 47us/step - loss: 1.4867e-04 - mae: 0.0084 - mse: 1.4867e-04 - val_loss: 7.5272e-04 - val_mae: 0.0170 - val_mse: 7.5272e-04\n",
      "Epoch 197/200\n",
      "2440/2440 [==============================] - 0s 46us/step - loss: 1.5076e-04 - mae: 0.0086 - mse: 1.5076e-04 - val_loss: 7.5148e-04 - val_mae: 0.0170 - val_mse: 7.5148e-04\n",
      "Epoch 198/200\n",
      "2440/2440 [==============================] - 0s 44us/step - loss: 1.6141e-04 - mae: 0.0088 - mse: 1.6141e-04 - val_loss: 7.4981e-04 - val_mae: 0.0177 - val_mse: 7.4981e-04\n",
      "Epoch 199/200\n",
      "2440/2440 [==============================] - 0s 43us/step - loss: 1.5863e-04 - mae: 0.0089 - mse: 1.5863e-04 - val_loss: 7.2611e-04 - val_mae: 0.0164 - val_mse: 7.2611e-04\n",
      "Epoch 200/200\n",
      "2440/2440 [==============================] - 0s 45us/step - loss: 1.5010e-04 - mae: 0.0085 - mse: 1.5010e-04 - val_loss: 7.2137e-04 - val_mae: 0.0162 - val_mse: 7.2137e-04\n"
     ]
    }
   ],
   "source": [
    "# Fit CNN\n",
    "cnnhistory = cnn.fit(X_train_CNN, y_train_CNN,\n",
    "                       epochs=EPOCHS,\n",
    "                       validation_data=(X_test_CNN, y_test_CNN),\n",
    "                       verbose=1,\n",
    "                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph CNN Error, mae and mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model WITHOUT Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/200\n",
      "4222/4222 [==============================] - 1s 122us/step - loss: 0.0306 - mae: 0.1061 - mse: 0.0306 - val_loss: 0.0147 - val_mae: 0.0705 - val_mse: 0.0147\n",
      "Epoch 2/200\n",
      "4222/4222 [==============================] - 0s 52us/step - loss: 0.0144 - mae: 0.0625 - mse: 0.0144 - val_loss: 0.0124 - val_mae: 0.0607 - val_mse: 0.0124\n",
      "Epoch 3/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0134 - mae: 0.0598 - mse: 0.0134 - val_loss: 0.0116 - val_mae: 0.0588 - val_mse: 0.0116\n",
      "Epoch 4/200\n",
      "4222/4222 [==============================] - 0s 47us/step - loss: 0.0129 - mae: 0.0585 - mse: 0.0129 - val_loss: 0.0112 - val_mae: 0.0573 - val_mse: 0.0112\n",
      "Epoch 5/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0125 - mae: 0.0570 - mse: 0.0125 - val_loss: 0.0107 - val_mae: 0.0562 - val_mse: 0.0107\n",
      "Epoch 6/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0121 - mae: 0.0557 - mse: 0.0121 - val_loss: 0.0104 - val_mae: 0.0549 - val_mse: 0.0104\n",
      "Epoch 7/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0117 - mae: 0.0547 - mse: 0.0117 - val_loss: 0.0100 - val_mae: 0.0536 - val_mse: 0.0100\n",
      "Epoch 8/200\n",
      "4222/4222 [==============================] - 0s 50us/step - loss: 0.0115 - mae: 0.0539 - mse: 0.0115 - val_loss: 0.0098 - val_mae: 0.0538 - val_mse: 0.0098\n",
      "Epoch 9/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0112 - mae: 0.0531 - mse: 0.0112 - val_loss: 0.0096 - val_mae: 0.0530 - val_mse: 0.0096\n",
      "Epoch 10/200\n",
      "4222/4222 [==============================] - 0s 50us/step - loss: 0.0111 - mae: 0.0528 - mse: 0.0111 - val_loss: 0.0094 - val_mae: 0.0530 - val_mse: 0.0094\n",
      "Epoch 11/200\n",
      "4222/4222 [==============================] - 0s 49us/step - loss: 0.0108 - mae: 0.0518 - mse: 0.0108 - val_loss: 0.0091 - val_mae: 0.0525 - val_mse: 0.0091\n",
      "Epoch 12/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0106 - mae: 0.0512 - mse: 0.0106 - val_loss: 0.0090 - val_mae: 0.0521 - val_mse: 0.0090\n",
      "Epoch 13/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0104 - mae: 0.0502 - mse: 0.0104 - val_loss: 0.0088 - val_mae: 0.0523 - val_mse: 0.0088\n",
      "Epoch 14/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0103 - mae: 0.0500 - mse: 0.0103 - val_loss: 0.0087 - val_mae: 0.0522 - val_mse: 0.0087\n",
      "Epoch 15/200\n",
      "4222/4222 [==============================] - 0s 47us/step - loss: 0.0100 - mae: 0.0490 - mse: 0.0100 - val_loss: 0.0084 - val_mae: 0.0518 - val_mse: 0.0084\n",
      "Epoch 16/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0098 - mae: 0.0483 - mse: 0.0098 - val_loss: 0.0083 - val_mae: 0.0519 - val_mse: 0.0083\n",
      "Epoch 17/200\n",
      "4222/4222 [==============================] - 0s 47us/step - loss: 0.0096 - mae: 0.0475 - mse: 0.0096 - val_loss: 0.0082 - val_mae: 0.0517 - val_mse: 0.0082\n",
      "Epoch 18/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0095 - mae: 0.0473 - mse: 0.0095 - val_loss: 0.0081 - val_mae: 0.0516 - val_mse: 0.0081\n",
      "Epoch 19/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0093 - mae: 0.0467 - mse: 0.0093 - val_loss: 0.0080 - val_mae: 0.0513 - val_mse: 0.0080\n",
      "Epoch 20/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0093 - mae: 0.0471 - mse: 0.0093 - val_loss: 0.0079 - val_mae: 0.0513 - val_mse: 0.0079\n",
      "Epoch 21/200\n",
      "4222/4222 [==============================] - 0s 47us/step - loss: 0.0092 - mae: 0.0468 - mse: 0.0092 - val_loss: 0.0077 - val_mae: 0.0490 - val_mse: 0.0077\n",
      "Epoch 22/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0093 - mae: 0.0477 - mse: 0.0093 - val_loss: 0.0078 - val_mae: 0.0518 - val_mse: 0.0078\n",
      "Epoch 23/200\n",
      "4222/4222 [==============================] - 0s 47us/step - loss: 0.0089 - mae: 0.0460 - mse: 0.0089 - val_loss: 0.0076 - val_mae: 0.0496 - val_mse: 0.0076\n",
      "Epoch 24/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0090 - mae: 0.0468 - mse: 0.0090 - val_loss: 0.0076 - val_mae: 0.0500 - val_mse: 0.0076\n",
      "Epoch 25/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0087 - mae: 0.0455 - mse: 0.0087 - val_loss: 0.0074 - val_mae: 0.0489 - val_mse: 0.0074\n",
      "Epoch 26/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0087 - mae: 0.0455 - mse: 0.0087 - val_loss: 0.0074 - val_mae: 0.0497 - val_mse: 0.0074\n",
      "Epoch 27/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0086 - mae: 0.0458 - mse: 0.0086 - val_loss: 0.0073 - val_mae: 0.0494 - val_mse: 0.0073\n",
      "Epoch 28/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0085 - mae: 0.0452 - mse: 0.0085 - val_loss: 0.0072 - val_mae: 0.0478 - val_mse: 0.0072\n",
      "Epoch 29/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0084 - mae: 0.0447 - mse: 0.0084 - val_loss: 0.0071 - val_mae: 0.0477 - val_mse: 0.0071\n",
      "Epoch 30/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0082 - mae: 0.0443 - mse: 0.0082 - val_loss: 0.0070 - val_mae: 0.0467 - val_mse: 0.0070\n",
      "Epoch 31/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0083 - mae: 0.0443 - mse: 0.0083 - val_loss: 0.0070 - val_mae: 0.0461 - val_mse: 0.0070\n",
      "Epoch 32/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0081 - mae: 0.0441 - mse: 0.0081 - val_loss: 0.0069 - val_mae: 0.0468 - val_mse: 0.0069\n",
      "Epoch 33/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0081 - mae: 0.0438 - mse: 0.0081 - val_loss: 0.0069 - val_mae: 0.0459 - val_mse: 0.0069\n",
      "Epoch 34/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0080 - mae: 0.0432 - mse: 0.0080 - val_loss: 0.0068 - val_mae: 0.0458 - val_mse: 0.0068\n",
      "Epoch 35/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0079 - mae: 0.0431 - mse: 0.0079 - val_loss: 0.0067 - val_mae: 0.0452 - val_mse: 0.0067\n",
      "Epoch 36/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0077 - mae: 0.0427 - mse: 0.0077 - val_loss: 0.0067 - val_mae: 0.0452 - val_mse: 0.0067\n",
      "Epoch 37/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0078 - mae: 0.0429 - mse: 0.0078 - val_loss: 0.0066 - val_mae: 0.0437 - val_mse: 0.0066\n",
      "Epoch 38/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0077 - mae: 0.0422 - mse: 0.0077 - val_loss: 0.0066 - val_mae: 0.0441 - val_mse: 0.0066\n",
      "Epoch 39/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0076 - mae: 0.0422 - mse: 0.0076 - val_loss: 0.0066 - val_mae: 0.0443 - val_mse: 0.0066\n",
      "Epoch 40/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0075 - mae: 0.0417 - mse: 0.0075 - val_loss: 0.0065 - val_mae: 0.0440 - val_mse: 0.0065\n",
      "Epoch 41/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0074 - mae: 0.0417 - mse: 0.0074 - val_loss: 0.0065 - val_mae: 0.0436 - val_mse: 0.0065\n",
      "Epoch 42/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0075 - mae: 0.0418 - mse: 0.0075 - val_loss: 0.0064 - val_mae: 0.0432 - val_mse: 0.0064\n",
      "Epoch 43/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0073 - mae: 0.0412 - mse: 0.0073 - val_loss: 0.0064 - val_mae: 0.0425 - val_mse: 0.0064\n",
      "Epoch 44/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0072 - mae: 0.0408 - mse: 0.0072 - val_loss: 0.0063 - val_mae: 0.0428 - val_mse: 0.0063\n",
      "Epoch 45/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0073 - mae: 0.0407 - mse: 0.0073 - val_loss: 0.0063 - val_mae: 0.0414 - val_mse: 0.0063\n",
      "Epoch 46/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0072 - mae: 0.0403 - mse: 0.0072 - val_loss: 0.0062 - val_mae: 0.0412 - val_mse: 0.0062\n",
      "Epoch 47/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0071 - mae: 0.0405 - mse: 0.0071 - val_loss: 0.0062 - val_mae: 0.0413 - val_mse: 0.0062\n",
      "Epoch 48/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0071 - mae: 0.0400 - mse: 0.0071 - val_loss: 0.0062 - val_mae: 0.0412 - val_mse: 0.0062\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0070 - mae: 0.0399 - mse: 0.0070 - val_loss: 0.0062 - val_mae: 0.0413 - val_mse: 0.0062\n",
      "Epoch 50/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0070 - mae: 0.0396 - mse: 0.0070 - val_loss: 0.0062 - val_mae: 0.0413 - val_mse: 0.0062\n",
      "Epoch 51/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0070 - mae: 0.0395 - mse: 0.0070 - val_loss: 0.0061 - val_mae: 0.0406 - val_mse: 0.0061\n",
      "Epoch 52/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0069 - mae: 0.0390 - mse: 0.0069 - val_loss: 0.0061 - val_mae: 0.0404 - val_mse: 0.0061\n",
      "Epoch 53/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0068 - mae: 0.0387 - mse: 0.0068 - val_loss: 0.0061 - val_mae: 0.0400 - val_mse: 0.0061\n",
      "Epoch 54/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0068 - mae: 0.0390 - mse: 0.0068 - val_loss: 0.0061 - val_mae: 0.0407 - val_mse: 0.0061\n",
      "Epoch 55/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0068 - mae: 0.0387 - mse: 0.0068 - val_loss: 0.0060 - val_mae: 0.0398 - val_mse: 0.0060\n",
      "Epoch 56/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0068 - mae: 0.0387 - mse: 0.0068 - val_loss: 0.0061 - val_mae: 0.0402 - val_mse: 0.0061\n",
      "Epoch 57/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0068 - mae: 0.0384 - mse: 0.0068 - val_loss: 0.0060 - val_mae: 0.0403 - val_mse: 0.0060\n",
      "Epoch 58/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0067 - mae: 0.0383 - mse: 0.0067 - val_loss: 0.0060 - val_mae: 0.0400 - val_mse: 0.0060\n",
      "Epoch 59/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0067 - mae: 0.0383 - mse: 0.0067 - val_loss: 0.0060 - val_mae: 0.0390 - val_mse: 0.0060\n",
      "Epoch 60/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0066 - mae: 0.0378 - mse: 0.0066 - val_loss: 0.0060 - val_mae: 0.0391 - val_mse: 0.0060\n",
      "Epoch 61/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0066 - mae: 0.0378 - mse: 0.0066 - val_loss: 0.0060 - val_mae: 0.0392 - val_mse: 0.0060\n",
      "Epoch 62/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0066 - mae: 0.0376 - mse: 0.0066 - val_loss: 0.0059 - val_mae: 0.0387 - val_mse: 0.0059\n",
      "Epoch 63/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0065 - mae: 0.0371 - mse: 0.0065 - val_loss: 0.0059 - val_mae: 0.0379 - val_mse: 0.0059\n",
      "Epoch 64/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0065 - mae: 0.0368 - mse: 0.0065 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 65/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0065 - mae: 0.0365 - mse: 0.0065 - val_loss: 0.0059 - val_mae: 0.0370 - val_mse: 0.0059\n",
      "Epoch 66/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0065 - mae: 0.0365 - mse: 0.0065 - val_loss: 0.0059 - val_mae: 0.0384 - val_mse: 0.0059\n",
      "Epoch 67/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0064 - mae: 0.0363 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0377 - val_mse: 0.0059\n",
      "Epoch 68/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0064 - mae: 0.0363 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0385 - val_mse: 0.0059\n",
      "Epoch 69/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0064 - mae: 0.0361 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0375 - val_mse: 0.0059\n",
      "Epoch 70/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0064 - mae: 0.0363 - mse: 0.0064 - val_loss: 0.0059 - val_mae: 0.0372 - val_mse: 0.0059\n",
      "Epoch 71/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0063 - mae: 0.0358 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 72/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0063 - mae: 0.0359 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0376 - val_mse: 0.0059\n",
      "Epoch 73/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0063 - mae: 0.0355 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0375 - val_mse: 0.0059\n",
      "Epoch 74/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0063 - mae: 0.0352 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0374 - val_mse: 0.0059\n",
      "Epoch 75/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0063 - mae: 0.0359 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0375 - val_mse: 0.0059\n",
      "Epoch 76/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0063 - mae: 0.0360 - mse: 0.0063 - val_loss: 0.0059 - val_mae: 0.0386 - val_mse: 0.0059\n",
      "Epoch 77/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0062 - mae: 0.0351 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0377 - val_mse: 0.0059\n",
      "Epoch 78/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0062 - mae: 0.0353 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0376 - val_mse: 0.0059\n",
      "Epoch 79/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0062 - mae: 0.0350 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0376 - val_mse: 0.0059\n",
      "Epoch 80/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0062 - mae: 0.0348 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0377 - val_mse: 0.0059\n",
      "Epoch 81/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0062 - mae: 0.0352 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0375 - val_mse: 0.0059\n",
      "Epoch 82/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0061 - mae: 0.0346 - mse: 0.0061 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 83/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0062 - mae: 0.0350 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0380 - val_mse: 0.0059\n",
      "Epoch 84/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0062 - mae: 0.0352 - mse: 0.0062 - val_loss: 0.0059 - val_mae: 0.0389 - val_mse: 0.0059\n",
      "Epoch 85/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0061 - mae: 0.0351 - mse: 0.0061 - val_loss: 0.0059 - val_mae: 0.0372 - val_mse: 0.0059\n",
      "Epoch 86/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0061 - mae: 0.0347 - mse: 0.0061 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 87/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0061 - mae: 0.0343 - mse: 0.0061 - val_loss: 0.0058 - val_mae: 0.0374 - val_mse: 0.0058\n",
      "Epoch 88/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0060 - mae: 0.0339 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0379 - val_mse: 0.0059\n",
      "Epoch 89/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0061 - mae: 0.0343 - mse: 0.0061 - val_loss: 0.0059 - val_mae: 0.0375 - val_mse: 0.0059\n",
      "Epoch 90/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0060 - mae: 0.0340 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0369 - val_mse: 0.0059\n",
      "Epoch 91/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0060 - mae: 0.0343 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0373 - val_mse: 0.0059\n",
      "Epoch 92/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0060 - mae: 0.0341 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0373 - val_mse: 0.0059\n",
      "Epoch 93/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0060 - mae: 0.0339 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0371 - val_mse: 0.0059\n",
      "Epoch 94/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0060 - mae: 0.0341 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0373 - val_mse: 0.0059\n",
      "Epoch 95/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0059 - mae: 0.0334 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0372 - val_mse: 0.0059\n",
      "Epoch 96/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0060 - mae: 0.0339 - mse: 0.0060 - val_loss: 0.0059 - val_mae: 0.0366 - val_mse: 0.0059\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0059 - mae: 0.0338 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0371 - val_mse: 0.0059\n",
      "Epoch 98/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0059 - mae: 0.0336 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0372 - val_mse: 0.0059\n",
      "Epoch 99/200\n",
      "4222/4222 [==============================] - 0s 36us/step - loss: 0.0059 - mae: 0.0337 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0372 - val_mse: 0.0059\n",
      "Epoch 100/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0059 - mae: 0.0335 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0370 - val_mse: 0.0059\n",
      "Epoch 101/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0059 - mae: 0.0337 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0367 - val_mse: 0.0059\n",
      "Epoch 102/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0059 - mae: 0.0340 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0385 - val_mse: 0.0059\n",
      "Epoch 103/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0058 - mae: 0.0329 - mse: 0.0058 - val_loss: 0.0059 - val_mae: 0.0365 - val_mse: 0.0059\n",
      "Epoch 104/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0059 - mae: 0.0336 - mse: 0.0059 - val_loss: 0.0059 - val_mae: 0.0365 - val_mse: 0.0059\n",
      "Epoch 105/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0058 - mae: 0.0333 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0355 - val_mse: 0.0058\n",
      "Epoch 106/200\n",
      "4222/4222 [==============================] - 0s 47us/step - loss: 0.0058 - mae: 0.0335 - mse: 0.0058 - val_loss: 0.0059 - val_mae: 0.0377 - val_mse: 0.0059\n",
      "Epoch 107/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0058 - mae: 0.0331 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0362 - val_mse: 0.0058\n",
      "Epoch 108/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0058 - mae: 0.0331 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0351 - val_mse: 0.0058\n",
      "Epoch 109/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0058 - mae: 0.0327 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0351 - val_mse: 0.0058\n",
      "Epoch 110/200\n",
      "4222/4222 [==============================] - 0s 45us/step - loss: 0.0058 - mae: 0.0327 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0359 - val_mse: 0.0058\n",
      "Epoch 111/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0058 - mae: 0.0330 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0351 - val_mse: 0.0058\n",
      "Epoch 112/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0057 - mae: 0.0327 - mse: 0.0057 - val_loss: 0.0058 - val_mae: 0.0354 - val_mse: 0.0058\n",
      "Epoch 113/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0058 - mae: 0.0328 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0349 - val_mse: 0.0058\n",
      "Epoch 114/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0057 - mae: 0.0324 - mse: 0.0057 - val_loss: 0.0058 - val_mae: 0.0356 - val_mse: 0.0058\n",
      "Epoch 115/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0057 - mae: 0.0324 - mse: 0.0057 - val_loss: 0.0058 - val_mae: 0.0349 - val_mse: 0.0058\n",
      "Epoch 116/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0057 - mae: 0.0324 - mse: 0.0057 - val_loss: 0.0059 - val_mae: 0.0356 - val_mse: 0.0059\n",
      "Epoch 117/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0057 - mae: 0.0320 - mse: 0.0057 - val_loss: 0.0057 - val_mae: 0.0343 - val_mse: 0.0057\n",
      "Epoch 118/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0057 - mae: 0.0319 - mse: 0.0057 - val_loss: 0.0058 - val_mae: 0.0356 - val_mse: 0.0058\n",
      "Epoch 119/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0057 - mae: 0.0321 - mse: 0.0057 - val_loss: 0.0058 - val_mae: 0.0354 - val_mse: 0.0058\n",
      "Epoch 120/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0056 - mae: 0.0320 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0351 - val_mse: 0.0058\n",
      "Epoch 121/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0056 - mae: 0.0319 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0343 - val_mse: 0.0058\n",
      "Epoch 122/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0056 - mae: 0.0321 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0345 - val_mse: 0.0058\n",
      "Epoch 123/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0056 - mae: 0.0315 - mse: 0.0056 - val_loss: 0.0059 - val_mae: 0.0354 - val_mse: 0.0059\n",
      "Epoch 124/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0057 - mae: 0.0325 - mse: 0.0057 - val_loss: 0.0058 - val_mae: 0.0356 - val_mse: 0.0058\n",
      "Epoch 125/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0056 - mae: 0.0319 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0346 - val_mse: 0.0058\n",
      "Epoch 126/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0056 - mae: 0.0323 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0339 - val_mse: 0.0058\n",
      "Epoch 127/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0056 - mae: 0.0318 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0349 - val_mse: 0.0058\n",
      "Epoch 128/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0056 - mae: 0.0321 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0355 - val_mse: 0.0058\n",
      "Epoch 129/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0056 - mae: 0.0317 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0347 - val_mse: 0.0058\n",
      "Epoch 130/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0056 - mae: 0.0319 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0350 - val_mse: 0.0058\n",
      "Epoch 131/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0055 - mae: 0.0317 - mse: 0.0055 - val_loss: 0.0058 - val_mae: 0.0343 - val_mse: 0.0058\n",
      "Epoch 132/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0056 - mae: 0.0315 - mse: 0.0056 - val_loss: 0.0058 - val_mae: 0.0346 - val_mse: 0.0058\n",
      "Epoch 133/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0055 - mae: 0.0313 - mse: 0.0055 - val_loss: 0.0057 - val_mae: 0.0342 - val_mse: 0.0057\n",
      "Epoch 134/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0055 - mae: 0.0315 - mse: 0.0055 - val_loss: 0.0059 - val_mae: 0.0350 - val_mse: 0.0059\n",
      "Epoch 135/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0055 - mae: 0.0313 - mse: 0.0055 - val_loss: 0.0058 - val_mae: 0.0349 - val_mse: 0.0058\n",
      "Epoch 136/200\n",
      "4222/4222 [==============================] - 0s 45us/step - loss: 0.0055 - mae: 0.0312 - mse: 0.0055 - val_loss: 0.0057 - val_mae: 0.0341 - val_mse: 0.0057\n",
      "Epoch 137/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0055 - mae: 0.0314 - mse: 0.0055 - val_loss: 0.0058 - val_mae: 0.0350 - val_mse: 0.0058\n",
      "Epoch 138/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0055 - mae: 0.0317 - mse: 0.0055 - val_loss: 0.0058 - val_mae: 0.0363 - val_mse: 0.0058\n",
      "Epoch 139/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0055 - mae: 0.0314 - mse: 0.0055 - val_loss: 0.0058 - val_mae: 0.0348 - val_mse: 0.0058\n",
      "Epoch 140/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0055 - mae: 0.0316 - mse: 0.0055 - val_loss: 0.0058 - val_mae: 0.0352 - val_mse: 0.0058\n",
      "Epoch 141/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0054 - mae: 0.0311 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0350 - val_mse: 0.0058\n",
      "Epoch 142/200\n",
      "4222/4222 [==============================] - 0s 45us/step - loss: 0.0054 - mae: 0.0309 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0359 - val_mse: 0.0058\n",
      "Epoch 143/200\n",
      "4222/4222 [==============================] - 0s 50us/step - loss: 0.0054 - mae: 0.0312 - mse: 0.0054 - val_loss: 0.0057 - val_mae: 0.0338 - val_mse: 0.0057\n",
      "Epoch 144/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0054 - mae: 0.0309 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0344 - val_mse: 0.0058\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 45us/step - loss: 0.0054 - mae: 0.0310 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0345 - val_mse: 0.0058\n",
      "Epoch 146/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0054 - mae: 0.0314 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0349 - val_mse: 0.0058\n",
      "Epoch 147/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0054 - mae: 0.0309 - mse: 0.0054 - val_loss: 0.0057 - val_mae: 0.0338 - val_mse: 0.0057\n",
      "Epoch 148/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0054 - mae: 0.0309 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0351 - val_mse: 0.0058\n",
      "Epoch 149/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0054 - mae: 0.0313 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0345 - val_mse: 0.0058\n",
      "Epoch 150/200\n",
      "4222/4222 [==============================] - 0s 39us/step - loss: 0.0054 - mae: 0.0313 - mse: 0.0054 - val_loss: 0.0057 - val_mae: 0.0342 - val_mse: 0.0057\n",
      "Epoch 151/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0054 - mae: 0.0308 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0353 - val_mse: 0.0058\n",
      "Epoch 152/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0053 - mae: 0.0306 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0344 - val_mse: 0.0058\n",
      "Epoch 153/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0054 - mae: 0.0311 - mse: 0.0054 - val_loss: 0.0057 - val_mae: 0.0336 - val_mse: 0.0057\n",
      "Epoch 154/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0053 - mae: 0.0306 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0346 - val_mse: 0.0058\n",
      "Epoch 155/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0054 - mae: 0.0313 - mse: 0.0054 - val_loss: 0.0058 - val_mae: 0.0344 - val_mse: 0.0058\n",
      "Epoch 156/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0055 - mae: 0.0326 - mse: 0.0055 - val_loss: 0.0058 - val_mae: 0.0355 - val_mse: 0.0058\n",
      "Epoch 157/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0054 - mae: 0.0311 - mse: 0.0054 - val_loss: 0.0057 - val_mae: 0.0337 - val_mse: 0.0057\n",
      "Epoch 158/200\n",
      "4222/4222 [==============================] - 0s 48us/step - loss: 0.0053 - mae: 0.0303 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0351 - val_mse: 0.0058\n",
      "Epoch 159/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0053 - mae: 0.0303 - mse: 0.0053 - val_loss: 0.0057 - val_mae: 0.0342 - val_mse: 0.0057\n",
      "Epoch 160/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0350 - val_mse: 0.0058\n",
      "Epoch 161/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0352 - val_mse: 0.0058\n",
      "Epoch 162/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0053 - mae: 0.0307 - mse: 0.0053 - val_loss: 0.0057 - val_mae: 0.0340 - val_mse: 0.0057\n",
      "Epoch 163/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0347 - val_mse: 0.0058\n",
      "Epoch 164/200\n",
      "4222/4222 [==============================] - 0s 46us/step - loss: 0.0053 - mae: 0.0306 - mse: 0.0053 - val_loss: 0.0059 - val_mae: 0.0364 - val_mse: 0.0059\n",
      "Epoch 165/200\n",
      "4222/4222 [==============================] - 0s 40us/step - loss: 0.0053 - mae: 0.0307 - mse: 0.0053 - val_loss: 0.0059 - val_mae: 0.0349 - val_mse: 0.0059\n",
      "Epoch 166/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0053 - mae: 0.0306 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0344 - val_mse: 0.0058\n",
      "Epoch 167/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0339 - val_mse: 0.0058\n",
      "Epoch 168/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0059 - val_mae: 0.0344 - val_mse: 0.0059\n",
      "Epoch 169/200\n",
      "4222/4222 [==============================] - 0s 41us/step - loss: 0.0052 - mae: 0.0304 - mse: 0.0052 - val_loss: 0.0059 - val_mae: 0.0350 - val_mse: 0.0059\n",
      "Epoch 170/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0303 - mse: 0.0052 - val_loss: 0.0057 - val_mae: 0.0337 - val_mse: 0.0057\n",
      "Epoch 171/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0354 - val_mse: 0.0058\n",
      "Epoch 172/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0052 - mae: 0.0296 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0343 - val_mse: 0.0058\n",
      "Epoch 173/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0053 - mae: 0.0306 - mse: 0.0053 - val_loss: 0.0057 - val_mae: 0.0338 - val_mse: 0.0057\n",
      "Epoch 174/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0300 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0346 - val_mse: 0.0058\n",
      "Epoch 175/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0343 - val_mse: 0.0058\n",
      "Epoch 176/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0304 - mse: 0.0052 - val_loss: 0.0059 - val_mae: 0.0349 - val_mse: 0.0059\n",
      "Epoch 177/200\n",
      "4222/4222 [==============================] - 0s 45us/step - loss: 0.0052 - mae: 0.0301 - mse: 0.0052 - val_loss: 0.0057 - val_mae: 0.0335 - val_mse: 0.0057\n",
      "Epoch 178/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0053 - mae: 0.0306 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0357 - val_mse: 0.0058\n",
      "Epoch 179/200\n",
      "4222/4222 [==============================] - 0s 48us/step - loss: 0.0053 - mae: 0.0304 - mse: 0.0053 - val_loss: 0.0058 - val_mae: 0.0349 - val_mse: 0.0058\n",
      "Epoch 180/200\n",
      "4222/4222 [==============================] - 0s 44us/step - loss: 0.0052 - mae: 0.0301 - mse: 0.0052 - val_loss: 0.0057 - val_mae: 0.0339 - val_mse: 0.0057\n",
      "Epoch 181/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0302 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0339 - val_mse: 0.0058\n",
      "Epoch 182/200\n",
      "4222/4222 [==============================] - 0s 45us/step - loss: 0.0052 - mae: 0.0302 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0353 - val_mse: 0.0058\n",
      "Epoch 183/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0051 - mae: 0.0296 - mse: 0.0051 - val_loss: 0.0057 - val_mae: 0.0342 - val_mse: 0.0057\n",
      "Epoch 184/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0302 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0341 - val_mse: 0.0058\n",
      "Epoch 185/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0306 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0354 - val_mse: 0.0058\n",
      "Epoch 186/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0301 - mse: 0.0052 - val_loss: 0.0057 - val_mae: 0.0345 - val_mse: 0.0057\n",
      "Epoch 187/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0300 - mse: 0.0052 - val_loss: 0.0057 - val_mae: 0.0349 - val_mse: 0.0057\n",
      "Epoch 188/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0298 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0343 - val_mse: 0.0058\n",
      "Epoch 189/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0051 - mae: 0.0298 - mse: 0.0051 - val_loss: 0.0058 - val_mae: 0.0342 - val_mse: 0.0058\n",
      "Epoch 190/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0298 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0349 - val_mse: 0.0058\n",
      "Epoch 191/200\n",
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0051 - mae: 0.0297 - mse: 0.0051 - val_loss: 0.0057 - val_mae: 0.0336 - val_mse: 0.0057\n",
      "Epoch 192/200\n",
      "4222/4222 [==============================] - 0s 42us/step - loss: 0.0051 - mae: 0.0299 - mse: 0.0051 - val_loss: 0.0057 - val_mae: 0.0350 - val_mse: 0.0057\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 43us/step - loss: 0.0052 - mae: 0.0301 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0335 - val_mse: 0.0058\n",
      "Epoch 194/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0051 - mae: 0.0299 - mse: 0.0051 - val_loss: 0.0057 - val_mae: 0.0342 - val_mse: 0.0057\n",
      "Epoch 195/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0052 - mae: 0.0301 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0343 - val_mse: 0.0058\n",
      "Epoch 196/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0052 - mae: 0.0299 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0345 - val_mse: 0.0058\n",
      "Epoch 197/200\n",
      "4222/4222 [==============================] - 0s 37us/step - loss: 0.0052 - mae: 0.0299 - mse: 0.0052 - val_loss: 0.0057 - val_mae: 0.0336 - val_mse: 0.0057\n",
      "Epoch 198/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0052 - mae: 0.0299 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0342 - val_mse: 0.0058\n",
      "Epoch 199/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0052 - mae: 0.0300 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0344 - val_mse: 0.0058\n",
      "Epoch 200/200\n",
      "4222/4222 [==============================] - 0s 38us/step - loss: 0.0052 - mae: 0.0299 - mse: 0.0052 - val_loss: 0.0058 - val_mae: 0.0348 - val_mse: 0.0058\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_CNN_nomob, y_CNN_nomob = get_CNN_states_dataset(state_cases_df, n_steps=N_STEPS)\n",
    "X_train_CNN_nomob, X_test_CNN_nomob, y_train_CNN_nomob, y_test_CNN_nomob = train_test_split(X_CNN_nomob, y_CNN_nomob, test_size=SPLIT, shuffle=False)\n",
    "\n",
    "# Set up model\n",
    "n_cnn_features = X_train_CNN_nomob.shape[2]\n",
    "cnn_nomob = get_CNN_model(N_STEPS, n_cnn_features)\n",
    "\n",
    "# Fit CNN\n",
    "cnn_nomob_history = cnn_nomob.fit(X_train_CNN_nomob, y_train_CNN_nomob,\n",
    "                                     epochs=EPOCHS,\n",
    "                                     validation_data=(X_test_CNN_nomob, y_test_CNN_nomob),\n",
    "                                     verbose=1,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yunzhou's Neural Net Model With Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Set up NN, Yunzhou's model\n",
    "# Model Build functions\n",
    "def build_YNN_model(n_features):\n",
    "    # 2 hidden layers, 128 units, activation functions specified as relu\n",
    "    # and 1 final layer for prediction result\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation=\"relu\", input_shape=[n_features]),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "    model.compile(loss=\"mse\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compile model\n",
    "n_ynn_features = X_train_YNN.shape[1]\n",
    "ynn = build_YNN_model(n_ynn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit NN\n",
    "# early_stop=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "ynnhistory=ynn.fit(X_train_YNN, y_train_YNN,\n",
    "                   epochs=EPOCHS,\n",
    "                   validation_data=(X_test_YNN, y_test_YNN),\n",
    "                   verbose=0)#,\n",
    "                   #callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1449e3ad0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph NN Error, mae and mse\n",
    "plt.plot(ynnhistory.history['loss'])\n",
    "plt.plot(ynnhistory.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yunzhou's Neural Net Model WITHOUT Mobility Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4222 samples, validate on 1056 samples\n",
      "Epoch 1/200\n",
      "4222/4222 [==============================] - 1s 137us/sample - loss: 0.0195 - mean_absolute_error: 0.0727 - mean_squared_error: 0.0195 - val_loss: 0.0121 - val_mean_absolute_error: 0.0612 - val_mean_squared_error: 0.0121\n",
      "Epoch 2/200\n",
      "4222/4222 [==============================] - 0s 54us/sample - loss: 0.0119 - mean_absolute_error: 0.0525 - mean_squared_error: 0.0119 - val_loss: 0.0104 - val_mean_absolute_error: 0.0559 - val_mean_squared_error: 0.0104\n",
      "Epoch 3/200\n",
      "4222/4222 [==============================] - 0s 51us/sample - loss: 0.0103 - mean_absolute_error: 0.0477 - mean_squared_error: 0.0103 - val_loss: 0.0079 - val_mean_absolute_error: 0.0476 - val_mean_squared_error: 0.0079\n",
      "Epoch 4/200\n",
      "4222/4222 [==============================] - 0s 43us/sample - loss: 0.0091 - mean_absolute_error: 0.0450 - mean_squared_error: 0.0091 - val_loss: 0.0065 - val_mean_absolute_error: 0.0432 - val_mean_squared_error: 0.0065\n",
      "Epoch 5/200\n",
      "4222/4222 [==============================] - 0s 48us/sample - loss: 0.0083 - mean_absolute_error: 0.0429 - mean_squared_error: 0.0083 - val_loss: 0.0067 - val_mean_absolute_error: 0.0434 - val_mean_squared_error: 0.0067\n",
      "Epoch 6/200\n",
      "4222/4222 [==============================] - 0s 42us/sample - loss: 0.0077 - mean_absolute_error: 0.0415 - mean_squared_error: 0.0077 - val_loss: 0.0052 - val_mean_absolute_error: 0.0401 - val_mean_squared_error: 0.0052\n",
      "Epoch 7/200\n",
      "4222/4222 [==============================] - 0s 44us/sample - loss: 0.0071 - mean_absolute_error: 0.0397 - mean_squared_error: 0.0071 - val_loss: 0.0047 - val_mean_absolute_error: 0.0386 - val_mean_squared_error: 0.0047\n",
      "Epoch 8/200\n",
      "4222/4222 [==============================] - 0s 42us/sample - loss: 0.0067 - mean_absolute_error: 0.0388 - mean_squared_error: 0.0067 - val_loss: 0.0044 - val_mean_absolute_error: 0.0392 - val_mean_squared_error: 0.0044\n",
      "Epoch 9/200\n",
      "4222/4222 [==============================] - 0s 43us/sample - loss: 0.0062 - mean_absolute_error: 0.0374 - mean_squared_error: 0.0062 - val_loss: 0.0043 - val_mean_absolute_error: 0.0384 - val_mean_squared_error: 0.0043\n",
      "Epoch 10/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0058 - mean_absolute_error: 0.0361 - mean_squared_error: 0.0058 - val_loss: 0.0044 - val_mean_absolute_error: 0.0380 - val_mean_squared_error: 0.0044\n",
      "Epoch 11/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0054 - mean_absolute_error: 0.0351 - mean_squared_error: 0.0054 - val_loss: 0.0043 - val_mean_absolute_error: 0.0400 - val_mean_squared_error: 0.0043\n",
      "Epoch 12/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0049 - mean_absolute_error: 0.0335 - mean_squared_error: 0.0049 - val_loss: 0.0152 - val_mean_absolute_error: 0.0671 - val_mean_squared_error: 0.0152\n",
      "Epoch 13/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0048 - mean_absolute_error: 0.0327 - mean_squared_error: 0.0048 - val_loss: 0.0196 - val_mean_absolute_error: 0.0765 - val_mean_squared_error: 0.0196\n",
      "Epoch 14/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0046 - mean_absolute_error: 0.0318 - mean_squared_error: 0.0046 - val_loss: 0.0156 - val_mean_absolute_error: 0.0679 - val_mean_squared_error: 0.0156\n",
      "Epoch 15/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0043 - mean_absolute_error: 0.0307 - mean_squared_error: 0.0043 - val_loss: 0.0172 - val_mean_absolute_error: 0.0705 - val_mean_squared_error: 0.0172\n",
      "Epoch 16/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0042 - mean_absolute_error: 0.0301 - mean_squared_error: 0.0042 - val_loss: 0.0129 - val_mean_absolute_error: 0.0601 - val_mean_squared_error: 0.0129\n",
      "Epoch 17/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0040 - mean_absolute_error: 0.0296 - mean_squared_error: 0.0040 - val_loss: 0.0097 - val_mean_absolute_error: 0.0513 - val_mean_squared_error: 0.0097\n",
      "Epoch 18/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0039 - mean_absolute_error: 0.0290 - mean_squared_error: 0.0039 - val_loss: 0.0092 - val_mean_absolute_error: 0.0509 - val_mean_squared_error: 0.0092\n",
      "Epoch 19/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0037 - mean_absolute_error: 0.0282 - mean_squared_error: 0.0037 - val_loss: 0.0068 - val_mean_absolute_error: 0.0426 - val_mean_squared_error: 0.0068\n",
      "Epoch 20/200\n",
      "4222/4222 [==============================] - 0s 42us/sample - loss: 0.0036 - mean_absolute_error: 0.0274 - mean_squared_error: 0.0036 - val_loss: 0.0050 - val_mean_absolute_error: 0.0358 - val_mean_squared_error: 0.0050\n",
      "Epoch 21/200\n",
      "4222/4222 [==============================] - 0s 43us/sample - loss: 0.0035 - mean_absolute_error: 0.0270 - mean_squared_error: 0.0035 - val_loss: 0.0058 - val_mean_absolute_error: 0.0393 - val_mean_squared_error: 0.0058\n",
      "Epoch 22/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0034 - mean_absolute_error: 0.0267 - mean_squared_error: 0.0034 - val_loss: 0.0036 - val_mean_absolute_error: 0.0319 - val_mean_squared_error: 0.0036\n",
      "Epoch 23/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0034 - mean_absolute_error: 0.0262 - mean_squared_error: 0.0034 - val_loss: 0.0040 - val_mean_absolute_error: 0.0329 - val_mean_squared_error: 0.0040\n",
      "Epoch 24/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0035 - mean_absolute_error: 0.0265 - mean_squared_error: 0.0035 - val_loss: 0.0052 - val_mean_absolute_error: 0.0347 - val_mean_squared_error: 0.0052\n",
      "Epoch 25/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0032 - mean_absolute_error: 0.0252 - mean_squared_error: 0.0032 - val_loss: 0.0038 - val_mean_absolute_error: 0.0332 - val_mean_squared_error: 0.0038\n",
      "Epoch 26/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0031 - mean_absolute_error: 0.0250 - mean_squared_error: 0.0031 - val_loss: 0.0032 - val_mean_absolute_error: 0.0298 - val_mean_squared_error: 0.0032\n",
      "Epoch 27/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0033 - mean_absolute_error: 0.0251 - mean_squared_error: 0.0033 - val_loss: 0.0039 - val_mean_absolute_error: 0.0379 - val_mean_squared_error: 0.0039\n",
      "Epoch 28/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0033 - mean_absolute_error: 0.0258 - mean_squared_error: 0.0033 - val_loss: 0.0042 - val_mean_absolute_error: 0.0402 - val_mean_squared_error: 0.0042\n",
      "Epoch 29/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0034 - mean_absolute_error: 0.0261 - mean_squared_error: 0.0034 - val_loss: 0.0046 - val_mean_absolute_error: 0.0419 - val_mean_squared_error: 0.0046\n",
      "Epoch 30/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0034 - mean_absolute_error: 0.0257 - mean_squared_error: 0.0034 - val_loss: 0.0040 - val_mean_absolute_error: 0.0392 - val_mean_squared_error: 0.0040\n",
      "Epoch 31/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0033 - mean_absolute_error: 0.0257 - mean_squared_error: 0.0033 - val_loss: 0.0042 - val_mean_absolute_error: 0.0403 - val_mean_squared_error: 0.0042\n",
      "Epoch 32/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0032 - mean_absolute_error: 0.0256 - mean_squared_error: 0.0032 - val_loss: 0.0036 - val_mean_absolute_error: 0.0348 - val_mean_squared_error: 0.0036\n",
      "Epoch 33/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0030 - mean_absolute_error: 0.0247 - mean_squared_error: 0.0030 - val_loss: 0.0038 - val_mean_absolute_error: 0.0373 - val_mean_squared_error: 0.0038\n",
      "Epoch 34/200\n",
      "4222/4222 [==============================] - 0s 42us/sample - loss: 0.0030 - mean_absolute_error: 0.0246 - mean_squared_error: 0.0030 - val_loss: 0.0034 - val_mean_absolute_error: 0.0365 - val_mean_squared_error: 0.0034\n",
      "Epoch 35/200\n",
      "4222/4222 [==============================] - 0s 42us/sample - loss: 0.0030 - mean_absolute_error: 0.0247 - mean_squared_error: 0.0030 - val_loss: 0.0034 - val_mean_absolute_error: 0.0348 - val_mean_squared_error: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "4222/4222 [==============================] - 0s 38us/sample - loss: 0.0030 - mean_absolute_error: 0.0244 - mean_squared_error: 0.0030 - val_loss: 0.0043 - val_mean_absolute_error: 0.0388 - val_mean_squared_error: 0.0043\n",
      "Epoch 37/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0030 - mean_absolute_error: 0.0247 - mean_squared_error: 0.0030 - val_loss: 0.0037 - val_mean_absolute_error: 0.0371 - val_mean_squared_error: 0.0037\n",
      "Epoch 38/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0031 - mean_absolute_error: 0.0246 - mean_squared_error: 0.0031 - val_loss: 0.0038 - val_mean_absolute_error: 0.0373 - val_mean_squared_error: 0.0038\n",
      "Epoch 39/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0030 - mean_absolute_error: 0.0240 - mean_squared_error: 0.0030 - val_loss: 0.0033 - val_mean_absolute_error: 0.0331 - val_mean_squared_error: 0.0033\n",
      "Epoch 40/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0031 - mean_absolute_error: 0.0238 - mean_squared_error: 0.0031 - val_loss: 0.0038 - val_mean_absolute_error: 0.0362 - val_mean_squared_error: 0.0038\n",
      "Epoch 41/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0028 - mean_absolute_error: 0.0230 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0303 - val_mean_squared_error: 0.0027\n",
      "Epoch 42/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0029 - mean_absolute_error: 0.0238 - mean_squared_error: 0.0029 - val_loss: 0.0035 - val_mean_absolute_error: 0.0346 - val_mean_squared_error: 0.0035\n",
      "Epoch 43/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0028 - mean_absolute_error: 0.0234 - mean_squared_error: 0.0028 - val_loss: 0.0033 - val_mean_absolute_error: 0.0343 - val_mean_squared_error: 0.0033\n",
      "Epoch 44/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0029 - mean_absolute_error: 0.0235 - mean_squared_error: 0.0029 - val_loss: 0.0033 - val_mean_absolute_error: 0.0317 - val_mean_squared_error: 0.0033\n",
      "Epoch 45/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0028 - mean_absolute_error: 0.0234 - mean_squared_error: 0.0028 - val_loss: 0.0031 - val_mean_absolute_error: 0.0344 - val_mean_squared_error: 0.0031\n",
      "Epoch 46/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0028 - mean_absolute_error: 0.0238 - mean_squared_error: 0.0028 - val_loss: 0.0034 - val_mean_absolute_error: 0.0342 - val_mean_squared_error: 0.0034\n",
      "Epoch 47/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0031 - mean_absolute_error: 0.0242 - mean_squared_error: 0.0031 - val_loss: 0.0027 - val_mean_absolute_error: 0.0316 - val_mean_squared_error: 0.0027\n",
      "Epoch 48/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0027 - mean_absolute_error: 0.0224 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_absolute_error: 0.0306 - val_mean_squared_error: 0.0026\n",
      "Epoch 49/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0027 - mean_absolute_error: 0.0227 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_mean_absolute_error: 0.0336 - val_mean_squared_error: 0.0033\n",
      "Epoch 50/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0027 - mean_absolute_error: 0.0229 - mean_squared_error: 0.0027 - val_loss: 0.0040 - val_mean_absolute_error: 0.0363 - val_mean_squared_error: 0.0040\n",
      "Epoch 51/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0026 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_absolute_error: 0.0282 - val_mean_squared_error: 0.0024\n",
      "Epoch 52/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0028 - mean_absolute_error: 0.0230 - mean_squared_error: 0.0028 - val_loss: 0.0034 - val_mean_absolute_error: 0.0350 - val_mean_squared_error: 0.0034\n",
      "Epoch 53/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0028 - mean_absolute_error: 0.0230 - mean_squared_error: 0.0028 - val_loss: 0.0032 - val_mean_absolute_error: 0.0352 - val_mean_squared_error: 0.0032\n",
      "Epoch 54/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0026 - mean_absolute_error: 0.0226 - mean_squared_error: 0.0026 - val_loss: 0.0027 - val_mean_absolute_error: 0.0314 - val_mean_squared_error: 0.0027\n",
      "Epoch 55/200\n",
      "4222/4222 [==============================] - 0s 37us/sample - loss: 0.0026 - mean_absolute_error: 0.0227 - mean_squared_error: 0.0026 - val_loss: 0.0032 - val_mean_absolute_error: 0.0338 - val_mean_squared_error: 0.0032\n",
      "Epoch 56/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0026 - mean_absolute_error: 0.0223 - mean_squared_error: 0.0026 - val_loss: 0.0028 - val_mean_absolute_error: 0.0320 - val_mean_squared_error: 0.0028\n",
      "Epoch 57/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0026 - mean_absolute_error: 0.0220 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_mean_absolute_error: 0.0311 - val_mean_squared_error: 0.0030\n",
      "Epoch 58/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0025 - mean_absolute_error: 0.0223 - mean_squared_error: 0.0025 - val_loss: 0.0031 - val_mean_absolute_error: 0.0319 - val_mean_squared_error: 0.0031\n",
      "Epoch 59/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0026 - mean_absolute_error: 0.0221 - mean_squared_error: 0.0026 - val_loss: 0.0032 - val_mean_absolute_error: 0.0324 - val_mean_squared_error: 0.0032\n",
      "Epoch 60/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0026 - mean_absolute_error: 0.0219 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_mean_absolute_error: 0.0367 - val_mean_squared_error: 0.0035\n",
      "Epoch 61/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0025 - mean_absolute_error: 0.0220 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_mean_absolute_error: 0.0334 - val_mean_squared_error: 0.0029\n",
      "Epoch 62/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0025 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_absolute_error: 0.0299 - val_mean_squared_error: 0.0024\n",
      "Epoch 63/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0025 - mean_absolute_error: 0.0216 - mean_squared_error: 0.0025 - val_loss: 0.0027 - val_mean_absolute_error: 0.0309 - val_mean_squared_error: 0.0027\n",
      "Epoch 64/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0025 - mean_absolute_error: 0.0223 - mean_squared_error: 0.0025 - val_loss: 0.0031 - val_mean_absolute_error: 0.0324 - val_mean_squared_error: 0.0031\n",
      "Epoch 65/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0024 - mean_absolute_error: 0.0221 - mean_squared_error: 0.0024 - val_loss: 0.0026 - val_mean_absolute_error: 0.0297 - val_mean_squared_error: 0.0026\n",
      "Epoch 66/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0024 - mean_absolute_error: 0.0212 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_mean_absolute_error: 0.0285 - val_mean_squared_error: 0.0024\n",
      "Epoch 67/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0024 - mean_absolute_error: 0.0222 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_mean_absolute_error: 0.0318 - val_mean_squared_error: 0.0028\n",
      "Epoch 68/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0024 - mean_absolute_error: 0.0221 - mean_squared_error: 0.0024 - val_loss: 0.0025 - val_mean_absolute_error: 0.0293 - val_mean_squared_error: 0.0025\n",
      "Epoch 69/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0023 - mean_absolute_error: 0.0220 - mean_squared_error: 0.0023 - val_loss: 0.0034 - val_mean_absolute_error: 0.0320 - val_mean_squared_error: 0.0034\n",
      "Epoch 70/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0022 - mean_absolute_error: 0.0210 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_mean_absolute_error: 0.0346 - val_mean_squared_error: 0.0029\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0025 - mean_absolute_error: 0.0221 - mean_squared_error: 0.0025 - val_loss: 0.0026 - val_mean_absolute_error: 0.0286 - val_mean_squared_error: 0.0026\n",
      "Epoch 72/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0024 - mean_absolute_error: 0.0215 - mean_squared_error: 0.0024 - val_loss: 0.0027 - val_mean_absolute_error: 0.0321 - val_mean_squared_error: 0.0027\n",
      "Epoch 73/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0024 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_mean_absolute_error: 0.0323 - val_mean_squared_error: 0.0028\n",
      "Epoch 74/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0024 - mean_absolute_error: 0.0216 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_absolute_error: 0.0265 - val_mean_squared_error: 0.0022\n",
      "Epoch 75/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0022 - mean_absolute_error: 0.0209 - mean_squared_error: 0.0022 - val_loss: 0.0030 - val_mean_absolute_error: 0.0310 - val_mean_squared_error: 0.0030\n",
      "Epoch 76/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0023 - mean_absolute_error: 0.0212 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_mean_absolute_error: 0.0284 - val_mean_squared_error: 0.0022\n",
      "Epoch 77/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0024 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_mean_absolute_error: 0.0297 - val_mean_squared_error: 0.0024\n",
      "Epoch 78/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0024 - mean_absolute_error: 0.0223 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_mean_absolute_error: 0.0315 - val_mean_squared_error: 0.0028\n",
      "Epoch 79/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0023 - mean_absolute_error: 0.0214 - mean_squared_error: 0.0023 - val_loss: 0.0025 - val_mean_absolute_error: 0.0295 - val_mean_squared_error: 0.0025\n",
      "Epoch 80/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0024 - mean_absolute_error: 0.0218 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_mean_absolute_error: 0.0303 - val_mean_squared_error: 0.0024\n",
      "Epoch 81/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0023 - mean_absolute_error: 0.0219 - mean_squared_error: 0.0023 - val_loss: 0.0025 - val_mean_absolute_error: 0.0311 - val_mean_squared_error: 0.0025\n",
      "Epoch 82/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0022 - mean_absolute_error: 0.0210 - mean_squared_error: 0.0022 - val_loss: 0.0028 - val_mean_absolute_error: 0.0336 - val_mean_squared_error: 0.0028\n",
      "Epoch 83/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0021 - mean_absolute_error: 0.0207 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_mean_absolute_error: 0.0287 - val_mean_squared_error: 0.0024\n",
      "Epoch 84/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0022 - mean_absolute_error: 0.0207 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_absolute_error: 0.0291 - val_mean_squared_error: 0.0025\n",
      "Epoch 85/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0022 - mean_absolute_error: 0.0215 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_mean_absolute_error: 0.0322 - val_mean_squared_error: 0.0026\n",
      "Epoch 86/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0022 - mean_absolute_error: 0.0209 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_mean_absolute_error: 0.0290 - val_mean_squared_error: 0.0026\n",
      "Epoch 87/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0022 - mean_absolute_error: 0.0211 - mean_squared_error: 0.0022 - val_loss: 0.0027 - val_mean_absolute_error: 0.0309 - val_mean_squared_error: 0.0027\n",
      "Epoch 88/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0022 - mean_absolute_error: 0.0203 - mean_squared_error: 0.0022 - val_loss: 0.0028 - val_mean_absolute_error: 0.0304 - val_mean_squared_error: 0.0028\n",
      "Epoch 89/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0022 - mean_absolute_error: 0.0206 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_absolute_error: 0.0278 - val_mean_squared_error: 0.0024\n",
      "Epoch 90/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0022 - mean_absolute_error: 0.0216 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_absolute_error: 0.0293 - val_mean_squared_error: 0.0024\n",
      "Epoch 91/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0020 - mean_absolute_error: 0.0214 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_mean_absolute_error: 0.0254 - val_mean_squared_error: 0.0022\n",
      "Epoch 92/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0206 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_mean_absolute_error: 0.0257 - val_mean_squared_error: 0.0023\n",
      "Epoch 93/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0022 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_absolute_error: 0.0240 - val_mean_squared_error: 0.0020\n",
      "Epoch 94/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0022 - mean_absolute_error: 0.0215 - mean_squared_error: 0.0022 - val_loss: 0.0021 - val_mean_absolute_error: 0.0259 - val_mean_squared_error: 0.0021\n",
      "Epoch 95/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0021 - mean_absolute_error: 0.0212 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_absolute_error: 0.0266 - val_mean_squared_error: 0.0020\n",
      "Epoch 96/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0022 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0022 - val_loss: 0.0021 - val_mean_absolute_error: 0.0254 - val_mean_squared_error: 0.0021\n",
      "Epoch 97/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0020 - mean_absolute_error: 0.0205 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_mean_absolute_error: 0.0262 - val_mean_squared_error: 0.0023\n",
      "Epoch 98/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0020 - mean_absolute_error: 0.0207 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_mean_absolute_error: 0.0275 - val_mean_squared_error: 0.0024\n",
      "Epoch 99/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0019 - mean_absolute_error: 0.0208 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_mean_absolute_error: 0.0265 - val_mean_squared_error: 0.0023\n",
      "Epoch 100/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0020 - mean_absolute_error: 0.0208 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_mean_absolute_error: 0.0272 - val_mean_squared_error: 0.0024\n",
      "Epoch 101/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0021 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0021 - val_loss: 0.0026 - val_mean_absolute_error: 0.0294 - val_mean_squared_error: 0.0026\n",
      "Epoch 102/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0021 - mean_absolute_error: 0.0207 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_absolute_error: 0.0253 - val_mean_squared_error: 0.0022\n",
      "Epoch 103/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0021 - mean_absolute_error: 0.0209 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_mean_absolute_error: 0.0255 - val_mean_squared_error: 0.0023\n",
      "Epoch 104/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0021 - mean_absolute_error: 0.0211 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_mean_absolute_error: 0.0280 - val_mean_squared_error: 0.0024\n",
      "Epoch 105/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0206 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_absolute_error: 0.0250 - val_mean_squared_error: 0.0022\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0021 - mean_absolute_error: 0.0209 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_absolute_error: 0.0234 - val_mean_squared_error: 0.0021\n",
      "Epoch 107/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0205 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0254 - val_mean_squared_error: 0.0024\n",
      "Epoch 108/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0021 - mean_absolute_error: 0.0208 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_absolute_error: 0.0243 - val_mean_squared_error: 0.0021\n",
      "Epoch 109/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0019 - mean_absolute_error: 0.0192 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_mean_absolute_error: 0.0255 - val_mean_squared_error: 0.0023\n",
      "Epoch 110/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0021 - mean_absolute_error: 0.0203 - mean_squared_error: 0.0021 - val_loss: 0.0026 - val_mean_absolute_error: 0.0274 - val_mean_squared_error: 0.0026\n",
      "Epoch 111/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0019 - mean_absolute_error: 0.0202 - mean_squared_error: 0.0019 - val_loss: 0.0025 - val_mean_absolute_error: 0.0253 - val_mean_squared_error: 0.0025\n",
      "Epoch 112/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0263 - val_mean_squared_error: 0.0024\n",
      "Epoch 113/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_mean_absolute_error: 0.0246 - val_mean_squared_error: 0.0024\n",
      "Epoch 114/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0017 - val_loss: 0.0029 - val_mean_absolute_error: 0.0285 - val_mean_squared_error: 0.0029\n",
      "Epoch 115/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_mean_absolute_error: 0.0265 - val_mean_squared_error: 0.0023\n",
      "Epoch 116/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0018 - val_loss: 0.0027 - val_mean_absolute_error: 0.0273 - val_mean_squared_error: 0.0027\n",
      "Epoch 117/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0020 - mean_absolute_error: 0.0204 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_mean_absolute_error: 0.0236 - val_mean_squared_error: 0.0022\n",
      "Epoch 118/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0018 - val_loss: 0.0025 - val_mean_absolute_error: 0.0265 - val_mean_squared_error: 0.0025\n",
      "Epoch 119/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0019 - mean_absolute_error: 0.0198 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_absolute_error: 0.0259 - val_mean_squared_error: 0.0022\n",
      "Epoch 120/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_mean_absolute_error: 0.0242 - val_mean_squared_error: 0.0023\n",
      "Epoch 121/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0019 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_mean_absolute_error: 0.0258 - val_mean_squared_error: 0.0023\n",
      "Epoch 122/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0018 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_mean_absolute_error: 0.0256 - val_mean_squared_error: 0.0024\n",
      "Epoch 123/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0018 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_mean_absolute_error: 0.0262 - val_mean_squared_error: 0.0023\n",
      "Epoch 124/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0019 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0267 - val_mean_squared_error: 0.0024\n",
      "Epoch 125/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0019 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_absolute_error: 0.0264 - val_mean_squared_error: 0.0022\n",
      "Epoch 126/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0019 - mean_absolute_error: 0.0203 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_absolute_error: 0.0256 - val_mean_squared_error: 0.0022\n",
      "Epoch 127/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0020 - mean_absolute_error: 0.0192 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_mean_absolute_error: 0.0267 - val_mean_squared_error: 0.0022\n",
      "Epoch 128/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0017 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0017 - val_loss: 0.0027 - val_mean_absolute_error: 0.0290 - val_mean_squared_error: 0.0027\n",
      "Epoch 129/200\n",
      "4222/4222 [==============================] - 0s 37us/sample - loss: 0.0019 - mean_absolute_error: 0.0202 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_mean_absolute_error: 0.0300 - val_mean_squared_error: 0.0027\n",
      "Epoch 130/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0271 - val_mean_squared_error: 0.0024\n",
      "Epoch 131/200\n",
      "4222/4222 [==============================] - 0s 42us/sample - loss: 0.0019 - mean_absolute_error: 0.0192 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0277 - val_mean_squared_error: 0.0024\n",
      "Epoch 132/200\n",
      "4222/4222 [==============================] - 0s 46us/sample - loss: 0.0019 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_mean_absolute_error: 0.0276 - val_mean_squared_error: 0.0023\n",
      "Epoch 133/200\n",
      "4222/4222 [==============================] - 0s 44us/sample - loss: 0.0019 - mean_absolute_error: 0.0206 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0278 - val_mean_squared_error: 0.0024\n",
      "Epoch 134/200\n",
      "4222/4222 [==============================] - 0s 45us/sample - loss: 0.0017 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_mean_absolute_error: 0.0295 - val_mean_squared_error: 0.0024\n",
      "Epoch 135/200\n",
      "4222/4222 [==============================] - 0s 47us/sample - loss: 0.0019 - mean_absolute_error: 0.0203 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0283 - val_mean_squared_error: 0.0024\n",
      "Epoch 136/200\n",
      "4222/4222 [==============================] - 0s 46us/sample - loss: 0.0018 - mean_absolute_error: 0.0198 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_mean_absolute_error: 0.0290 - val_mean_squared_error: 0.0024\n",
      "Epoch 137/200\n",
      "4222/4222 [==============================] - 0s 41us/sample - loss: 0.0018 - mean_absolute_error: 0.0198 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_mean_absolute_error: 0.0310 - val_mean_squared_error: 0.0028\n",
      "Epoch 138/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0018 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0018 - val_loss: 0.0025 - val_mean_absolute_error: 0.0288 - val_mean_squared_error: 0.0025\n",
      "Epoch 139/200\n",
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0019 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_mean_absolute_error: 0.0296 - val_mean_squared_error: 0.0026\n",
      "Epoch 140/200\n",
      "4222/4222 [==============================] - 0s 43us/sample - loss: 0.0020 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_mean_absolute_error: 0.0281 - val_mean_squared_error: 0.0024\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 40us/sample - loss: 0.0018 - mean_absolute_error: 0.0189 - mean_squared_error: 0.0018 - val_loss: 0.0035 - val_mean_absolute_error: 0.0296 - val_mean_squared_error: 0.0035\n",
      "Epoch 142/200\n",
      "4222/4222 [==============================] - 0s 39us/sample - loss: 0.0017 - mean_absolute_error: 0.0201 - mean_squared_error: 0.0017 - val_loss: 0.0026 - val_mean_absolute_error: 0.0296 - val_mean_squared_error: 0.0026\n",
      "Epoch 143/200\n",
      "4222/4222 [==============================] - 0s 38us/sample - loss: 0.0018 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0018 - val_loss: 0.0029 - val_mean_absolute_error: 0.0286 - val_mean_squared_error: 0.0029\n",
      "Epoch 144/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0019 - mean_absolute_error: 0.0210 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_absolute_error: 0.0285 - val_mean_squared_error: 0.0024\n",
      "Epoch 145/200\n",
      "4222/4222 [==============================] - 0s 54us/sample - loss: 0.0017 - mean_absolute_error: 0.0198 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_mean_absolute_error: 0.0243 - val_mean_squared_error: 0.0023\n",
      "Epoch 146/200\n",
      "4222/4222 [==============================] - 0s 52us/sample - loss: 0.0016 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0016 - val_loss: 0.0028 - val_mean_absolute_error: 0.0335 - val_mean_squared_error: 0.0028\n",
      "Epoch 147/200\n",
      "4222/4222 [==============================] - 0s 49us/sample - loss: 0.0020 - mean_absolute_error: 0.0196 - mean_squared_error: 0.0020 - val_loss: 0.0021 - val_mean_absolute_error: 0.0276 - val_mean_squared_error: 0.0021\n",
      "Epoch 148/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0018 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_mean_absolute_error: 0.0285 - val_mean_squared_error: 0.0024\n",
      "Epoch 149/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0017 - mean_absolute_error: 0.0191 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_mean_absolute_error: 0.0281 - val_mean_squared_error: 0.0023\n",
      "Epoch 150/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0018 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_mean_absolute_error: 0.0263 - val_mean_squared_error: 0.0022\n",
      "Epoch 151/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0018 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0018 - val_loss: 0.0034 - val_mean_absolute_error: 0.0309 - val_mean_squared_error: 0.0034\n",
      "Epoch 152/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0016 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_mean_absolute_error: 0.0268 - val_mean_squared_error: 0.0022\n",
      "Epoch 153/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0020 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_mean_absolute_error: 0.0275 - val_mean_squared_error: 0.0022\n",
      "Epoch 154/200\n",
      "4222/4222 [==============================] - 0s 33us/sample - loss: 0.0016 - mean_absolute_error: 0.0191 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_mean_absolute_error: 0.0290 - val_mean_squared_error: 0.0024\n",
      "Epoch 155/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0016 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0016 - val_loss: 0.0025 - val_mean_absolute_error: 0.0296 - val_mean_squared_error: 0.0025\n",
      "Epoch 156/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0018 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_mean_absolute_error: 0.0303 - val_mean_squared_error: 0.0028\n",
      "Epoch 157/200\n",
      "4222/4222 [==============================] - 0s 32us/sample - loss: 0.0017 - mean_absolute_error: 0.0196 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_mean_absolute_error: 0.0265 - val_mean_squared_error: 0.0023\n",
      "Epoch 158/200\n",
      "4222/4222 [==============================] - 0s 49us/sample - loss: 0.0016 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_mean_absolute_error: 0.0280 - val_mean_squared_error: 0.0024\n",
      "Epoch 159/200\n",
      "4222/4222 [==============================] - 0s 56us/sample - loss: 0.0018 - mean_absolute_error: 0.0191 - mean_squared_error: 0.0018 - val_loss: 0.0039 - val_mean_absolute_error: 0.0350 - val_mean_squared_error: 0.0039\n",
      "Epoch 160/200\n",
      "4222/4222 [==============================] - 0s 43us/sample - loss: 0.0016 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_mean_absolute_error: 0.0256 - val_mean_squared_error: 0.0020\n",
      "Epoch 161/200\n",
      "4222/4222 [==============================] - 0s 49us/sample - loss: 0.0019 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0019 - val_loss: 0.0025 - val_mean_absolute_error: 0.0304 - val_mean_squared_error: 0.0025\n",
      "Epoch 162/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0018 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_mean_absolute_error: 0.0295 - val_mean_squared_error: 0.0028\n",
      "Epoch 163/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_mean_absolute_error: 0.0261 - val_mean_squared_error: 0.0023\n",
      "Epoch 164/200\n",
      "4222/4222 [==============================] - 0s 37us/sample - loss: 0.0017 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0017 - val_loss: 0.0026 - val_mean_absolute_error: 0.0275 - val_mean_squared_error: 0.0026\n",
      "Epoch 165/200\n",
      "4222/4222 [==============================] - 0s 37us/sample - loss: 0.0017 - mean_absolute_error: 0.0189 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_mean_absolute_error: 0.0267 - val_mean_squared_error: 0.0024\n",
      "Epoch 166/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0016 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0016 - val_loss: 0.0023 - val_mean_absolute_error: 0.0291 - val_mean_squared_error: 0.0023\n",
      "Epoch 167/200\n",
      "4222/4222 [==============================] - 0s 37us/sample - loss: 0.0020 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0020 - val_loss: 0.0021 - val_mean_absolute_error: 0.0263 - val_mean_squared_error: 0.0021\n",
      "Epoch 168/200\n",
      "4222/4222 [==============================] - 0s 37us/sample - loss: 0.0017 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_mean_absolute_error: 0.0259 - val_mean_squared_error: 0.0021\n",
      "Epoch 169/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0019 - mean_absolute_error: 0.0203 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_absolute_error: 0.0251 - val_mean_squared_error: 0.0022\n",
      "Epoch 170/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0017 - mean_absolute_error: 0.0202 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_mean_absolute_error: 0.0269 - val_mean_squared_error: 0.0021\n",
      "Epoch 171/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0015 - mean_absolute_error: 0.0189 - mean_squared_error: 0.0015 - val_loss: 0.0022 - val_mean_absolute_error: 0.0293 - val_mean_squared_error: 0.0022\n",
      "Epoch 172/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0017 - mean_absolute_error: 0.0198 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_mean_absolute_error: 0.0305 - val_mean_squared_error: 0.0025\n",
      "Epoch 173/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_mean_absolute_error: 0.0215 - val_mean_squared_error: 0.0021\n",
      "Epoch 174/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0017 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0017 - val_loss: 0.0028 - val_mean_absolute_error: 0.0332 - val_mean_squared_error: 0.0028\n",
      "Epoch 175/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0018 - mean_absolute_error: 0.0201 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_mean_absolute_error: 0.0298 - val_mean_squared_error: 0.0024\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/4222 [==============================] - 0s 38us/sample - loss: 0.0017 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_mean_absolute_error: 0.0284 - val_mean_squared_error: 0.0024\n",
      "Epoch 177/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0019 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_mean_absolute_error: 0.0311 - val_mean_squared_error: 0.0027\n",
      "Epoch 178/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_mean_absolute_error: 0.0325 - val_mean_squared_error: 0.0022\n",
      "Epoch 179/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0016 - mean_absolute_error: 0.0191 - mean_squared_error: 0.0016 - val_loss: 0.0023 - val_mean_absolute_error: 0.0317 - val_mean_squared_error: 0.0023\n",
      "Epoch 180/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0192 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_mean_absolute_error: 0.0305 - val_mean_squared_error: 0.0024\n",
      "Epoch 181/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0018 - val_loss: 0.0027 - val_mean_absolute_error: 0.0297 - val_mean_squared_error: 0.0027\n",
      "Epoch 182/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0015 - mean_absolute_error: 0.0187 - mean_squared_error: 0.0015 - val_loss: 0.0024 - val_mean_absolute_error: 0.0285 - val_mean_squared_error: 0.0024\n",
      "Epoch 183/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_mean_absolute_error: 0.0279 - val_mean_squared_error: 0.0023\n",
      "Epoch 184/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0189 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_mean_absolute_error: 0.0275 - val_mean_squared_error: 0.0022\n",
      "Epoch 185/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0016 - mean_absolute_error: 0.0186 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_mean_absolute_error: 0.0297 - val_mean_squared_error: 0.0021\n",
      "Epoch 186/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0017 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_mean_absolute_error: 0.0268 - val_mean_squared_error: 0.0021\n",
      "Epoch 187/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0016 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_mean_absolute_error: 0.0290 - val_mean_squared_error: 0.0022\n",
      "Epoch 188/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0017 - mean_absolute_error: 0.0192 - mean_squared_error: 0.0017 - val_loss: 0.0026 - val_mean_absolute_error: 0.0269 - val_mean_squared_error: 0.0026\n",
      "Epoch 189/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_mean_absolute_error: 0.0280 - val_mean_squared_error: 0.0022\n",
      "Epoch 190/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0016 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_mean_absolute_error: 0.0278 - val_mean_squared_error: 0.0022\n",
      "Epoch 191/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0016 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_mean_absolute_error: 0.0272 - val_mean_squared_error: 0.0021\n",
      "Epoch 192/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0016 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_mean_absolute_error: 0.0249 - val_mean_squared_error: 0.0021\n",
      "Epoch 193/200\n",
      "4222/4222 [==============================] - 0s 36us/sample - loss: 0.0016 - mean_absolute_error: 0.0189 - mean_squared_error: 0.0016 - val_loss: 0.0019 - val_mean_absolute_error: 0.0256 - val_mean_squared_error: 0.0019\n",
      "Epoch 194/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0017 - mean_absolute_error: 0.0202 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_mean_absolute_error: 0.0266 - val_mean_squared_error: 0.0019\n",
      "Epoch 195/200\n",
      "4222/4222 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0196 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_mean_absolute_error: 0.0285 - val_mean_squared_error: 0.0021\n",
      "Epoch 196/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_mean_absolute_error: 0.0254 - val_mean_squared_error: 0.0021\n",
      "Epoch 197/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0015 - mean_absolute_error: 0.0191 - mean_squared_error: 0.0015 - val_loss: 0.0023 - val_mean_absolute_error: 0.0267 - val_mean_squared_error: 0.0023\n",
      "Epoch 198/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_mean_absolute_error: 0.0297 - val_mean_squared_error: 0.0022\n",
      "Epoch 199/200\n",
      "4222/4222 [==============================] - 0s 37us/sample - loss: 0.0015 - mean_absolute_error: 0.0181 - mean_squared_error: 0.0015 - val_loss: 0.0022 - val_mean_absolute_error: 0.0269 - val_mean_squared_error: 0.0022\n",
      "Epoch 200/200\n",
      "4222/4222 [==============================] - 0s 35us/sample - loss: 0.0018 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_mean_absolute_error: 0.0307 - val_mean_squared_error: 0.0023\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_YNN_nomob, y_YNN_nomob = get_YNN_states_dataset(state_cases_df, n_steps=N_STEPS)\n",
    "X_train_YNN_nomob, X_test_YNN_nomob, y_train_YNN_nomob, y_test_YNN_nomob = train_test_split(X_YNN_nomob, y_YNN_nomob, test_size=SPLIT, shuffle=False)\n",
    "\n",
    "# Set up model\n",
    "n_ynn_features = X_train_YNN_nomob.shape[1]\n",
    "ynn_nomob = build_YNN_model(n_ynn_features)\n",
    "\n",
    "# Fit CNN\n",
    "ynn_nomob_history = ynn_nomob.fit(X_train_YNN_nomob, y_train_YNN_nomob,\n",
    "                                     epochs=EPOCHS,\n",
    "                                     validation_data=(X_test_YNN_nomob, y_test_YNN_nomob),\n",
    "                                     verbose=1,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.004527903903583825"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the predicted vs. actual, we can see that the values are fitted pretty well\n",
    "test_pred = ynn.predict(X_test_YNN)\n",
    "plt.scatter(test_pred, y_test_YNN)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# The errors seem to have much normality, but a bit right-skewed\n",
    "errors = test_pred - y_test_YNN\n",
    "plt.hist(errors, bins=25)\n",
    "plt.xlabel(\"Prediction Error [MPG]\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# And the residuals mean is close to zero. \n",
    "np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.007992969348711363"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still, we can see that the predicted is pretty close to the actual, \n",
    "# but with less precisions as the model with Mobility data\n",
    "test_ynn2 = ynn_nomob.predict(X_test_YNN_nomob)\n",
    "plt.scatter(test_ynn2, y_test_YNN_nomob)\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Errors shows much normality, but seems to have a little right-skewed\n",
    "errors2 = test_ynn2 - y_test_YNN_nomob\n",
    "plt.hist(errors2, bins=25)\n",
    "plt.xlabel(\"Prediction Error [MPG]\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# And the error mean is pretty closed to zero\n",
    "np.mean(errors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['lstm', 'lstm_nomob', 'slstm', 'slstm_nomob', 'cnn', 'cnn_nomob', 'ynn', 'ynn_nomob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm with X_test_LSTM and Y_test_LSTM\n",
    "lstm_pred = lstm.predict(X_test_LSTM)\n",
    "lstm_error = lstm_pred - y_test_LSTM\n",
    "\n",
    "# lstm_nomob with X_test_LSTM_nomob and Y_test_LSTM_nomob\n",
    "lstm_nomob_pred = lstm_nomob.predict(X_test_LSTM_nomob)\n",
    "lstm_nomob_error = lstm_nomob_pred - y_test_LSTM_nomob\n",
    "\n",
    "# slstm with X_test_LSTM and Y_test_LSTM\n",
    "slstm_pred = slstm.predict(X_test_LSTM)\n",
    "slstm_error = slstm_pred - y_test_LSTM\n",
    "\n",
    "# slstm_nomob with X_test_LSTM_nomob and Y_test_LSTM_nomob\n",
    "slstm_nomob_pred = slstm_nomob.predict(X_test_LSTM_nomob)\n",
    "slstm_nomob_error = slstm_nomob_pred - y_test_LSTM_nomob\n",
    "\n",
    "# cnn with X_test_CNN and Y_test_CNN\n",
    "cnn_pred = cnn.predict(X_test_CNN)\n",
    "cnn_error = cnn_pred - y_test_CNN\n",
    "\n",
    "# cnn_nomob with X_test_CNN_nomob and Y_test_CNN_nomob\n",
    "cnn_nomob_pred = cnn_nomob.predict(X_test_CNN_nomob)\n",
    "cnn_nomob_error = cnn_nomob_pred - y_test_CNN_nomob\n",
    "\n",
    "# ynn with X_test_YNN and Y_test_YNN\n",
    "ynn_pred = ynn.predict(X_test_YNN)\n",
    "ynn_error = ynn_pred - y_test_YNN\n",
    "\n",
    "# ynn_nomob with X_test_YNN_nomob and Y_test_YNN_nomob\n",
    "ynn_nomob_pred = ynn_nomob.predict(X_test_YNN_nomob)\n",
    "ynn_nomob_error = ynn_nomob_pred - y_test_YNN_nomob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM: Testing set Mean Abs Error: 0.00788\n",
      "--------\n",
      "LSTM without mobility: Testing set Mean Abs Error: 0.01892\n",
      "--------\n",
      "Stacked LSTM: Testing set Mean Abs Error: 0.00812\n",
      "--------\n",
      "Stacked LSTM without mobility: Testing set Mean Abs Error: 0.01837\n",
      "--------\n",
      "CNN: Testing set Mean Abs Error: 0.01617\n",
      "--------\n",
      "CNN without mobility: Testing set Mean Abs Error: 0.03479\n",
      "--------\n",
      "NN: Testing set Mean Abs Error: 0.01556\n",
      "--------\n",
      "NN without mobility: Testing set Mean Abs Error: 0.03068\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "maes = []\n",
    "mses = []\n",
    "loss, mae, mse = lstm.evaluate(X_test_LSTM, y_test_LSTM, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"LSTM: Testing set Mean Abs Error: {:5.5f}\".format(mae))\n",
    "print(\"--------\")\n",
    "loss, mae, mse = lstm_nomob.evaluate(X_test_LSTM_nomob, y_test_LSTM_nomob, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"LSTM without mobility: Testing set Mean Abs Error: {:5.5f}\".format(mae))\n",
    "print(\"--------\")\n",
    "loss, mae, mse = slstm.evaluate(X_test_LSTM, y_test_LSTM, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"Stacked LSTM: Testing set Mean Abs Error: {:5.5f}\".format(mae))\n",
    "print(\"--------\")\n",
    "loss, mae, mse = slstm_nomob.evaluate(X_test_LSTM_nomob, y_test_LSTM_nomob, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"Stacked LSTM without mobility: Testing set Mean Abs Error: {:5.5f}\".format(mae))\n",
    "print(\"--------\")\n",
    "loss, mae, mse = cnn.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"CNN: Testing set Mean Abs Error: {:5.5f}\".format(mae))\n",
    "print(\"--------\")\n",
    "loss, mae, mse = cnn_nomob.evaluate(X_test_CNN_nomob, y_test_CNN_nomob, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"CNN without mobility: Testing set Mean Abs Error: {:5.5f}\".format(mae))\n",
    "print(\"--------\")\n",
    "loss, mae, mse = ynn.evaluate(X_test_YNN, y_test_YNN, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"NN: Testing set Mean Abs Error: {:5.5f}\".format(mae))\n",
    "print(\"--------\")\n",
    "loss, mae, mse = ynn_nomob.evaluate(X_test_YNN_nomob, y_test_YNN_nomob, verbose=0)\n",
    "losses.append(loss)\n",
    "maes.append(mae)\n",
    "mses.append(mse)\n",
    "print(\"NN without mobility: Testing set Mean Abs Error: {:5.5f}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models, losses, maes, mses\n",
      "lstm : 0.00021 0.00788 0.00021\n",
      "lstm_nomob : 0.00210 0.01892 0.00210\n",
      "slstm : 0.00022 0.00812 0.00022\n",
      "slstm_nomob : 0.00201 0.01837 0.00201\n",
      "cnn : 0.00072 0.01617 0.00072\n",
      "cnn_nomob : 0.00579 0.03479 0.00579\n",
      "ynn : 0.00066 0.01556 0.00066\n",
      "ynn_nomob : 0.00234 0.03068 0.00234\n"
     ]
    }
   ],
   "source": [
    "print(\"models, losses, maes, mses\")\n",
    "for i in range(len(models)):\n",
    "    print(models[i], \":\", \"{:5.5f}\".format(losses[i]), \"{:5.5f}\".format(maes[i]), \"{:5.5f}\".format(mses[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
